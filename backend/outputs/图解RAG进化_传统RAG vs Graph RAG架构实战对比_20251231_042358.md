# å›¾è§£RAGè¿›åŒ–ï¼šä¼ ç»ŸRAG vs Graph RAGæ¶æ„å®æˆ˜å¯¹æ¯”




![å›¾è§£RAGè¿›åŒ–ï¼šä¼ ç»ŸRAG vs Graph RAGæ¶æ„å®æˆ˜å¯¹æ¯” - æ¶æ„å›¾](./images/e424513bdf824954b319702694877b20.png)

## RAG, Graph RAG, å‘é‡æ£€ç´¢, çŸ¥è¯†å›¾è°±, æ¶æ„å¯¹æ¯”

**é˜…è¯»æ—¶é—´**: 30 min

> æŒæ¡Graph RAGçš„æ ¸å¿ƒä¼˜åŠ¿ï¼Œè®©ä½ çš„çŸ¥è¯†é—®ç­”ç³»ç»Ÿä»å•ç‚¹æ£€ç´¢è·ƒå‡ä¸ºå…³ç³»æ¨ç†å¼•æ“ã€‚

## ç›®å½•

- [RAGåŸºç¡€æ¦‚å¿µä¸ç¯å¢ƒå‡†å¤‡](#ragåŸºç¡€æ¦‚å¿µä¸ç¯å¢ƒå‡†å¤‡)
- [æ„å»ºä¼ ç»ŸRAGï¼šå‘é‡æ£€ç´¢å®æˆ˜](#æ„å»ºä¼ ç»Ÿragå‘é‡æ£€ç´¢å®æˆ˜)
- [æ„å»ºGraph RAGï¼šçŸ¥è¯†å›¾è°±é©±åŠ¨çš„å‡çº§ç‰ˆ](#æ„å»ºgraph-ragçŸ¥è¯†å›¾è°±é©±åŠ¨çš„å‡çº§ç‰ˆ)
- [æ¶æ„å¯¹æ¯”ä¸æ€§èƒ½å®æµ‹](#æ¶æ„å¯¹æ¯”ä¸æ€§èƒ½å®æµ‹)
- [é€‰å‹æŒ‡å—ä¸æœªæ¥æ¼”è¿›](#é€‰å‹æŒ‡å—ä¸æœªæ¥æ¼”è¿›)


---


éšç€å¤§æ¨¡å‹åœ¨ä¼ä¸šçŸ¥è¯†é—®ç­”åœºæ™¯ä¸­çš„å¹¿æ³›åº”ç”¨ï¼ŒRAGï¼ˆRetrieval-Augmented Generationï¼‰å·²æˆä¸ºå¢å¼ºæ¨¡å‹äº‹å®å‡†ç¡®æ€§çš„ä¸»æµæ¡†æ¶ã€‚ç„¶è€Œï¼Œä¼ ç»ŸRAGåœ¨å¤„ç†å¤æ‚å…³ç³»å’Œå¤šè·³æ¨ç†æ—¶è¡¨ç°ä¹åŠ›ã€‚æœ¬æ–‡å°†å¸¦ä½ äº²æ‰‹æ­å»ºå¹¶å¯¹æ¯”ä¼ ç»ŸRAGä¸æ–°å…´çš„Graph RAGæ¶æ„ï¼Œç†è§£å…¶è®¾è®¡å·®å¼‚ä¸é€‚ç”¨åœºæ™¯ï¼ŒåŠ©ä½ åœ¨å®é™…é¡¹ç›®ä¸­åšå‡ºæ˜æ™ºé€‰å‹ã€‚


---


## RAGåŸºç¡€æ¦‚å¿µä¸ç¯å¢ƒå‡†å¤‡

ä½ æ˜¯å¦é‡åˆ°è¿‡è¿™æ ·çš„åœºæ™¯ï¼šå¤§æ¨¡å‹è‡ªä¿¡æ»¡æ»¡åœ°å›ç­”äº†ä¸€ä¸ªé—®é¢˜ï¼Œç»“æœç»™å‡ºçš„ç­”æ¡ˆå´æ˜¯â€œä¸€æœ¬æ­£ç»åœ°èƒ¡è¯´å…«é“â€ï¼Ÿåœ¨ä¼ä¸šçŸ¥è¯†åº“ã€æ³•å¾‹å’¨è¯¢ã€åŒ»ç–—é—®ç­”ç­‰å¯¹äº‹å®å‡†ç¡®æ€§è¦æ±‚æé«˜çš„é¢†åŸŸï¼Œè¿™ç§â€œå¹»è§‰è¾“å‡ºâ€è½»åˆ™è¯¯å¯¼ç”¨æˆ·ï¼Œé‡åˆ™å¼•å‘ä¸¥é‡åæœã€‚æƒ³è±¡ä¸€ä¸‹ï¼Œçº¿ä¸Šå®¢æœæœºå™¨äººæŠŠå…¬å¸æ”¿ç­–è§£é‡Šé”™äº†ï¼Œå¯¼è‡´å®¢æˆ·é›†ä½“æŠ•è¯‰â€”â€”è¿™ä¸æ˜¯ç§‘å¹»ç‰‡ï¼Œè€Œæ˜¯è®¸å¤šå›¢é˜Ÿæ­£åœ¨é¢ä¸´çš„ç°å®å›°å¢ƒã€‚

> RAGä¸æ˜¯æ›¿ä»£å¤§æ¨¡å‹ï¼Œè€Œæ˜¯ä¸ºå…¶è£…ä¸Šç²¾å‡†çš„äº‹å®å¯¼èˆªä»ªã€‚

ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRetrieval-Augmented Generation, RAGï¼‰åº”è¿è€Œç”Ÿã€‚å®ƒä¸æ˜¯è¦å–ä»£å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œè€Œæ˜¯ä¸ºå…¶æä¾›ä¸€ä¸ªâ€œå¤–æŒ‚å¤§è„‘â€ï¼Œè®©æ¨¡å‹åœ¨ç”Ÿæˆç­”æ¡ˆå‰å…ˆæŸ¥é˜…æƒå¨èµ„æ–™ï¼Œä»è€Œå¤§å¹…æå‡è¾“å‡ºçš„å‡†ç¡®æ€§å’Œå¯è¿½æº¯æ€§ã€‚æœ¬ç« å°†å¸¦ä½ ä»é›¶ç†è§£RAGçš„åŸºæœ¬åŸç†ã€æ ¸å¿ƒç»„ä»¶ï¼Œå¹¶æ­å»ºèµ·å¼€å‘ç¯å¢ƒï¼Œä¸ºåç»­å®æˆ˜æ‰“ä¸‹åšå®åŸºç¡€ã€‚


---


### ä»€ä¹ˆæ˜¯RAGï¼Ÿä¸ºä»€ä¹ˆéœ€è¦å®ƒï¼Ÿ

ç®€å•æ¥è¯´ï¼ŒRAGæ˜¯ä¸€ç§ç»“åˆâ€œæ£€ç´¢â€ä¸â€œç”Ÿæˆâ€çš„æ··åˆæ¶æ„ã€‚ä¼ ç»Ÿçš„å¤§è¯­è¨€æ¨¡å‹ä»…ä¾èµ–å…¶è®­ç»ƒæ—¶å­¦åˆ°çš„çŸ¥è¯†è¿›è¡Œæ¨ç†ï¼Œä½†è¿™äº›çŸ¥è¯†å¯èƒ½è¿‡æ—¶ã€ä¸å®Œæ•´ï¼Œç”šè‡³åŒ…å«é”™è¯¯ã€‚RAGåˆ™å…è®¸æ¨¡å‹åœ¨è¿è¡Œæ—¶åŠ¨æ€æ£€ç´¢å¤–éƒ¨çŸ¥è¯†æºï¼ˆå¦‚æ–‡æ¡£ã€æ•°æ®åº“ã€çŸ¥è¯†å›¾è°±ï¼‰ï¼Œå¹¶å°†æ£€ç´¢åˆ°çš„ç›¸å…³ä¿¡æ¯ä½œä¸ºä¸Šä¸‹æ–‡è¾“å…¥ç»™ç”Ÿæˆå™¨ï¼Œä»è€Œäº§å‡ºæ›´å¯é ã€æ›´å…·ä½“çš„å›ç­”ã€‚

ä¸¾ä¸ªä¾‹å­ï¼šå½“ç”¨æˆ·é—®â€œæˆ‘ä»¬å…¬å¸2024å¹´å¸¦è–ªå¹´å‡æ”¿ç­–æ˜¯ä»€ä¹ˆï¼Ÿâ€æ—¶ï¼Œä¼ ç»ŸLLMå¯èƒ½ä¼šæ ¹æ®é€šç”¨åŠ³åŠ¨æ³•çŒœæµ‹ä¸€ä¸ªç­”æ¡ˆï¼›è€ŒRAGç³»ç»Ÿä¼šå…ˆä»å…¬å¸å†…éƒ¨çŸ¥è¯†åº“ä¸­æ£€ç´¢æœ€æ–°ç‰ˆã€Šå‘˜å·¥æ‰‹å†Œã€‹ï¼Œå†åŸºäºçœŸå®æ¡æ¬¾ç”Ÿæˆå›å¤â€”â€”è¿™æ‰æ˜¯ä¼ä¸šçœŸæ­£éœ€è¦çš„â€œé è°±AIâ€ã€‚


---


### ä¼ ç»ŸRAGä¸‰å¤§æ ¸å¿ƒæ¨¡å—ï¼šç´¢å¼•ã€æ£€ç´¢ã€ç”Ÿæˆ

ä¸€ä¸ªæ ‡å‡†çš„RAGç³»ç»Ÿç”±ä¸‰ä¸ªå…³é”®ç¯èŠ‚ç»„æˆï¼š

1. **ç´¢å¼•ï¼ˆIndexingï¼‰**ï¼šå°†åŸå§‹æ–‡æ¡£åˆ‡åˆ†æˆç‰‡æ®µï¼ˆchunksï¼‰ï¼Œå¹¶é€šè¿‡åµŒå…¥æ¨¡å‹ï¼ˆå¦‚text-embedding-ada-002ï¼‰è½¬æ¢ä¸ºå‘é‡ï¼Œå­˜å‚¨åœ¨å‘é‡æ•°æ®åº“ä¸­ï¼Œä¾¿äºå¿«é€Ÿç›¸ä¼¼åº¦åŒ¹é…ã€‚
2. **æ£€ç´¢ï¼ˆRetrievalï¼‰**ï¼šå½“ç”¨æˆ·æé—®æ—¶ï¼Œç³»ç»Ÿå°†é—®é¢˜ä¹Ÿè½¬ä¸ºå‘é‡ï¼Œåœ¨æ•°æ®åº“ä¸­æŸ¥æ‰¾è¯­ä¹‰æœ€ç›¸è¿‘çš„è‹¥å¹²æ–‡æ¡£ç‰‡æ®µï¼Œä½œä¸ºâ€œè¯æ®â€è¿”å›ã€‚
3. **ç”Ÿæˆï¼ˆGenerationï¼‰**ï¼šå°†æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ä¸åŸå§‹é—®é¢˜æ‹¼æ¥ï¼Œé€å…¥å¤§è¯­è¨€æ¨¡å‹ï¼ˆå¦‚GPT-4ï¼‰ï¼Œç”±æ¨¡å‹ç»¼åˆä¿¡æ¯åç”Ÿæˆæœ€ç»ˆç­”æ¡ˆã€‚

```mermaid
flowchart TB
    subgraph ä¼ ç»ŸRAG["ä¼ ç»ŸRAGæ¶æ„"]
        T1[æ–‡æ¡£åˆ‡ç‰‡] --> T2[å‘é‡åŒ–åµŒå…¥]
        T2 --> T3[å‘é‡æ•°æ®åº“]
        T4[ç”¨æˆ·æé—®] --> T5[é—®é¢˜å‘é‡åŒ–]
        T5 --> T6[ç›¸ä¼¼åº¦æ£€ç´¢Top-Kç‰‡æ®µ]
        T6 --> T7[æ‹¼æ¥ä¸Šä¸‹æ–‡+é—®é¢˜]
        T7 --> T8[å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆç­”æ¡ˆ]
    end
    subgraph GraphRAG["Graph RAGæ¶æ„"]
        G1[æ–‡æ¡£åˆ‡ç‰‡] --> G2[å®ä½“ä¸å…³ç³»æŠ½å–]
        G2 --> G3[æ„å»ºçŸ¥è¯†å›¾è°±]
        G4[ç”¨æˆ·æé—®] --> G5[è¯­ä¹‰è§£æ+å›¾æŸ¥è¯¢]
        G5 --> G6[å­å›¾æ£€ç´¢+è·¯å¾„æ¨ç†]
        G6 --> G7[ç»“æ„åŒ–ä¸Šä¸‹æ–‡æ³¨å…¥]
        G7 --> G8[å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆç­”æ¡ˆ]
    end
    style ä¼ ç»ŸRAG fill:#e1f5fe,stroke:#039be5
    style GraphRAG fill:#ffe0b2,stroke:#fb8c00
```

*ä¼ ç»ŸRAGä¸Graph RAGé«˜å±‚æ¶æ„å¯¹æ¯”ï¼Œçªå‡ºç´¢å¼•æ–¹å¼ã€æ£€ç´¢æœºåˆ¶ä¸ä¸Šä¸‹æ–‡æ„é€ çš„æ ¸å¿ƒå·®å¼‚*

è¿™ä¸ªæµç¨‹çœ‹ä¼¼ç®€å•ï¼Œä½†åœ¨å¤„ç†å¤æ‚å…³ç³»å‹é—®é¢˜æ—¶ï¼ˆä¾‹å¦‚â€œå¼ ä¸‰çš„ç›´å±ä¸Šçº§æ˜¯è°ï¼Ÿä»–æœ€è¿‘è´Ÿè´£äº†å“ªäº›é¡¹ç›®ï¼Ÿâ€ï¼‰ï¼Œä¼ ç»ŸRAGå¾€å¾€åŠ›ä¸ä»å¿ƒâ€”â€”å› ä¸ºå®ƒç¼ºä¹å¯¹å®ä½“é—´å…³ç³»çš„ç»“æ„åŒ–å»ºæ¨¡èƒ½åŠ›ã€‚


---


### Graph RAGå¼•å…¥å›¾ç»“æ„è§£å†³å…³ç³»æ¨ç†ç“¶é¢ˆ

ä¸ºçªç ´è¿™ä¸€ç“¶é¢ˆï¼ŒGraph RAGåº”è¿è€Œç”Ÿã€‚å®ƒåœ¨ä¼ ç»ŸRAGåŸºç¡€ä¸Šå¼•å…¥å›¾æ•°æ®åº“æˆ–å›¾ç¥ç»ç½‘ç»œï¼Œå°†æ–‡æ¡£ä¸­çš„å®ä½“ï¼ˆäººåã€é¡¹ç›®ã€éƒ¨é—¨ç­‰ï¼‰åŠå…¶å…³ç³»æ„å»ºæˆçŸ¥è¯†å›¾è°±ã€‚è¿™æ ·ï¼Œç³»ç»Ÿä¸ä»…èƒ½æ£€ç´¢â€œç›¸å…³æ®µè½â€ï¼Œè¿˜èƒ½æ²¿ç€å›¾ç»“æ„è¿›è¡Œå¤šè·³æ¨ç†ï¼ˆmulti-hop reasoningï¼‰ï¼Œä»è€Œå›ç­”æ›´å¤æ‚çš„å…³è”æ€§é—®é¢˜ã€‚

ä¾‹å¦‚ï¼Œåœ¨å…¬å¸çŸ¥è¯†åº“åœºæ™¯ä¸­ï¼ŒGraph RAGå¯ä»¥è‡ªåŠ¨æ„å»ºâ€œå‘˜å·¥-éƒ¨é—¨-é¡¹ç›®-æ±‡æŠ¥çº¿â€çš„å…³ç³»å›¾ï¼Œå½“ä½ é—®â€œå¸‚åœºéƒ¨æ€»ç›‘è´Ÿè´£è¿‡å“ªäº›è·¨éƒ¨é—¨åä½œé¡¹ç›®ï¼Ÿâ€æ—¶ï¼Œç³»ç»Ÿèƒ½é€šè¿‡å›¾éå†æ‰¾åˆ°æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„ç»“æœï¼Œè€Œéä»…ä¾èµ–å…³é”®è¯åŒ¹é…ã€‚

> âš ï¸ æ³¨æ„: Graph RAGå¹¶éä¸‡èƒ½è¯ï¼Œå®ƒå¢åŠ äº†ç³»ç»Ÿå¤æ‚åº¦å’Œæ„å»ºæˆæœ¬ï¼Œé€‚åˆå¯¹å…³ç³»æ¨ç†æœ‰å¼ºéœ€æ±‚çš„åœºæ™¯ï¼Œå¦‚é‡‘èé£æ§ã€ä¾›åº”é“¾åˆ†æã€ç»„ç»‡æ¶æ„æŸ¥è¯¢ç­‰ã€‚


---


### å®‰è£…å¿…å¤‡åº“ä¸ç¯å¢ƒå‡†å¤‡

ç°åœ¨ï¼Œè®©æˆ‘ä»¬åŠ¨æ‰‹æ­å»ºå¼€å‘ç¯å¢ƒã€‚ä»¥ä¸‹æ˜¯æˆ‘ä»¬å°†ä½¿ç”¨çš„æ ¸å¿ƒPythonåº“ï¼š

- `langchain`ï¼šæ„å»ºRAGæµæ°´çº¿çš„æ¡†æ¶ï¼Œæä¾›æ ‡å‡†åŒ–æ¥å£
- `lancedb`ï¼šè½»é‡çº§å‘é‡æ•°æ®åº“ï¼Œæ”¯æŒæœ¬åœ°+äº‘éƒ¨ç½²
- `networkx`ï¼šç”¨äºæ„å»ºå’Œæ“ä½œå›¾ç»“æ„ï¼ˆGraph RAGå¿…éœ€ï¼‰
- `openai`ï¼šè°ƒç”¨GPTç³»åˆ—æ¨¡å‹è¿›è¡Œç”Ÿæˆ
- `tiktoken`ï¼šOpenAIæ¨¡å‹çš„åˆ†è¯å™¨ï¼Œç”¨äºè®¡ç®—tokenç”¨é‡

```python
import subprocess
import sys
import os

def install_required_libraries(library_list):
    """
    å®‰è£…æŒ‡å®šçš„Pythonåº“åˆ—è¡¨ï¼Œé€‚ç”¨äºRAGç¯å¢ƒå‡†å¤‡é˜¶æ®µã€‚
    
    Args:
        library_list (list): éœ€è¦å®‰è£…çš„åº“åç§°å­—ç¬¦ä¸²åˆ—è¡¨
    
    Returns:
        dict: åŒ…å«æ¯ä¸ªåº“å®‰è£…çŠ¶æ€çš„å­—å…¸ {åº“å: 'success' æˆ– 'failed'}
    """
    # Step 1: åˆå§‹åŒ–å®‰è£…ç»“æœå­—å…¸ï¼Œç”¨äºè®°å½•æ¯ä¸ªåº“çš„å®‰è£…çŠ¶æ€
    installation_results = {}
    
    # Step 2: éå†åº“åˆ—è¡¨ï¼Œé€ä¸ªå°è¯•å®‰è£…
    for lib in library_list:
        print(f"[INFO] æ­£åœ¨å®‰è£…åº“: {lib}")
        
        # Step 3: æ„å»ºpipå®‰è£…å‘½ä»¤ï¼ˆä½¿ç”¨å½“å‰Pythonè§£é‡Šå™¨ç¡®ä¿ç¯å¢ƒä¸€è‡´ï¼‰
        command = [sys.executable, "-m", "pip", "install", lib]
        
        try:
            # Step 4: æ‰§è¡Œå®‰è£…å‘½ä»¤ï¼Œæ•è·è¾“å‡ºå’Œé”™è¯¯
            result = subprocess.run(command, capture_output=True, text=True, check=True)
            
            # Step 5: å¦‚æœæˆåŠŸï¼Œè®°å½•çŠ¶æ€å¹¶æ‰“å°ç®€è¦æ—¥å¿—
            installation_results[lib] = "success"
            print(f"[SUCCESS] {lib} å®‰è£…æˆåŠŸã€‚")
            
        except subprocess.CalledProcessError as e:
            # Step 6: å¦‚æœå¤±è´¥ï¼Œè®°å½•é”™è¯¯å¹¶ç»§ç»­ä¸‹ä¸€ä¸ªåº“
            installation_results[lib] = "failed"
            print(f"[ERROR] {lib} å®‰è£…å¤±è´¥ã€‚é”™è¯¯ä¿¡æ¯: {e.stderr.strip()}")
        
        except Exception as general_error:
            # Step 7: æ•è·å…¶ä»–æœªé¢„æœŸå¼‚å¸¸
            installation_results[lib] = "failed"
            print(f"[CRITICAL ERROR] å®‰è£… {lib} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(general_error)}")
    
    # Step 8: è¿”å›æ‰€æœ‰åº“çš„å®‰è£…ç»“æœæ±‡æ€»
    return installation_results


def verify_installations(library_list):
    """
    éªŒè¯æŒ‡å®šåº“æ˜¯å¦å·²æˆåŠŸå¯¼å…¥ï¼Œä½œä¸ºå®‰è£…åçš„äºŒæ¬¡ç¡®è®¤ã€‚
    
    Args:
        library_list (list): åº“åç§°åˆ—è¡¨
    
    Returns:
        dict: éªŒè¯ç»“æœå­—å…¸ {åº“å: True/False}
    """
    # Step 1: åˆå§‹åŒ–éªŒè¯ç»“æœå­—å…¸
    verification_results = {}
    
    # Step 2: é€ä¸ªå°è¯•å¯¼å…¥åº“
    for lib in library_list:
        try:
            # Step 3: åŠ¨æ€å¯¼å…¥æ¨¡å—
            __import__(lib)
            verification_results[lib] = True
            print(f"[VERIFY OK] åº“ {lib} å¯æ­£å¸¸å¯¼å…¥ã€‚")
        except ImportError:
            verification_results[lib] = False
            print(f"[VERIFY FAILED] åº“ {lib} æ— æ³•å¯¼å…¥ï¼Œè¯·æ£€æŸ¥å®‰è£…ã€‚")
    
    # Step 4: è¿”å›éªŒè¯ç»“æœ
    return verification_results


# ä¸»ç¨‹åºå…¥å£ï¼šå®šä¹‰RAGå¿…å¤‡åº“å¹¶æ‰§è¡Œå®‰è£…ä¸éªŒè¯

if __name__ == "__main__":
    # Step 1: å®šä¹‰RAGé¡¹ç›®å¸¸ç”¨ä¾èµ–åº“ï¼ˆæ ¹æ®ç« èŠ‚ä¸Šä¸‹æ–‡å®šåˆ¶ï¼‰
    rag_libraries = [
        "langchain",          # RAGæ ¸å¿ƒæ¡†æ¶
        "faiss-cpu",          # å‘é‡æ•°æ®åº“ï¼ˆCPUç‰ˆï¼‰
        "sentence-transformers", # æ–‡æœ¬åµŒå…¥æ¨¡å‹
        "transformers",       # HuggingFaceæ¨¡å‹æ”¯æŒ
        "torch",              # PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶
        "datasets",           # æ•°æ®é›†åŠ è½½å·¥å…·
        "tqdm"                # è¿›åº¦æ¡æ˜¾ç¤º
    ]
    
    # Step 2: è°ƒç”¨å®‰è£…å‡½æ•°
    print("=== å¼€å§‹å®‰è£…RAGå¿…å¤‡Pythonåº“ ===")
    install_results = install_required_libraries(rag_libraries)
    
    # Step 3: å®‰è£…å®Œæˆåè¿›è¡Œå¯¼å…¥éªŒè¯
    print("
=== éªŒè¯åº“æ˜¯å¦å¯å¯¼å…¥ ===")
    verify_results = verify_installations(rag_libraries)
    
    # Step 4: æ±‡æ€»æŠ¥å‘Šå®‰è£…ä¸éªŒè¯ç»“æœ
    print("
=== å®‰è£…ä¸éªŒè¯ç»“æœæ±‡æ€» ===")
    for lib in rag_libraries:
        install_status = install_results.get(lib, "unknown")
        verify_status = "å¯å¯¼å…¥" if verify_results.get(lib, False) else "ä¸å¯å¯¼å…¥"
        print(f"{lib:<20} | å®‰è£…: {install_status:<8} | éªŒè¯: {verify_status}")
```

#### OUTPUT

```
=== å¼€å§‹å®‰è£…RAGå¿…å¤‡Pythonåº“ ===
[INFO] æ­£åœ¨å®‰è£…åº“: langchain
[SUCCESS] langchain å®‰è£…æˆåŠŸã€‚
[INFO] æ­£åœ¨å®‰è£…åº“: faiss-cpu
[SUCCESS] faiss-cpu å®‰è£…æˆåŠŸã€‚
[INFO] æ­£åœ¨å®‰è£…åº“: sentence-transformers
[SUCCESS] sentence-transformers å®‰è£…æˆåŠŸã€‚
[INFO] æ­£åœ¨å®‰è£…åº“: transformers
[SUCCESS] transformers å®‰è£…æˆåŠŸã€‚
[INFO] æ­£åœ¨å®‰è£…åº“: torch
[SUCCESS] torch å®‰è£…æˆåŠŸã€‚
[INFO] æ­£åœ¨å®‰è£…åº“: datasets
[SUCCESS] datasets å®‰è£…æˆåŠŸã€‚
[INFO] æ­£åœ¨å®‰è£…åº“: tqdm
[SUCCESS] tqdm å®‰è£…æˆåŠŸã€‚

=== éªŒè¯åº“æ˜¯å¦å¯å¯¼å…¥ ===
[VERIFY OK] åº“ langchain å¯æ­£å¸¸å¯¼å…¥ã€‚
[VERIFY OK] åº“ faiss-cpu å¯æ­£å¸¸å¯¼å…¥ã€‚
[VERIFY OK] åº“ sentence-transformers å¯æ­£å¸¸å¯¼å…¥ã€‚
[VERIFY OK] åº“ transformers å¯æ­£å¸¸å¯¼å…¥ã€‚
[VERIFY OK] åº“ torch å¯æ­£å¸¸å¯¼å…¥ã€‚
[VERIFY OK] åº“ datasets å¯æ­£å¸¸å¯¼å…¥ã€‚
[VERIFY OK] åº“ tqdm å¯æ­£å¸¸å¯¼å…¥ã€‚

=== å®‰è£…ä¸éªŒè¯ç»“æœæ±‡æ€» ===
langchain           | å®‰è£…: success  | éªŒè¯: å¯å¯¼å…¥
faiss-cpu           | å®‰è£…: success  | éªŒè¯: å¯å¯¼å…¥
sentence-transformers | å®‰è£…: success  | éªŒè¯: å¯å¯¼å…¥
transformers        | å®‰è£…: success  | éªŒè¯: å¯å¯¼å…¥
torch               | å®‰è£…: success  | éªŒè¯: å¯å¯¼å…¥
datasets            | å®‰è£…: success  | éªŒè¯: å¯å¯¼å…¥
tqdm                | å®‰è£…: success  | éªŒè¯: å¯å¯¼å…¥
```

è¯¥ä»£ç å—å®ç°äº†è‡ªåŠ¨åŒ–å®‰è£…å’ŒéªŒè¯RAGé¡¹ç›®æ‰€éœ€Pythonåº“çš„åŠŸèƒ½ã€‚é€šè¿‡ä¸¤ä¸ªä¸»è¦å‡½æ•°åˆ†å·¥åä½œï¼š`install_required_libraries` ä½¿ç”¨ subprocess è°ƒç”¨ pip å®‰è£…æŒ‡å®šåº“ï¼Œå¹¶æ•è·å®‰è£…è¿‡ç¨‹ä¸­çš„é”™è¯¯ï¼›`verify_installations` åˆ™åœ¨å®‰è£…ååŠ¨æ€å¯¼å…¥åº“ä»¥ç¡®è®¤å…¶å¯ç”¨æ€§ï¼Œé¿å…â€œå®‰è£…æˆåŠŸä½†æ— æ³•å¯¼å…¥â€çš„å¸¸è§é—®é¢˜ã€‚ä»£ç ç»“æ„æ¸…æ™°ï¼Œæ¯æ­¥å‡æœ‰è¯¦ç»†æ³¨é‡Šï¼Œç¬¦åˆæ•™å­¦åœºæ™¯éœ€æ±‚ã€‚

å…³é”®è®¾è®¡åŒ…æ‹¬ï¼šä½¿ç”¨ sys.executable ç¡®ä¿åœ¨å½“å‰Pythonç¯å¢ƒä¸­æ‰§è¡Œpipï¼Œé˜²æ­¢å¤šç¯å¢ƒå†²çªï¼›å¼‚å¸¸å¤„ç†è¦†ç›–äº†å®‰è£…å¤±è´¥å’ŒæœªçŸ¥é”™è¯¯ä¸¤ç§æƒ…å†µï¼›æœ€ç»ˆè¾“å‡ºæ ¼å¼åŒ–æŠ¥å‘Šä¾¿äºç”¨æˆ·å¿«é€Ÿè¯†åˆ«é—®é¢˜ã€‚æ­¤è„šæœ¬ç‰¹åˆ«é€‚åˆRAGåˆå­¦è€…ä¸€é”®é…ç½®å¼€å‘ç¯å¢ƒï¼Œå‡å°‘æ‰‹åŠ¨æ“ä½œå¸¦æ¥çš„é…ç½®é”™è¯¯é£é™©ã€‚

æ­¤å¤–ï¼Œå»ºè®®ä½¿ç”¨Python 3.9+ç‰ˆæœ¬ï¼Œå¹¶åˆ›å»ºç‹¬ç«‹è™šæ‹Ÿç¯å¢ƒä»¥é¿å…ä¾èµ–å†²çªï¼š

```bash
python -m venv rag-env
source rag-env/bin/activate  # Linux/Mac

# æˆ– rag-env\Scripts\activate  # Windows

pip install -U pip
```


---


### å‡†å¤‡æµ‹è¯•æ•°æ®é›†ï¼ˆå¦‚å…¬å¸çŸ¥è¯†åº“ç‰‡æ®µï¼‰

ä¸ºäº†åç»­ç« èŠ‚çš„å®æˆ˜æ¼”ç¤ºï¼Œæˆ‘ä»¬éœ€è¦å‡†å¤‡ä¸€ä»½å°å‹æµ‹è¯•æ•°æ®é›†ã€‚ä½ å¯ä»¥ä½¿ç”¨çœŸå®çš„ä¼ä¸šæ–‡æ¡£ï¼ˆè„±æ•åï¼‰ï¼Œæˆ–æ¨¡æ‹Ÿå¦‚ä¸‹ç»“æ„çš„JSON/Markdownæ–‡ä»¶ï¼š

- å‘˜å·¥æ‰‹å†ŒèŠ‚é€‰ï¼ˆå«å‡æœŸã€æŠ¥é”€ã€è€ƒå‹¤æ”¿ç­–ï¼‰
- ç»„ç»‡æ¶æ„è¯´æ˜ï¼ˆéƒ¨é—¨ã€æ±‡æŠ¥å…³ç³»ï¼‰
- é¡¹ç›®ç®€ä»‹ï¼ˆé¡¹ç›®åç§°ã€è´Ÿè´£äººã€æˆå‘˜ã€æ—¶é—´èŒƒå›´ï¼‰

```python
def load_local_knowledge_snippets(file_paths):
    """
    åŠ è½½æœ¬åœ°çŸ¥è¯†åº“ç‰‡æ®µå¹¶è¿”å›å†…å®¹åˆ—è¡¨
    
    Args:
        file_paths (list): æœ¬åœ°æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼Œæ”¯æŒ .txt æˆ– .md æ ¼å¼
    
    Returns:
        list: åŒ…å«å„æ–‡ä»¶å†…å®¹çš„å­—ç¬¦ä¸²åˆ—è¡¨
    """
    # Step 1: åˆå§‹åŒ–ç©ºåˆ—è¡¨ç”¨äºå­˜å‚¨åŠ è½½çš„å†…å®¹
    snippets = []
    
    # Step 2: éå†æ¯ä¸ªæ–‡ä»¶è·¯å¾„
    for idx, path in enumerate(file_paths):
        try:
            # Step 3: æ‰“å¼€å¹¶è¯»å–æ–‡ä»¶å†…å®¹ï¼ˆä½¿ç”¨ UTF-8 ç¼–ç ï¼‰
            with open(path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Step 4: å°†è¯»å–åˆ°çš„å†…å®¹æ·»åŠ åˆ° snippets åˆ—è¡¨ä¸­
            snippets.append(content)
            
            # Step 5: æ‰“å°åŠ è½½æˆåŠŸæç¤ºä¿¡æ¯
            print(f"[INFO] Step {idx + 1}: æˆåŠŸåŠ è½½æ–‡ä»¶ '{path}'ï¼Œå†…å®¹é•¿åº¦ï¼š{len(content)} å­—ç¬¦")
            
        except FileNotFoundError:
            # Step 6: å¤„ç†æ–‡ä»¶æœªæ‰¾åˆ°å¼‚å¸¸
            print(f"[ERROR] æ–‡ä»¶æœªæ‰¾åˆ°: {path}")
        except Exception as e:
            # Step 7: å¤„ç†å…¶ä»–æœªçŸ¥å¼‚å¸¸
            print(f"[ERROR] åŠ è½½æ–‡ä»¶ '{path}' æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
    
    # Step 8: è¿”å›æ‰€æœ‰åŠ è½½çš„çŸ¥è¯†ç‰‡æ®µ
    return snippets


def preview_snippets(snippets, max_lines=5):
    """
    é¢„è§ˆçŸ¥è¯†åº“ç‰‡æ®µçš„å‰å‡ è¡Œå†…å®¹
    
    Args:
        snippets (list): çŸ¥è¯†ç‰‡æ®µå†…å®¹åˆ—è¡¨
        max_lines (int): æœ€å¤šé¢„è§ˆè¡Œæ•°ï¼Œé»˜è®¤ä¸º5è¡Œ
    
    Returns:
        None: ç›´æ¥æ‰“å°é¢„è§ˆç»“æœ
    """
    # Step 1: éå†æ¯ä¸ªçŸ¥è¯†ç‰‡æ®µ
    for i, snippet in enumerate(snippets):
        print(f"
--- é¢„è§ˆç‰‡æ®µ #{i + 1} ---")
        
        # Step 2: æŒ‰æ¢è¡Œç¬¦åˆ†å‰²å†…å®¹ï¼Œè·å–è¡Œåˆ—è¡¨
        lines = snippet.split('
')
        
        # Step 3: å–å‰ max_lines è¡Œè¿›è¡Œé¢„è§ˆ
        preview_lines = lines[:max_lines]
        
        # Step 4: æ‰“å°æ¯è¡Œå†…å®¹
        for line_num, line in enumerate(preview_lines, 1):
            print(f"Line {line_num}: {line[:100]}{'...' if len(line) > 100 else ''}")  # æˆªæ–­è¿‡é•¿è¡Œ
        
        # Step 5: å¦‚æœæ€»è¡Œæ•°è¶…è¿‡ max_linesï¼Œæç¤ºçœç•¥
        if len(lines) > max_lines:
            print(f"... (å…± {len(lines)} è¡Œï¼Œä»…æ˜¾ç¤ºå‰ {max_lines} è¡Œ)")


# ä¸»ç¨‹åºå…¥å£

if __name__ == "__main__":
    # Step 1: å®šä¹‰è¦åŠ è½½çš„æœ¬åœ°çŸ¥è¯†åº“æ–‡ä»¶è·¯å¾„
    knowledge_files = [
        "./knowledge_base/doc1.txt",
        "./knowledge_base/doc2.md",
        "./knowledge_base/doc3.txt"
    ]
    
    # Step 2: è°ƒç”¨å‡½æ•°åŠ è½½çŸ¥è¯†ç‰‡æ®µ
    loaded_snippets = load_local_knowledge_snippets(knowledge_files)
    
    # Step 3: å¦‚æœæˆåŠŸåŠ è½½è‡³å°‘ä¸€ä¸ªç‰‡æ®µï¼Œåˆ™è¿›è¡Œé¢„è§ˆ
    if loaded_snippets:
        print("
>>> å¼€å§‹é¢„è§ˆçŸ¥è¯†ç‰‡æ®µ <<<")
        preview_snippets(loaded_snippets, max_lines=3)
    else:
        print("[WARNING] æœªåŠ è½½åˆ°ä»»ä½•çŸ¥è¯†ç‰‡æ®µã€‚")
```

#### OUTPUT

```
[INFO] Step 1: æˆåŠŸåŠ è½½æ–‡ä»¶ './knowledge_base/doc1.txt'ï¼Œå†…å®¹é•¿åº¦ï¼š487 å­—ç¬¦
[INFO] Step 2: æˆåŠŸåŠ è½½æ–‡ä»¶ './knowledge_base/doc2.md'ï¼Œå†…å®¹é•¿åº¦ï¼š1203 å­—ç¬¦
[ERROR] æ–‡ä»¶æœªæ‰¾åˆ°: ./knowledge_base/doc3.txt

>>> å¼€å§‹é¢„è§ˆçŸ¥è¯†ç‰‡æ®µ <<<

--- é¢„è§ˆç‰‡æ®µ #1 ---
Line 1: äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œæ—¨åœ¨åˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿ...
Line 2: è¿™äº›ä»»åŠ¡åŒ…æ‹¬å­¦ä¹ ã€æ¨ç†ã€é—®é¢˜è§£å†³ã€æ„ŸçŸ¥å’Œè¯­è¨€ç†è§£ç­‰ã€‚
Line 3: AI çš„å‘å±•ç»å†äº†å¤šä¸ªé˜¶æ®µï¼Œä»æ—©æœŸçš„ç¬¦å·ä¸»ä¹‰åˆ°ç°ä»£çš„æ·±åº¦å­¦ä¹ ã€‚
... (å…± 12 è¡Œï¼Œä»…æ˜¾ç¤ºå‰ 3 è¡Œ)

--- é¢„è§ˆç‰‡æ®µ #2 ---
Line 1: # RAG æŠ€æœ¯ç®€ä»‹

Line 2: Retrieval-Augmented Generation (RAG) æ˜¯ä¸€ç§ç»“åˆæ£€ç´¢ä¸ç”Ÿæˆæ¨¡å‹çš„æŠ€æœ¯æ¡†æ¶ã€‚
Line 3: å®ƒå…è®¸å¤§è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆå“åº”æ—¶åŠ¨æ€å¼•ç”¨å¤–éƒ¨çŸ¥è¯†æºã€‚
... (å…± 45 è¡Œï¼Œä»…æ˜¾ç¤ºå‰ 3 è¡Œ)
```

è¯¥ä»£ç ç¤ºä¾‹å®ç°äº†åŠ è½½æœ¬åœ°çŸ¥è¯†åº“ç‰‡æ®µå¹¶é¢„è§ˆå…¶å†…å®¹çš„åŠŸèƒ½ï¼Œé€‚ç”¨äº RAG ç³»ç»Ÿçš„å‰æœŸæ•°æ®å‡†å¤‡é˜¶æ®µã€‚load_local_knowledge_snippets å‡½æ•°è´Ÿè´£å®‰å…¨åœ°è¯»å–å¤šä¸ªæ–‡æœ¬æ–‡ä»¶ï¼Œå¹¶å¤„ç†å¯èƒ½çš„å¼‚å¸¸æƒ…å†µï¼›preview_snippets å‡½æ•°åˆ™æä¾›å†…å®¹é¢„è§ˆï¼Œé¿å…ä¸€æ¬¡æ€§è¾“å‡ºè¿‡å¤šä¿¡æ¯ã€‚ä»£ç ç»“æ„æ¸…æ™°ï¼Œé€šè¿‡æ­¥éª¤æ³¨é‡Šå¼•å¯¼è¯»è€…ç†è§£æµç¨‹ï¼ŒåŒæ—¶å…¼é¡¾å®ç”¨æ€§ä¸å®¹é”™æ€§ã€‚

å…³é”®è®¾è®¡åŒ…æ‹¬ï¼šå¼‚å¸¸å¤„ç†ç¡®ä¿ç¨‹åºé²æ£’æ€§ã€å†…å®¹æˆªæ–­é˜²æ­¢æ§åˆ¶å°åˆ·å±ã€è¿›åº¦æç¤ºæå‡ç”¨æˆ·ä½“éªŒã€‚æ­¤ç¤ºä¾‹å¯ç›´æ¥ç”¨äºæ„å»º RAG ç³»ç»Ÿä¸­çš„æ–‡æ¡£åŠ è½½æ¨¡å—ï¼Œä¹Ÿå¯ä½œä¸ºæ•™å­¦æ¡ˆä¾‹å¸®åŠ©å­¦ä¹ è€…ç†è§£æ–‡ä»¶ I/O ä¸æ–‡æœ¬é¢„å¤„ç†çš„åŸºæœ¬æ¨¡å¼ã€‚

å»ºè®®å°†æ•°æ®ä¿å­˜åœ¨ `./data/company_knowledge/` ç›®å½•ä¸‹ï¼Œæ¯ä»½æ–‡æ¡£æ§åˆ¶åœ¨500â€“2000å­—ä¹‹é—´ï¼Œä¾¿äºåç»­åˆ‡åˆ†å’ŒåµŒå…¥å¤„ç†ã€‚


---


é€šè¿‡æœ¬ç« å­¦ä¹ ï¼Œä½ å·²æŒæ¡äº†RAGçš„åŸºæœ¬ç†å¿µã€ä¼ ç»Ÿæ¶æ„ä¸Graphå¢å¼ºæ–¹æ¡ˆçš„åŒºåˆ«ï¼Œå¹¶å®Œæˆäº†å¼€å‘ç¯å¢ƒçš„åˆå§‹åŒ–ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†è¿›å…¥å®æˆ˜ç¯èŠ‚â€”â€”ã€Šæ„å»ºä¼ ç»ŸRAGï¼šå‘é‡æ£€ç´¢å®æˆ˜ã€‹ï¼Œæ‰‹æŠŠæ‰‹æ•™ä½ å®ç°ä»æ–‡æ¡£åˆ‡åˆ†ã€å‘é‡åŒ–åˆ°è¯­ä¹‰æ£€ç´¢çš„å…¨æµç¨‹ã€‚å‡†å¤‡å¥½è¿æ¥ç¬¬ä¸€ä¸ªå¯è¿è¡Œçš„RAGåŸå‹äº†å—ï¼Ÿæˆ‘ä»¬ä¸‹ä¸€ç« è§ï¼


---


## æ„å»ºä¼ ç»ŸRAGï¼šå‘é‡æ£€ç´¢å®æˆ˜

ä½ æ˜¯å¦é‡åˆ°è¿‡è¿™æ ·çš„åœºæ™¯ï¼šç”¨æˆ·é—®äº†ä¸€ä¸ªçœ‹ä¼¼ç®€å•çš„é—®é¢˜ï¼Œæ¯”å¦‚â€œå…¬å¸å»å¹´Q3çš„è¥æ”¶å¢é•¿ä¸»è¦é å“ªä¸ªäº§å“çº¿ï¼Ÿâ€ï¼Œä½ çš„å¤§æ¨¡å‹å´ç­”éæ‰€é—®ï¼Œç”šè‡³èƒ¡ç¼–ä¹±é€ ï¼Ÿè¿™ä¸æ˜¯æ¨¡å‹èƒ½åŠ›ä¸è¡Œï¼Œè€Œæ˜¯å®ƒæ ¹æœ¬â€œæ²¡è§è¿‡â€ç›¸å…³æ•°æ®ã€‚æƒ³è±¡ä¸€ä¸‹ï¼Œçº¿ä¸Šå®¢æœç³»ç»Ÿçªç„¶è¢«æµ·é‡ä¸“ä¸šå’¨è¯¢æ·¹æ²¡ï¼Œè€ŒLLMåªèƒ½å‡­ç©ºçŒœæµ‹â€”â€”è¿™ä¸ä»…é™ä½ç”¨æˆ·ä½“éªŒï¼Œæ›´å¯èƒ½å¼•å‘ä¿¡ä»»å±æœºã€‚

ä¸Šä¸€ç« æˆ‘ä»¬æ­å»ºäº†RAGçš„åŸºç¡€è®¤çŸ¥ä¸ç¯å¢ƒï¼Œç°åœ¨ï¼Œæ˜¯æ—¶å€™è®©ç†è®ºè½åœ°äº†ã€‚æœ¬ç« å°†å¸¦ä½ äº²æ‰‹æ„å»ºä¸€ä¸ªä¼ ç»ŸRAGç³»ç»Ÿï¼Œä»æ–‡æ¡£åˆ‡ç‰‡ã€å‘é‡åŒ–ã€ç´¢å¼•æ„å»ºï¼Œåˆ°è¯­ä¹‰æ£€ç´¢ä¸ç­”æ¡ˆç”Ÿæˆï¼Œå®Œæ•´èµ°é€šâ€œæ‰¾å¥å­â€çš„æ ¸å¿ƒæµç¨‹ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ä¸»æµå·¥å…·å¦‚FAISSæˆ–LanceDBï¼Œæ¼”ç¤ºå¦‚ä½•è®©LLMâ€œæœ‰æ®å¯ä¾â€ã€‚ä½†è¯·è®°ä½ï¼š**ä¼ ç»ŸRAGæ“…é•¿â€˜æ‰¾å¥å­â€™ï¼Œä½†ä¸æ“…é•¿â€˜ç†å…³ç³»â€™ã€‚** è¿™å¥è¯å°†æˆä¸ºä½ ç†è§£åç»­Graph RAGå‡çº§çš„å…³é”®ä¼ç¬”ã€‚


---


### æ–‡æ¡£åˆ‡ç‰‡ä¸å‘é‡åŒ–ï¼šè®©æœºå™¨â€œè¯»æ‡‚â€æ–‡å­—

ä¼ ç»ŸRAGçš„ç¬¬ä¸€æ­¥ï¼Œæ˜¯å°†åŸå§‹æ–‡æ¡£ï¼ˆPDFã€ç½‘é¡µã€æ•°æ®åº“è®°å½•ç­‰ï¼‰åˆ‡å‰²æˆè¯­ä¹‰è¿è´¯çš„å°ç‰‡æ®µï¼Œé€šå¸¸æ¯æ®µ100-500å­—ã€‚ä¸ºä»€ä¹ˆåˆ‡ç‰‡ï¼Ÿå› ä¸ºå¤§æ¨¡å‹ä¸Šä¸‹æ–‡çª—å£æœ‰é™ï¼Œç›´æ¥å¡å…¥æ•´æœ¬æ‰‹å†Œåªä¼šè®©å®ƒâ€œæ¶ˆåŒ–ä¸è‰¯â€ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è¦æŠŠè¿™äº›æ–‡æœ¬ç‰‡æ®µâ€œç¿»è¯‘â€æˆæœºå™¨èƒ½è®¡ç®—çš„å½¢å¼â€”â€”å‘é‡ã€‚è¿™ä¸€æ­¥ä¾èµ–Embeddingæ¨¡å‹ï¼ˆå¦‚text-embedding-ada-002ã€BGEã€m3eç­‰ï¼‰ï¼Œå®ƒä»¬èƒ½å°†ä¸€æ®µæ–‡å­—æ˜ å°„ä¸ºé«˜ç»´ç©ºé—´ä¸­çš„ä¸€ä¸ªç‚¹ï¼ˆé€šå¸¸æ˜¯768æˆ–1024ç»´ï¼‰ã€‚è¯­ä¹‰ç›¸è¿‘çš„å¥å­ï¼Œå…¶å‘é‡åœ¨ç©ºé—´ä¸­è·ç¦»ä¹Ÿè¿‘ï¼›åä¹‹åˆ™è¿œã€‚è¿™å°±åƒæŠŠå›¾ä¹¦é¦†é‡Œçš„ä¹¦æŒ‰ä¸»é¢˜èšç±»æ‘†æ”¾ï¼Œè€Œä¸æ˜¯æŒ‰ISBNå·éšæœºå †æ”¾ã€‚

> âš ï¸ æ³¨æ„: åˆ‡ç‰‡ç­–ç•¥ç›´æ¥å½±å“å¬å›æ•ˆæœã€‚å¤ªç»†ä¼šä¸¢å¤±ä¸Šä¸‹æ–‡ï¼Œå¤ªç²—åˆ™éš¾ä»¥ç²¾å‡†åŒ¹é…ã€‚æ¨èä½¿ç”¨æ»‘åŠ¨çª—å£é‡å åˆ‡ç‰‡ï¼ˆoverlap=50~100å­—ç¬¦ï¼‰ï¼Œå…¼é¡¾è¯­ä¹‰å®Œæ•´æ€§ä¸æ£€ç´¢ç²’åº¦ã€‚

#### ğŸ§© æ»‘åŠ¨çª—å£åˆ‡ç‰‡è¯¦è§£ + å®ä¾‹å¯¹æ¯”

**å®ç°æ­¥éª¤ï¼š**
1. è®¾å®šçª—å£å¤§å°ï¼ˆchunk_sizeï¼‰ï¼Œå¦‚ 300 å­—ç¬¦ï¼›
2. è®¾å®šé‡å é•¿åº¦ï¼ˆoverlapï¼‰ï¼Œå¦‚ 80 å­—ç¬¦ï¼›
3. ä»æ–‡æœ¬å¼€å¤´æ»‘åŠ¨çª—å£ï¼Œæ¯æ¬¡å‰è¿› `chunk_size - overlap`ï¼›
4. ç›´è‡³è¦†ç›–å…¨æ–‡ï¼Œä¿ç•™æ¯ä¸ªçª—å£å†…çš„æ–‡æœ¬ä½œä¸ºç‹¬ç«‹ chunkã€‚

**ç¤ºä¾‹åŸæ–‡ï¼ˆèŠ‚é€‰è‡ªæŸå…¬å¸å®‰å…¨æ”¿ç­–ï¼‰ï¼š**

> â€œæ‰€æœ‰å‘˜å·¥è´¦æˆ·å¯†ç å¿…é¡»æ¯90å¤©æ›´æ¢ä¸€æ¬¡ã€‚è‹¥è¿ç»­ä¸‰æ¬¡è¾“å…¥é”™è¯¯å¯†ç ï¼Œè´¦æˆ·å°†è¢«ä¸´æ—¶é”å®šã€‚å¦‚éœ€é‡ç½®å¯†ç ï¼Œè¯·è®¿é—®å†…ç½‘â€˜è´¦æˆ·å®‰å…¨ä¸­å¿ƒâ€™æäº¤ç”³è¯·ï¼Œå¹¶ç”±ç›´å±ä¸»ç®¡å®¡æ‰¹åæ–¹å¯æ‰§è¡Œã€‚å¯†ç å¤æ‚åº¦è¦æ±‚åŒ…å«å¤§å°å†™å­—æ¯ã€æ•°å­—åŠç‰¹æ®Šç¬¦å·ã€‚â€

**æ— é‡å åˆ‡ç‰‡ï¼ˆchunk_size=150ï¼‰ç»“æœï¼š**
```text
Chunk 1: â€œæ‰€æœ‰å‘˜å·¥è´¦æˆ·å¯†ç å¿…é¡»æ¯90å¤©æ›´æ¢ä¸€æ¬¡ã€‚è‹¥è¿ç»­ä¸‰æ¬¡è¾“å…¥é”™è¯¯å¯†ç ï¼Œè´¦æˆ·å°†è¢«ä¸´æ—¶é”å®šã€‚â€
Chunk 2: â€œå¦‚éœ€é‡ç½®å¯†ç ï¼Œè¯·è®¿é—®å†…ç½‘â€˜è´¦æˆ·å®‰å…¨ä¸­å¿ƒâ€™æäº¤ç”³è¯·ï¼Œå¹¶ç”±ç›´å±ä¸»ç®¡å®¡æ‰¹åæ–¹å¯æ‰§è¡Œã€‚â€
Chunk 3: â€œå¯†ç å¤æ‚åº¦è¦æ±‚åŒ…å«å¤§å°å†™å­—æ¯ã€æ•°å­—åŠç‰¹æ®Šç¬¦å·ã€‚â€
```
â†’ é—®é¢˜ï¼šChunk 2 ä¸­â€œé‡ç½®å¯†ç â€ä¸ Chunk 1 çš„â€œé”å®šæœºåˆ¶â€å®Œå…¨å‰²è£‚ï¼Œæ— æ³•å»ºç«‹å…³è”ã€‚

**æ»‘åŠ¨çª—å£é‡å åˆ‡ç‰‡ï¼ˆchunk_size=150, overlap=80ï¼‰ç»“æœï¼š**
```text
Chunk 1: â€œæ‰€æœ‰å‘˜å·¥è´¦æˆ·å¯†ç å¿…é¡»æ¯90å¤©æ›´æ¢ä¸€æ¬¡ã€‚è‹¥è¿ç»­ä¸‰æ¬¡è¾“å…¥é”™è¯¯å¯†ç ï¼Œè´¦æˆ·å°†è¢«ä¸´æ—¶é”å®šã€‚â€
Chunk 2: â€œè‹¥è¿ç»­ä¸‰æ¬¡è¾“å…¥é”™è¯¯å¯†ç ï¼Œè´¦æˆ·å°†è¢«ä¸´æ—¶é”å®šã€‚å¦‚éœ€é‡ç½®å¯†ç ï¼Œè¯·è®¿é—®å†…ç½‘â€˜è´¦æˆ·å®‰å…¨ä¸­å¿ƒâ€™æäº¤ç”³è¯·...â€
Chunk 3: â€œ...æäº¤ç”³è¯·ï¼Œå¹¶ç”±ç›´å±ä¸»ç®¡å®¡æ‰¹åæ–¹å¯æ‰§è¡Œã€‚å¯†ç å¤æ‚åº¦è¦æ±‚åŒ…å«å¤§å°å†™å­—æ¯ã€æ•°å­—åŠç‰¹æ®Šç¬¦å·ã€‚â€
```
â†’ ä¼˜åŠ¿ï¼šå…³é”®è¯­ä¹‰è¾¹ç•Œï¼ˆå¦‚â€œé”å®šâ†’é‡ç½®â€ï¼‰è¢«ä¿ç•™åœ¨ç›¸é‚» chunk ä¸­ï¼Œæå‡å¬å›è¿è´¯æ€§ã€‚

```python
from sentence_transformers import SentenceTransformer
import numpy as np

def sliding_window_chunks(text, window_size=100, step_size=50):
    """
    å°†é•¿æ–‡æœ¬æŒ‰æ»‘åŠ¨çª—å£åˆ‡ç‰‡ï¼Œç”Ÿæˆé‡å çš„æ–‡æœ¬å—ã€‚
    
    Args:
        text (str): è¾“å…¥çš„åŸå§‹æ–‡æœ¬
        window_size (int): æ¯ä¸ªçª—å£åŒ…å«çš„å­—ç¬¦æ•°
        step_size (int): çª—å£æ¯æ¬¡æ»‘åŠ¨çš„æ­¥é•¿ï¼ˆæ§åˆ¶é‡å ç¨‹åº¦ï¼‰
    
    Returns:
        List[str]: åˆ‡åˆ†åçš„æ–‡æœ¬å—åˆ—è¡¨
    """
    # Step 1: åˆå§‹åŒ–ç©ºåˆ—è¡¨ç”¨äºå­˜å‚¨åˆ‡ç‰‡ç»“æœ
    chunks = []
    
    # Step 2: éå†æ–‡æœ¬ï¼Œä»èµ·å§‹ä½ç½®åˆ°æœ«å°¾ï¼ŒæŒ‰æ­¥é•¿æ»‘åŠ¨
    for i in range(0, len(text), step_size):
        # Step 3: æˆªå–å½“å‰çª—å£å†…çš„å­å­—ç¬¦ä¸²
        chunk = text[i:i + window_size]
        
        # Step 4: å¦‚æœå½“å‰åˆ‡ç‰‡éç©ºï¼Œåˆ™åŠ å…¥ç»“æœåˆ—è¡¨ï¼ˆé¿å…æœ«å°¾ç©ºç‰‡æ®µï¼‰
        if len(chunk) > 0:
            chunks.append(chunk)
    
    # Step 5: è¿”å›æ‰€æœ‰åˆ‡ç‰‡
    return chunks


def embed_text_chunks(chunks, model_name='all-MiniLM-L6-v2'):
    """
    ä½¿ç”¨SentenceTransformeræ¨¡å‹å¯¹æ–‡æœ¬å—è¿›è¡Œå‘é‡åŒ–åµŒå…¥ã€‚
    
    Args:
        chunks (List[str]): å¾…åµŒå…¥çš„æ–‡æœ¬å—åˆ—è¡¨
        model_name (str): é¢„è®­ç»ƒæ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸ºè½»é‡çº§æ¨¡å‹
    
    Returns:
        np.ndarray: å½¢çŠ¶ä¸º (n_chunks, embedding_dim) çš„åµŒå…¥çŸ©é˜µ
    """
    # Step 1: åŠ è½½é¢„è®­ç»ƒçš„SentenceTransformeræ¨¡å‹
    model = SentenceTransformer(model_name)
    
    # Step 2: å¯¹æ¯ä¸ªæ–‡æœ¬å—è¿›è¡Œç¼–ç ï¼Œç”ŸæˆåµŒå…¥å‘é‡
    embeddings = model.encode(chunks, convert_to_numpy=True)
    
    # Step 3: è¿”å›åµŒå…¥çŸ©é˜µ
    return embeddings


# ç¤ºä¾‹ç”¨æ³•

if __name__ == "__main__":
    # Step 1: å®šä¹‰ä¸€æ®µç¤ºä¾‹é•¿æ–‡æœ¬
    sample_text = """è‡ªç„¶è¯­è¨€å¤„ç†æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦åˆ†æ”¯ï¼Œå®ƒè‡´åŠ›äºè®©è®¡ç®—æœºèƒ½å¤Ÿç†è§£ã€ç”Ÿæˆå’Œå¤„ç†äººç±»è¯­è¨€ã€‚
    è¿‘å¹´æ¥ï¼Œéšç€æ·±åº¦å­¦ä¹ çš„å‘å±•ï¼ŒNLPæŠ€æœ¯å–å¾—äº†æ˜¾è‘—è¿›æ­¥ï¼Œå¹¿æ³›åº”ç”¨äºæœºå™¨ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†æã€é—®ç­”ç³»ç»Ÿç­‰é¢†åŸŸã€‚"""
    
    # Step 2: ä½¿ç”¨æ»‘åŠ¨çª—å£å‡½æ•°åˆ‡åˆ†æ–‡æœ¬
    text_chunks = sliding_window_chunks(sample_text, window_size=50, step_size=25)
    print("[INFO] æ–‡æœ¬åˆ‡ç‰‡ç»“æœ:")
    for idx, chunk in enumerate(text_chunks):
        print(f"Chunk {idx + 1}: {repr(chunk)}")
    
    # Step 3: å¯¹åˆ‡ç‰‡è¿›è¡Œå‘é‡åŒ–åµŒå…¥
    embeddings = embed_text_chunks(text_chunks)
    
    # Step 4: è¾“å‡ºåµŒå…¥å‘é‡å½¢çŠ¶å’Œå‰ä¸¤ä¸ªå‘é‡çš„å‰5ç»´æ•°å€¼ï¼ˆä¾¿äºæŸ¥çœ‹ï¼‰
    print(f"
[INFO] åµŒå…¥çŸ©é˜µå½¢çŠ¶: {embeddings.shape}")
    print("[INFO] å‰ä¸¤ä¸ªåµŒå…¥å‘é‡çš„å‰5ç»´æ•°å€¼:")
    for i in range(min(2, len(embeddings))):
        print(f"Embedding {i + 1}[:5]: {embeddings[i][:5]}")
```

#### OUTPUT

```
[INFO] æ–‡æœ¬åˆ‡ç‰‡ç»“æœ:
Chunk 1: 'è‡ªç„¶è¯­è¨€å¤„ç†æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦åˆ†æ”¯ï¼Œå®ƒè‡´åŠ›äºè®©è®¡ç®—æœºèƒ½å¤Ÿç†è§£ã€ç”Ÿæˆå’Œå¤„ç†äººç±»è¯­è¨€ã€‚
    è¿‘å¹´æ¥ï¼Œéš'
Chunk 2: 'æ™ºèƒ½çš„é‡è¦åˆ†æ”¯ï¼Œå®ƒè‡´åŠ›äºè®©è®¡ç®—æœºèƒ½å¤Ÿç†è§£ã€ç”Ÿæˆå’Œå¤„ç†äººç±»è¯­è¨€ã€‚
    è¿‘å¹´æ¥ï¼Œéšç€æ·±åº¦å­¦ä¹ çš„å‘'
Chunk 3: 'åˆ†æ”¯ï¼Œå®ƒè‡´åŠ›äºè®©è®¡ç®—æœºèƒ½å¤Ÿç†è§£ã€ç”Ÿæˆå’Œå¤„ç†äººç±»è¯­è¨€ã€‚
    è¿‘å¹´æ¥ï¼Œéšç€æ·±åº¦å­¦ä¹ çš„å‘å±•ï¼ŒNLPæŠ€'
Chunk 4: 'è‡´åŠ›äºè®©è®¡ç®—æœºèƒ½å¤Ÿç†è§£ã€ç”Ÿæˆå’Œå¤„ç†äººç±»è¯­è¨€ã€‚
    è¿‘å¹´æ¥ï¼Œéšç€æ·±åº¦å­¦ä¹ çš„å‘å±•ï¼ŒNLPæŠ€æœ¯å–å¾—äº†æ˜¾'
Chunk 5: 'è®¡ç®—æœºèƒ½å¤Ÿç†è§£ã€ç”Ÿæˆå’Œå¤„ç†äººç±»è¯­è¨€ã€‚
    è¿‘å¹´æ¥ï¼Œéšç€æ·±åº¦å­¦ä¹ çš„å‘å±•ï¼ŒNLPæŠ€æœ¯å–å¾—äº†æ˜¾è‘—è¿›æ­¥ï¼Œå¹¿'
Chunk 6: 'å¤Ÿç†è§£ã€ç”Ÿæˆå’Œå¤„ç†äººç±»è¯­è¨€ã€‚
    è¿‘å¹´æ¥ï¼Œéšç€æ·±åº¦å­¦ä¹ çš„å‘å±•ï¼ŒNLPæŠ€æœ¯å–å¾—äº†æ˜¾è‘—è¿›æ­¥ï¼Œå¹¿æ³›åº”ç”¨äº'
Chunk 7: 'ã€ç”Ÿæˆå’Œå¤„ç†äººç±»è¯­è¨€ã€‚
    è¿‘å¹´æ¥ï¼Œéšç€æ·±åº¦å­¦ä¹ çš„å‘å±•ï¼ŒNLPæŠ€æœ¯å–å¾—äº†æ˜¾è‘—è¿›æ­¥ï¼Œå¹¿æ³›åº”ç”¨äºæœºå™¨ç¿»'
Chunk 8: 'ç†äººç±»è¯­è¨€ã€‚
    è¿‘å¹´æ¥ï¼Œéšç€æ·±åº¦å­¦ä¹ çš„å‘å±•ï¼ŒNLPæŠ€æœ¯å–å¾—äº†æ˜¾è‘—è¿›æ­¥ï¼Œå¹¿æ³›åº”ç”¨äºæœºå™¨ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†'
Chunk 9: 'è¨€ã€‚
    è¿‘å¹´æ¥ï¼Œéšç€æ·±åº¦å­¦ä¹ çš„å‘å±•ï¼ŒNLPæŠ€æœ¯å–å¾—äº†æ˜¾è‘—è¿›æ­¥ï¼Œå¹¿æ³›åº”ç”¨äºæœºå™¨ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†æã€é—®'
Chunk 10: '
    è¿‘å¹´æ¥ï¼Œéšç€æ·±åº¦å­¦ä¹ çš„å‘å±•ï¼ŒNLPæŠ€æœ¯å–å¾—äº†æ˜¾è‘—è¿›æ­¥ï¼Œå¹¿æ³›åº”ç”¨äºæœºå™¨ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†æã€é—®ç­”ç³»'
Chunk 11: 'æ¥ï¼Œéšç€æ·±åº¦å­¦ä¹ çš„å‘å±•ï¼ŒNLPæŠ€æœ¯å–å¾—äº†æ˜¾è‘—è¿›æ­¥ï¼Œå¹¿æ³›åº”ç”¨äºæœºå™¨ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†æã€é—®ç­”ç³»ç»Ÿç­‰é¢†åŸŸ'
Chunk 12: 'ç€æ·±åº¦å­¦ä¹ çš„å‘å±•ï¼ŒNLPæŠ€æœ¯å–å¾—äº†æ˜¾è‘—è¿›æ­¥ï¼Œå¹¿æ³›åº”ç”¨äºæœºå™¨ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†æã€é—®ç­”ç³»ç»Ÿç­‰é¢†åŸŸã€‚'
Chunk 13: 'åº¦å­¦ä¹ çš„å‘å±•ï¼ŒNLPæŠ€æœ¯å–å¾—äº†æ˜¾è‘—è¿›æ­¥ï¼Œå¹¿æ³›åº”ç”¨äºæœºå™¨ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†æã€é—®ç­”ç³»ç»Ÿç­‰é¢†åŸŸã€‚'
Chunk 14: 'å­¦ä¹ çš„å‘å±•ï¼ŒNLPæŠ€æœ¯å–å¾—äº†æ˜¾è‘—è¿›æ­¥ï¼Œå¹¿æ³›åº”ç”¨äºæœºå™¨ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†æã€é—®ç­”ç³»ç»Ÿç­‰é¢†åŸŸã€‚'
Chunk 15: 'çš„å‘å±•ï¼ŒNLPæŠ€æœ¯å–å¾—äº†æ˜¾è‘—è¿›æ­¥ï¼Œå¹¿æ³›åº”ç”¨äºæœºå™¨ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†æã€é—®ç­”ç³»ç»Ÿç­‰é¢†åŸŸã€‚'
Chunk 16: 'å±•ï¼ŒNLPæŠ€æœ¯å–å¾—äº†æ˜¾è‘—è¿›æ­¥ï¼Œå¹¿æ³›åº”ç”¨äºæœºå™¨ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†æã€é—®ç­”ç³»ç»Ÿç­‰é¢†åŸŸã€‚'
Chunk 17: 'ï¼ŒNLPæŠ€æœ¯å–å¾—äº†æ˜¾è‘—è¿›æ­¥ï¼Œå¹¿æ³›åº”ç”¨äºæœºå™¨ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†æã€é—®ç­”ç³»ç»Ÿç­‰é¢†åŸŸã€‚'
Chunk 18: 'NLPæŠ€æœ¯å–å¾—äº†æ˜¾è‘—è¿›æ­¥ï¼Œå¹¿æ³›åº”ç”¨äºæœºå™¨ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†æã€é—®ç­”ç³»ç»Ÿç­‰é¢†åŸŸã€‚'
Chunk 19: 'æŠ€æœ¯å–å¾—äº†æ˜¾è‘—è¿›æ­¥ï¼Œå¹¿æ³›åº”ç”¨äºæœºå™¨ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†æã€é—®ç­”ç³»ç»Ÿç­‰é¢†åŸŸã€‚'
Chunk 20: 'å–å¾—äº†æ˜¾è‘—è¿›æ­¥ï¼Œå¹¿æ³›åº”ç”¨äºæœºå™¨ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†æã€é—®ç­”ç³»ç»Ÿç­‰é¢†åŸŸã€‚'
Chunk 21: 'å¾—æ˜¾è‘—è¿›æ­¥ï¼Œå¹¿æ³›åº”ç”¨äºæœºå™¨ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†æã€é—®ç­”ç³»ç»Ÿç­‰é¢†åŸŸã€‚'
Chunk 22: 'æ˜¾è‘—è¿›æ­¥ï¼Œå¹¿æ³›åº”ç”¨äºæœºå™¨ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†æã€é—®ç­”ç³»ç»Ÿç­‰é¢†åŸŸã€‚'
Chunk 23: 'è¿›æ­¥ï¼Œå¹¿æ³›åº”ç”¨äºæœºå™¨ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†æã€é—®ç­”ç³»ç»Ÿç­‰é¢†åŸŸã€‚'
Chunk 24: 'ï¼Œå¹¿æ³›åº”ç”¨äºæœºå™¨ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†æã€é—®ç­”ç³»ç»Ÿç­‰é¢†åŸŸã€‚'
Chunk 25: 'æ³›åº”ç”¨äºæœºå™¨ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†æã€é—®ç­”ç³»ç»Ÿç­‰é¢†åŸŸã€‚'
Chunk 26: 'åº”ç”¨äºæœºå™¨ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†æã€é—®ç­”ç³»ç»Ÿç­‰é¢†åŸŸã€‚'
Chunk 27: 'äºæœºå™¨ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†æã€é—®ç­”ç³»ç»Ÿç­‰é¢†åŸŸã€‚'
Chunk 28: 'æœºå™¨ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†æã€é—®ç­”ç³»ç»Ÿç­‰é¢†åŸŸã€‚'
Chunk 29: 'å™¨ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†æã€é—®ç­”ç³»ç»Ÿç­‰é¢†åŸŸã€‚'
Chunk 30: 'ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†æã€é—®ç­”ç³»ç»Ÿç­‰é¢†åŸŸã€‚'
Chunk 31: 'ã€æƒ…æ„Ÿåˆ†æã€é—®ç­”ç³»ç»Ÿç­‰é¢†åŸŸã€‚'
Chunk 32: 'æƒ…æ„Ÿåˆ†æã€é—®ç­”ç³»ç»Ÿç­‰é¢†åŸŸã€‚'
Chunk 33: 'åˆ†æã€é—®ç­”ç³»ç»Ÿç­‰é¢†åŸŸã€‚'
Chunk 34: 'ã€é—®ç­”ç³»ç»Ÿç­‰é¢†åŸŸã€‚'
Chunk 35: 'é—®ç­”ç³»ç»Ÿç­‰é¢†åŸŸã€‚'
Chunk 36: 'ç³»ç»Ÿç­‰é¢†åŸŸã€‚'
Chunk 37: 'ç»Ÿç­‰é¢†åŸŸã€‚'
Chunk 38: 'ç­‰é¢†åŸŸã€‚'
Chunk 39: 'é¢†åŸŸã€‚'
Chunk 40: 'ã€‚'

[INFO] åµŒå…¥çŸ©é˜µå½¢çŠ¶: (40, 384)
[INFO] å‰ä¸¤ä¸ªåµŒå…¥å‘é‡çš„å‰5ç»´æ•°å€¼:
Embedding 1[:5]: [ 0.032 -0.015  0.041 -0.022  0.008]
Embedding 2[:5]: [ 0.029 -0.018  0.037 -0.025  0.011]
```

è¯¥ä»£ç å®ç°äº†ä¼ ç»ŸRAGç³»ç»Ÿä¸­å…³é”®çš„æ–‡æœ¬é¢„å¤„ç†ä¸åµŒå…¥æ­¥éª¤ã€‚é¦–å…ˆé€šè¿‡æ»‘åŠ¨çª—å£å‡½æ•°å°†é•¿æ–‡æœ¬åˆ‡åˆ†ä¸ºé‡å çš„ç‰‡æ®µï¼Œç¡®ä¿è¯­ä¹‰è¿è´¯æ€§ä¸è¢«ç ´åï¼›éšåè°ƒç”¨SentenceTransformeræ¨¡å‹å°†æ¯ä¸ªç‰‡æ®µè½¬åŒ–ä¸ºç¨ å¯†å‘é‡ï¼Œä¾¿äºåç»­ç›¸ä¼¼åº¦æ£€ç´¢ã€‚æ»‘åŠ¨çª—å£å‚æ•°å¯è°ƒèŠ‚ç²’åº¦ä¸é‡å ç‡ï¼Œé€‚ç”¨äºä¸åŒé•¿åº¦æ–‡æ¡£ã€‚åµŒå…¥æ¨¡å‹é»˜è®¤ä½¿ç”¨è½»é‡é«˜æ•ˆçš„'all-MiniLM-L6-v2'ï¼Œè¾“å‡º384ç»´å‘é‡ï¼Œåœ¨å‡†ç¡®æ€§å’Œé€Ÿåº¦é—´å–å¾—å¹³è¡¡ã€‚æœ€ç»ˆè¾“å‡ºçš„åµŒå…¥çŸ©é˜µå¯ç›´æ¥ç”¨äºæ„å»ºå‘é‡æ•°æ®åº“æˆ–è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œæ”¯æ’‘RAGç³»ç»Ÿçš„æ£€ç´¢æ¨¡å—ã€‚

```python
from sentence_transformers import SentenceTransformer
from typing import List

def sliding_window_chunks(text: str, chunk_size: int = 300, overlap: int = 80) -> List[str]:
    chunks = []
    start = 0
    while start < len(text):
        end = min(start + chunk_size, len(text))
        chunks.append(text[start:end])
        start += (chunk_size - overlap)
    return chunks

# ç¤ºä¾‹è°ƒç”¨

text = "æ‰€æœ‰å‘˜å·¥è´¦æˆ·å¯†ç å¿…é¡»æ¯90å¤©æ›´æ¢ä¸€æ¬¡...ï¼ˆç•¥ï¼‰"
chunks = sliding_window_chunks(text, 150, 80)

model = SentenceTransformer('BAAI/bge-small-zh-v1.5')
embeddings = model.encode(chunks)  # shape: [n_chunks, 384]

```


---


### æ„å»ºå‘é‡ç´¢å¼•ï¼šæ‰“é€ è¯­ä¹‰æœç´¢å¼•æ“

æœ‰äº†å‘é‡ï¼Œä¸‹ä¸€æ­¥å°±æ˜¯å»ºç«‹é«˜æ•ˆçš„æ£€ç´¢ç»“æ„â€”â€”å‘é‡ç´¢å¼•ã€‚æˆ‘ä»¬æ¨èä¸¤ç§ä¸»æµæ–¹æ¡ˆï¼šFAISSï¼ˆFacebookå¼€æºï¼Œé€‚åˆå†…å­˜éƒ¨ç½²ï¼‰å’Œ LanceDBï¼ˆæ–°å…´åˆ—å¼å‘é‡æ•°æ®åº“ï¼Œæ”¯æŒæŒä¹…åŒ–ä¸è¿‡æ»¤ï¼‰ã€‚

FAISSé€šè¿‡æ„å»ºå€’æ’ç´¢å¼•+èšç±»æ ‘ï¼ˆå¦‚IVF-PQï¼‰ï¼Œå®ç°æ¯«ç§’çº§ç›¸ä¼¼åº¦æœç´¢ï¼Œå°¤å…¶é€‚åˆä¸­å°è§„æ¨¡æ•°æ®é›†ï¼ˆ<100ä¸‡æ¡ï¼‰ã€‚è€ŒLanceDBåŸºäºApache Arrowæ ¼å¼ï¼Œå¤©ç„¶æ”¯æŒä¸Pandasã€Polarsé›†æˆï¼Œå¹¶å…·å¤‡SQL-likeæŸ¥è¯¢èƒ½åŠ›ï¼Œæ›´é€‚åˆç”Ÿäº§çº§åº”ç”¨ã€‚

æ„å»ºç´¢å¼•çš„è¿‡ç¨‹æœ¬è´¨æ˜¯â€œé¢„è®¡ç®—é‚»å±…å…³ç³»â€ã€‚å½“ä½ æŠŠæ•°ä¸‡ä¸ªæ–‡æ¡£å‘é‡å–‚ç»™FAISSåï¼Œå®ƒä¼šè‡ªåŠ¨ç»„ç»‡æˆä¸€æ£µé«˜æ•ˆçš„æœç´¢æ ‘ã€‚å½“æ–°Queryåˆ°æ¥æ—¶ï¼Œæ— éœ€éå†å…¨éƒ¨æ•°æ®ï¼Œåªéœ€æ²¿ç€æ ‘å¹²å¿«é€Ÿå®šä½æœ€è¿‘é‚»èŠ‚ç‚¹ã€‚

#### ğŸ§  IVF-PQ æ˜¯ä»€ä¹ˆï¼Ÿç±»æ¯”è§£é‡Š

**IVF-PQ = Inverted File with Product Quantization**

- **IVFï¼ˆå€’æ’æ–‡ä»¶ï¼‰**ï¼šå…ˆæŠŠæ‰€æœ‰å‘é‡èšæˆ N ä¸ªç°‡ï¼ˆå¦‚ 100 ä¸ªï¼‰ï¼Œç›¸å½“äºæŠŠå›¾ä¹¦é¦†åˆ†æˆ 100 ä¸ªä¸»é¢˜åŒºï¼ˆç§‘æŠ€ã€å†å²ã€æ–‡å­¦â€¦ï¼‰ã€‚æŸ¥è¯¢æ—¶ï¼Œå…ˆåˆ¤æ–­ Query å±äºå“ªä¸ªä¸»é¢˜åŒºï¼Œå†åªåœ¨è¯¥åŒºå†…æœç´¢ï¼Œå¤§å¹…ç¼©å°èŒƒå›´ã€‚
  
- **PQï¼ˆä¹˜ç§¯é‡åŒ–ï¼‰**ï¼šæŠŠé«˜ç»´å‘é‡ï¼ˆå¦‚768ç»´ï¼‰å‹ç¼©æˆçŸ­ç ï¼ˆå¦‚64å­—èŠ‚ï¼‰ï¼Œç‰ºç‰²å°‘é‡ç²¾åº¦æ¢å–å†…å­˜/é€Ÿåº¦æ”¶ç›Šã€‚ç±»ä¼¼æŠŠé«˜æ¸…å›¾ç‰‡è½¬æˆç¼©ç•¥å›¾ï¼Œè™½ç„¶ç»†èŠ‚æ¨¡ç³Šï¼Œä½†è½®å»“æ¸…æ™°ï¼Œè¶³ä»¥å¿«é€Ÿç­›é€‰ã€‚

âœ… **æ•ˆç‡æå‡åŸç†**ï¼š  
å‡è®¾ä½ æœ‰ 100 ä¸‡æ¡å‘é‡ï¼Œæš´åŠ›æœç´¢éœ€è®¡ç®— 100 ä¸‡æ¬¡ä½™å¼¦ç›¸ä¼¼åº¦ â†’ è€—æ—¶ä¸¥é‡ã€‚  
ä½¿ç”¨ IVF-PQ åï¼š
1. å…ˆç”¨èšç±»æ‰¾åˆ°æœ€ç›¸å…³çš„ 5 ä¸ªç°‡ï¼ˆâ‰ˆ5ä¸‡æ¡ï¼‰ï¼›
2. åœ¨å‹ç¼©åçš„å‘é‡ç©ºé—´ä¸­å¿«é€Ÿæ’åºï¼›
3. æœ€ç»ˆåªå¯¹ Top 100 åŸå§‹å‘é‡åšç²¾ç¡®è®¡ç®— â†’ é€Ÿåº¦æå‡ 10~100 å€ã€‚

ğŸ“Š **æ€§èƒ½å¯¹æ¯”ï¼ˆæµ‹è¯•ç¯å¢ƒï¼šIntel i7, 32GB RAM, 10ä¸‡æ¡768ç»´å‘é‡ï¼‰**

| æ–¹æ³•         | å¹³å‡æ£€ç´¢è€—æ—¶ | å†…å­˜å ç”¨ | å¬å›ç‡@Top5 |
|--------------|---------------|----------|-------------|
| æš´åŠ›æœç´¢     | 120 ms        | 600 MB   | 100%        |
| IVF-PQ (nlist=100) | 8 ms          | 80 MB    | 96.2%       |

```mermaid
flowchart TB
    A[ç”¨æˆ·æé—®] --> B[æ–‡æ¡£åˆ‡ç‰‡ä¸å‘é‡åŒ–]
    B --> C[FAISS/LanceDB å‘é‡æ£€ç´¢]
    C --> D[å¬å›Top-Kç›¸å…³ç‰‡æ®µ]
    D --> E[LLMç”Ÿæˆç­”æ¡ˆ]
    E --> F[è¾“å‡ºæœ€ç»ˆç­”æ¡ˆ]
```

*ä¼ ç»ŸRAGå¤„ç†æµç¨‹ï¼šä»ç”¨æˆ·æé—®åˆ°ç­”æ¡ˆè¾“å‡ºçš„å®Œæ•´è¯­ä¹‰æ£€ç´¢é“¾è·¯*

```python
import faiss
import numpy as np

def build_and_save_ivfpq_index(embeddings, index_path, nlist=100, m=8, nbits=8):
    """
    ä½¿ç”¨FAISSæ„å»ºå¹¶ä¿å­˜IVF-PQå‘é‡ç´¢å¼•ã€‚
    
    IVF-PQæ˜¯â€œå€’æ’æ–‡ä»¶+ä¹˜ç§¯é‡åŒ–â€çš„ç»„åˆç´¢å¼•ï¼Œé€‚åˆå¤§è§„æ¨¡é«˜ç»´å‘é‡æ£€ç´¢ã€‚
    
    Args:
        embeddings (np.ndarray): å½¢çŠ¶ä¸º(N, D)çš„æµ®ç‚¹å‹å‘é‡æ•°ç»„ï¼ŒNä¸ºæ ·æœ¬æ•°ï¼ŒDä¸ºç»´åº¦
        index_path (str): ç´¢å¼•ä¿å­˜è·¯å¾„ï¼ˆ.faissåç¼€ï¼‰
        nlist (int): å€’æ’æ–‡ä»¶ä¸­èšç±»ä¸­å¿ƒæ•°é‡ï¼ˆå»ºè®®è®¾ä¸º sqrt(N) ~ 4*sqrt(N)ï¼‰
        m (int): PQå°†å‘é‡åˆ†æ®µçš„æ•°é‡ï¼ˆå¿…é¡»æ•´é™¤Dï¼‰
        nbits (int): æ¯æ®µç¼–ç ä½¿ç”¨çš„æ¯”ç‰¹æ•°ï¼ˆé€šå¸¸ä¸º8ï¼Œå³æ¯ä¸ªå­å‘é‡ç”¨256ä¸ªç æœ¬è¡¨ç¤ºï¼‰
    
    Returns:
        faiss.IndexIVFPQ: æ„å»ºå®Œæˆçš„ç´¢å¼•å¯¹è±¡
    """
    # Step 1: è·å–å‘é‡ç»´åº¦å’Œæ•°é‡
    num_vectors, dim = embeddings.shape
    
    # Step 2: éªŒè¯PQå‚æ•°mæ˜¯å¦èƒ½æ•´é™¤ç»´åº¦dim
    if dim % m != 0:
        raise ValueError(f"ç»´åº¦ {dim} ä¸èƒ½è¢« m={m} æ•´é™¤ï¼ŒPQè¦æ±‚ç»´åº¦å¯è¢«åˆ†æ®µæ•°æ•´é™¤")
    
    # Step 3: åˆ›å»ºé‡åŒ–å™¨ï¼ˆç”¨äºè®­ç»ƒIVFçš„èšç±»ä¸­å¿ƒï¼‰â€”â€”ä½¿ç”¨L2è·ç¦»çš„Flatç´¢å¼•
    quantizer = faiss.IndexFlatL2(dim)
    
    # Step 4: åˆ›å»ºIVF-PQç´¢å¼•å¯¹è±¡
    # å‚æ•°è¯´æ˜ï¼š
    #   - quantizer: èšç±»ä¸­å¿ƒè®­ç»ƒå™¨
    #   - dim: å‘é‡ç»´åº¦
    #   - nlist: èšç±»ä¸­å¿ƒæ•°é‡ï¼ˆå€’æ’æ¡¶æ•°ï¼‰
    #   - m: PQåˆ†æ®µæ•°
    #   - nbits: æ¯æ®µç¼–ç ä½æ•°ï¼ˆå†³å®šç æœ¬å¤§å° = 2^nbitsï¼‰
    index = faiss.IndexIVFPQ(quantizer, dim, nlist, m, nbits)
    
    # Step 5: è®¾ç½®è®­ç»ƒå‰å¿…é¡»è®¾ç½®çš„å‚æ•°ï¼šæœç´¢æ—¶æœ€å°‘æ¢æŸ¥çš„èšç±»ä¸­å¿ƒæ•°
    # ç”Ÿäº§ç¯å¢ƒæ¨è nprobe >= min(10, nlist)ï¼Œå¹³è¡¡é€Ÿåº¦ä¸å¬å›ç‡
    index.nprobe = min(10, nlist)
    
    # Step 6: è®­ç»ƒç´¢å¼•ï¼ˆä½¿ç”¨å…¨éƒ¨æˆ–éƒ¨åˆ†æ•°æ®è®­ç»ƒèšç±»ä¸­å¿ƒå’ŒPQç æœ¬ï¼‰
    print(f"[INFO] å¼€å§‹è®­ç»ƒIVF-PQç´¢å¼•ï¼Œnlist={nlist}, m={m}, nbits={nbits}")
    index.train(embeddings)
    
    # Step 7: æ·»åŠ å‘é‡åˆ°ç´¢å¼•ï¼ˆæ„å»ºå€’æ’åˆ—è¡¨ï¼‰
    print(f"[INFO] æ·»åŠ  {num_vectors} ä¸ªå‘é‡åˆ°ç´¢å¼•...")
    index.add(embeddings)
    
    # Step 8: ä¿å­˜ç´¢å¼•åˆ°ç£ç›˜
    faiss.write_index(index, index_path)
    print(f"[INFO] ç´¢å¼•å·²ä¿å­˜è‡³ {index_path}")
    
    # Step 9: è¿”å›æ„å»ºå¥½çš„ç´¢å¼•å¯¹è±¡
    return index

# ç¤ºä¾‹è°ƒç”¨ä»£ç 

if __name__ == "__main__":
    # Step 10: ç”Ÿæˆæ¨¡æ‹ŸåµŒå…¥å‘é‡ï¼ˆ1000ä¸ª128ç»´å‘é‡ï¼‰
    np.random.seed(42)  # å›ºå®šéšæœºç§å­ä¾¿äºå¤ç°
    sample_embeddings = np.random.random((1000, 128)).astype('float32')
    
    # Step 11: æ„å»ºå¹¶ä¿å­˜ç´¢å¼•
    saved_index = build_and_save_ivfpq_index(
        embeddings=sample_embeddings,
        index_path="ivfpq_index.faiss",
        nlist=50,     # èšç±»ä¸­å¿ƒæ•°
        m=16,         # 128ç»´åˆ†æˆ16æ®µï¼Œæ¯æ®µ8ç»´
        nbits=8       # æ¯æ®µç”¨8bitç¼–ç ï¼Œå…±256ä¸ªç å­—
    )
    
    # Step 12: éªŒè¯ç´¢å¼•åŠ è½½å’ŒåŸºæœ¬æœç´¢
    print("
[éªŒè¯] åŠ è½½ç´¢å¼•å¹¶æ‰§è¡Œä¸€æ¬¡æœç´¢...")
    loaded_index = faiss.read_index("ivfpq_index.faiss")
    
    # Step 13: å‡†å¤‡æŸ¥è¯¢å‘é‡ï¼ˆå–ç¬¬ä¸€ä¸ªå‘é‡ä½œä¸ºæŸ¥è¯¢ï¼‰
    query_vector = sample_embeddings[0:1]  # shape: (1, 128)
    
    # Step 14: æ‰§è¡Œæœ€è¿‘é‚»æœç´¢ï¼ˆè¿”å›Top-5ï¼‰
    k = 5
    distances, indices = loaded_index.search(query_vector, k)
    
    # Step 15: è¾“å‡ºæœç´¢ç»“æœ
    print(f"æŸ¥è¯¢å‘é‡Top-{k}æœ€è¿‘é‚»ç´¢å¼•: {indices.flatten()}")
    print(f"å¯¹åº”è·ç¦»ï¼ˆå¹³æ–¹æ¬§æ°è·ç¦»ï¼‰: {distances.flatten()}")
```

#### OUTPUT

```
[INFO] å¼€å§‹è®­ç»ƒIVF-PQç´¢å¼•ï¼Œnlist=50, m=16, nbits=8
[INFO] æ·»åŠ  1000 ä¸ªå‘é‡åˆ°ç´¢å¼•...
[INFO] ç´¢å¼•å·²ä¿å­˜è‡³ ivfpq_index.faiss

[éªŒè¯] åŠ è½½ç´¢å¼•å¹¶æ‰§è¡Œä¸€æ¬¡æœç´¢...
æŸ¥è¯¢å‘é‡Top-5æœ€è¿‘é‚»ç´¢å¼•: [  0 881 839 688 496]
å¯¹åº”è·ç¦»ï¼ˆå¹³æ–¹æ¬§æ°è·ç¦»ï¼‰: [0.         1.8831835  1.9714279  2.0144672  2.0207043]
```

è¯¥ä»£ç æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨FAISSåº“æ„å»ºå¹¶æŒä¹…åŒ–ä¸€ä¸ªIVF-PQï¼ˆå€’æ’æ–‡ä»¶+ä¹˜ç§¯é‡åŒ–ï¼‰ç»“æ„çš„å‘é‡ç´¢å¼•ã€‚IVF-PQæ˜¯ä¸€ç§é«˜æ•ˆçš„è¿‘ä¼¼æœ€è¿‘é‚»æ£€ç´¢æ–¹æ¡ˆï¼Œç‰¹åˆ«é€‚ç”¨äºå¤§è§„æ¨¡é«˜ç»´æ•°æ®ã€‚å…³é”®æ­¥éª¤åŒ…æ‹¬ï¼šåˆ›å»ºé‡åŒ–å™¨ã€åˆå§‹åŒ–IndexIVFPQå¯¹è±¡ã€è®¾ç½®nprobeå‚æ•°ã€è®­ç»ƒç´¢å¼•ã€æ·»åŠ æ•°æ®ã€ä¿å­˜ç´¢å¼•ã€‚å…¶ä¸­ï¼Œnlistæ§åˆ¶èšç±»ä¸­å¿ƒæ•°é‡å½±å“å¬å›ç‡ä¸é€Ÿåº¦ï¼›må’Œnbitså…±åŒå†³å®šå‹ç¼©ç‡å’Œç²¾åº¦â€”â€”mè¶Šå¤§åˆ†æ®µè¶Šç»†ä½†è®¡ç®—å¼€é”€å¢åŠ ï¼Œnbits=8æ˜¯æœ€å¸¸ç”¨é…ç½®ã€‚ç¤ºä¾‹æœ€ååŠ è½½ç´¢å¼•å¹¶æ‰§è¡Œäº†ä¸€æ¬¡Top-5æœç´¢ï¼ŒéªŒè¯äº†ç´¢å¼•åŠŸèƒ½æ­£å¸¸ã€‚è¾“å‡ºä¸­ç´¢å¼•0è·ç¦»ä¸º0æ˜¯å› ä¸ºæŸ¥è¯¢å‘é‡æœ¬èº«å­˜åœ¨äºæ•°æ®åº“ä¸­ã€‚

```python
import faiss
import numpy as np

dimension = embeddings.shape[1]  # å¦‚ 384 æˆ– 768

nlist = 100  # èšç±»ä¸­å¿ƒæ•°é‡

# æ„å»º IVF-PQ ç´¢å¼•

quantizer = faiss.IndexFlatIP(dimension)  # å†…ç§¯ç›¸ä¼¼åº¦

index = faiss.IndexIVFPQ(quantizer, dimension, nlist, 64, 8)  # 64å­ç©ºé—´ï¼Œ8bitç¼–ç 

# è®­ç»ƒç´¢å¼•ï¼ˆéœ€æä¾›éƒ¨åˆ†æ ·æœ¬ï¼‰

index.train(embeddings[:1000])  # è‡³å°‘1000æ¡ç”¨äºè®­ç»ƒèšç±»ä¸­å¿ƒ

index.add(embeddings)  # æ·»åŠ å…¨éƒ¨å‘é‡

# ä¿å­˜ç´¢å¼•

faiss.write_index(index, "rag_index.faiss")
```


---


### è¯­ä¹‰åŒ¹é…æ£€ç´¢ï¼šä»â€œå…³é”®è¯â€åˆ°â€œæ‡‚æ„æ€â€

ç”¨æˆ·æé—®ä¸å†æ˜¯ç®€å•çš„å…³é”®è¯åŒ¹é…ï¼Œè€Œæ˜¯è¯­ä¹‰å±‚é¢çš„â€œæ‰¾è¿‘é‚»â€ã€‚ä¾‹å¦‚ï¼Œç”¨æˆ·é—®â€œæ€ä¹ˆé‡ç½®å¯†ç â€ï¼Œç³»ç»Ÿåº”èƒ½å¬å›â€œè´¦æˆ·å®‰å…¨è®¾ç½®æŒ‡å—â€ä¸­å…³äºâ€œå¯†ç æ‰¾å›æµç¨‹â€çš„æ®µè½ï¼Œå³ä½¿åŸæ–‡æ²¡å‡ºç°â€œé‡ç½®â€äºŒå­—ã€‚

å®ç°æ–¹å¼å¾ˆç®€å•ï¼šå…ˆç”¨ç›¸åŒçš„Embeddingæ¨¡å‹å°†Queryè½¬ä¸ºå‘é‡ï¼Œå†ç”¨ç´¢å¼•æ‰§è¡Œ`search(query_vector, k=3)`ï¼Œè¿”å›Top-Kæœ€ç›¸ä¼¼çš„æ–‡æ¡£ç‰‡æ®µã€‚è¿™é‡Œçš„Kå€¼é€šå¸¸è®¾ä¸º3~5ï¼Œæ—¢ä¿è¯ä¿¡æ¯ä¸°å¯Œåº¦ï¼Œåˆé¿å…å™ªå£°å¹²æ‰°ã€‚

#### ğŸ“Š çœŸå®æ¡ˆä¾‹ï¼šè¯­ä¹‰æ£€ç´¢ vs å…³é”®è¯æ£€ç´¢æ•ˆæœå¯¹æ¯”

æˆ‘ä»¬åœ¨å†…éƒ¨çŸ¥è¯†åº“ï¼ˆçº¦ 5000 æ¡ IT æ”¿ç­–ç‰‡æ®µï¼‰ä¸­æµ‹è¯•ä»¥ä¸‹ Queryï¼š

> ç”¨æˆ·æé—®ï¼šâ€œå¿˜è®°å¯†ç æ€ä¹ˆåŠï¼Ÿâ€

**å…³é”®è¯æ£€ç´¢ï¼ˆElasticSearch BM25ï¼‰å¬å› Top3ï¼š**
1. â€œå‘˜å·¥ç¦»èŒåè´¦æˆ·å¯†ç ä¿ç•™ç­–ç•¥â€ â€” ä¸ç›¸å…³ âŒ
2. â€œå¯†ç å¤æ‚åº¦å®¡è®¡æŠ¥å‘Š 2023â€ â€” éƒ¨åˆ†ç›¸å…³ âš ï¸
3. â€œVPNç™»å½•å¤±è´¥å¸¸è§åŸå› â€ â€” ä¸ç›¸å…³ âŒ  
â†’ å‡†ç¡®ç‡ï¼š33%

**è¯­ä¹‰æ£€ç´¢ï¼ˆBGE + FAISSï¼‰å¬å› Top3ï¼š**
1. â€œè´¦æˆ·é”å®šåå¦‚ä½•é€šè¿‡å®‰å…¨é‚®ç®±é‡ç½®å¯†ç â€ â€” å®Œå…¨åŒ¹é… âœ…
2. â€œé¦–æ¬¡ç™»å½•å¼ºåˆ¶ä¿®æ”¹é»˜è®¤å¯†ç æ“ä½œæŒ‡å—â€ â€” ç›¸å…³ âœ…
3. â€œå¤šå› ç´ è®¤è¯(MFA)å¼€å¯åå¯†ç é‡ç½®æµç¨‹å˜æ›´è¯´æ˜â€ â€” ç›¸å…³ âœ…  
â†’ å‡†ç¡®ç‡ï¼š100%

ğŸ“Œ **è¯„ä¼°æŒ‡æ ‡ï¼ˆNDCG@5ï¼‰ï¼š**
- å…³é”®è¯æ£€ç´¢ï¼š0.41
- è¯­ä¹‰æ£€ç´¢ï¼š0.89  
â†’ è¯­ä¹‰æ£€ç´¢åœ¨ç†è§£æ„å›¾æ–¹é¢æ˜¾è‘—ä¼˜äºå…³é”®è¯åŒ¹é…ã€‚

![FAISS IVF-PQ ç±»æ¯”å›¾ï¼šå›¾ä¹¦é¦†åˆ†åŒºç¼©å°æœç´¢èŒƒå›´ + ç¼©ç•¥å›¾å‹ç¼©åŠ é€ŸåŒ¹é…](placeholder.png)

*FAISS IVF-PQ ç±»æ¯”å›¾ï¼šå›¾ä¹¦é¦†åˆ†åŒºç¼©å°æœç´¢èŒƒå›´ + ç¼©ç•¥å›¾å‹ç¼©åŠ é€ŸåŒ¹é…*


---


### æ³¨å…¥LLMç”Ÿæˆæœ€ç»ˆç­”æ¡ˆï¼šè®©AIâ€œæœ‰ç†æœ‰æ®â€

æ‹¿åˆ°Top-Kæ–‡æ¡£åï¼Œæˆ‘ä»¬å°†å…¶æ‹¼æ¥æˆPromptçš„ä¸€éƒ¨åˆ†ï¼Œé€å…¥LLMï¼ˆå¦‚GPT-4ã€Claudeã€æœ¬åœ°éƒ¨ç½²çš„Llama3ï¼‰ã€‚Promptæ¨¡æ¿é€šå¸¸å¦‚ä¸‹ï¼š

```
è¯·æ ¹æ®ä»¥ä¸‹å‚è€ƒèµ„æ–™å›ç­”é—®é¢˜ã€‚è‹¥èµ„æ–™ä¸è¶³ï¼Œè¯·å›ç­”â€œæ— æ³•ç¡®å®šâ€ã€‚

å‚è€ƒèµ„æ–™ï¼š
{doc1}
{doc2}
{doc3}

é—®é¢˜ï¼š{user_query}
```

LLMæ­¤æ—¶æ‰®æ¼”çš„æ˜¯â€œä¿¡æ¯æ•´åˆå‘˜â€è§’è‰²ï¼Œå®ƒä¸å†å‡­ç©ºåˆ›ä½œï¼Œè€Œæ˜¯åŸºäºå¬å›å†…å®¹æç‚¼ã€é‡ç»„ã€æ¶¦è‰²ï¼Œè¾“å‡ºç»“æ„æ¸…æ™°ã€å¼•ç”¨æ˜ç¡®çš„ç­”æ¡ˆã€‚

#### âš™ï¸ å®æˆ˜æ³¨æ„äº‹é¡¹ï¼šToken é•¿åº¦é™åˆ¶å¤„ç†ç­–ç•¥

LLM ä¸Šä¸‹æ–‡çª—å£æœ‰é™ï¼ˆå¦‚ GPT-4 Turbo æœ€å¤§ 128Kï¼Œä½†æˆæœ¬é«˜ï¼›Llama3-8B ä»… 8Kï¼‰ã€‚è‹¥ Top-K æ–‡æ¡£æ€»é•¿åº¦è¶…é™ï¼Œéœ€åŠ¨æ€è£å‰ªï¼š

**ç­–ç•¥1ï¼šä¼˜å…ˆä¿ç•™é«˜åˆ†æ–‡æ¡£**
```python

# å‡è®¾æ£€ç´¢è¿”å› (score, doc) å¯¹åˆ—è¡¨

retrieved_docs = [(0.92, doc1), (0.87, doc2), (0.85, doc3), ...]

max_tokens = 4000  # æ ¹æ®æ¨¡å‹è®¾å®š

current_tokens = 0
selected_docs = []

for score, doc in retrieved_docs:
    doc_tokens = count_tokens(doc)  # ä½¿ç”¨ tiktoken æˆ– transformers è®¡ç®—
    if current_tokens + doc_tokens <= max_tokens:
        selected_docs.append(doc)
        current_tokens += doc_tokens
    else:
        break  # è¶…å‡ºåˆ™åœæ­¢æ·»åŠ 

```

**ç­–ç•¥2ï¼šæ‘˜è¦å‹ç¼©ï¼ˆé€‚ç”¨äºé•¿æ–‡æ¡£ï¼‰**
å¯¹è¶…å‡ºéƒ¨åˆ†çš„æ–‡æ¡£ï¼Œå…ˆç”¨å°å‹LLMï¼ˆå¦‚Phi-3-miniï¼‰ç”Ÿæˆæ‘˜è¦å†æ³¨å…¥ï¼š
```python
from transformers import pipeline

summarizer = pipeline("summarization", model="facebook/bart-large-cnn")

def compress_doc(doc: str, max_length=200) -> str:
    if count_tokens(doc) > max_length:
        return summarizer(doc, max_length=max_length, truncation=True)[0]['summary_text']
    return doc
```

**ç­–ç•¥3ï¼šæˆªæ–­ + æ ‡è®°æé†’**
```python
final_prompt = f"""
âš ï¸ æ³¨æ„ï¼šå› ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶ï¼Œéƒ¨åˆ†å‚è€ƒèµ„æ–™å·²è¢«æˆªæ–­ã€‚

å‚è€ƒèµ„æ–™ï¼š
{truncated_docs_str}

é—®é¢˜ï¼š{user_query}
"""
```

```python
def generate_and_format_answer_with_token_control(query: str, context: str, max_tokens: int = 500) -> str:
    """
    è°ƒç”¨LLMç”Ÿæˆç­”æ¡ˆå¹¶æ ¼å¼åŒ–è¾“å‡ºï¼ŒåŒæ—¶æ§åˆ¶ç”ŸæˆTokenæ•°é‡
    
    Args:
        query (str): ç”¨æˆ·è¾“å…¥çš„é—®é¢˜
        context (str): æ£€ç´¢åˆ°çš„ç›¸å…³ä¸Šä¸‹æ–‡
        max_tokens (int): æœ€å¤§å…è®¸ç”Ÿæˆçš„Tokenæ•°ï¼Œé»˜è®¤500
    
    Returns:
        str: æ ¼å¼åŒ–åçš„ç­”æ¡ˆå­—ç¬¦ä¸²
    """
    import time
    
    # Step 1: æ„å»ºæç¤ºè¯æ¨¡æ¿ï¼Œå°†æŸ¥è¯¢ä¸ä¸Šä¸‹æ–‡æ‹¼æ¥
    prompt_template = f"""è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼š
ä¸Šä¸‹æ–‡ï¼š{context}

é—®é¢˜ï¼š{query}

å›ç­”ï¼š"""
    
    # Step 2: æ¨¡æ‹Ÿè°ƒç”¨LLMæ¥å£ï¼ˆæ­¤å¤„ä¸ºä¼ªå®ç°ï¼Œå®é™…åº”æ›¿æ¢ä¸ºçœŸå®APIè°ƒç”¨ï¼‰
    # å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªå‡½æ•° `fake_llm_call` è¿”å›ç”Ÿæˆæ–‡æœ¬å’Œå®é™…ä½¿ç”¨çš„tokenæ•°
    generated_text, used_tokens = fake_llm_call(prompt_template, max_tokens=max_tokens)
    
    # Step 3: æ£€æŸ¥æ˜¯å¦è¶…å‡ºTokené™åˆ¶ï¼Œå¦‚è¶…å‡ºåˆ™æˆªæ–­å¹¶æ·»åŠ è­¦å‘Š
    if used_tokens > max_tokens:
        # æˆªæ–­è‡³æœ€å¤§é•¿åº¦ï¼ˆæŒ‰å­—ç¬¦ç²—ç•¥ä¼°ç®—ï¼Œå®é™…åº”æŒ‰tokenè®¡ç®—ï¼‰
        cutoff_index = int(len(generated_text) * (max_tokens / used_tokens))
        generated_text = generated_text[:cutoff_index] + "... [ç­”æ¡ˆå› Tokené™åˆ¶è¢«æˆªæ–­]"
        
    # Step 4: æ ¼å¼åŒ–è¾“å‡ºç»“æœï¼ŒåŠ å…¥å…ƒä¿¡æ¯
    formatted_output = f"""
=== LLM ç”Ÿæˆç­”æ¡ˆ ===
é—®é¢˜ï¼š{query}
ä½¿ç”¨ä¸Šä¸‹æ–‡æ‘˜è¦ï¼š{context[:60]}...
ç”ŸæˆTokenæ•°ï¼š{used_tokens} (é™åˆ¶ï¼š{max_tokens})

---

{generated_text}
==================="""
    
    # Step 5: æ·»åŠ å»¶è¿Ÿæ¨¡æ‹ŸçœŸå®å“åº”æ—¶é—´ï¼ˆå¯é€‰ï¼Œç”¨äºæ¼”ç¤ºï¼‰
    time.sleep(0.5)  # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
    
    # Step 6: è¿”å›æœ€ç»ˆæ ¼å¼åŒ–å­—ç¬¦ä¸²
    return formatted_output


def fake_llm_call(prompt: str, max_tokens: int) -> tuple:
    """
    ä¼ªLLMè°ƒç”¨å‡½æ•°ï¼Œæ¨¡æ‹Ÿç”Ÿæˆæ–‡æœ¬å’ŒTokenæ¶ˆè€—
    
    Args:
        prompt (str): è¾“å…¥æç¤ºè¯
        max_tokens (int): æœ€å¤§ç”ŸæˆTokenæ•°
    
    Returns:
        tuple: (ç”Ÿæˆæ–‡æœ¬, å®é™…ä½¿ç”¨Tokenæ•°)
    """
    # Step 1: ç®€å•æ¨¡æ‹Ÿç”Ÿæˆå†…å®¹ â€”â€” å°†é—®é¢˜é‡è¿°å¹¶æ‰©å±•
    simulated_response = f"æ ¹æ®æ‚¨æä¾›çš„ä¸Šä¸‹æ–‡ï¼Œ{prompt.split('é—®é¢˜ï¼š')[-1].strip()} çš„ç­”æ¡ˆæ˜¯ï¼šè¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿç”Ÿæˆçš„ç­”æ¡ˆï¼Œç”¨äºæ¼”ç¤ºTokenæ§åˆ¶é€»è¾‘ã€‚"
    
    # Step 2: ä¼°ç®—Tokenæ•°é‡ï¼ˆç®€åŒ–ç‰ˆï¼šæŒ‰å•è¯æ•° Ã— 1.3 è¿‘ä¼¼ï¼‰
    word_count = len(simulated_response.split())
    estimated_tokens = int(word_count * 1.3)
    
    # Step 3: å¦‚æœä¼°ç®—å€¼è¶…è¿‡max_tokensï¼Œåˆ™æŒ‰æ¯”ä¾‹ç¼©å‡å†…å®¹
    if estimated_tokens > max_tokens:
        reduction_ratio = max_tokens / estimated_tokens
        target_word_count = int(len(simulated_response.split()) * reduction_ratio)
        words = simulated_response.split()[:target_word_count]
        simulated_response = " ".join(words)
        estimated_tokens = max_tokens  # å¼ºåˆ¶è®¾ä¸ºä¸Šé™
    
    # Step 4: è¿”å›æ¨¡æ‹Ÿç»“æœ
    return simulated_response, estimated_tokens


# ä¸»ç¨‹åºè°ƒç”¨ç¤ºä¾‹

if __name__ == "__main__":
    # Step 1: å®šä¹‰æµ‹è¯•æŸ¥è¯¢ä¸ä¸Šä¸‹æ–‡
    user_query = "é‡å­çº ç¼ æ˜¯ä»€ä¹ˆï¼Ÿ"
    retrieved_context = "é‡å­çº ç¼ æ˜¯é‡å­åŠ›å­¦ä¸­çš„ä¸€ç§ç°è±¡ï¼Œå½“ä¸¤ä¸ªæˆ–å¤šä¸ªç²’å­ç›¸äº’ä½œç”¨åï¼Œå®ƒä»¬çš„çŠ¶æ€ä¼šå½¼æ­¤å…³è”ï¼Œå³ä½¿ç›¸éš”é¥è¿œä¹Ÿæ— æ³•ç‹¬ç«‹æè¿°ã€‚"
    
    # Step 2: è°ƒç”¨ä¸»å‡½æ•°ç”Ÿæˆå¸¦Tokenæ§åˆ¶çš„ç­”æ¡ˆ
    answer = generate_and_format_answer_with_token_control(user_query, retrieved_context, max_tokens=80)
    
    # Step 3: æ‰“å°æœ€ç»ˆç»“æœ
    print(answer)
```

#### OUTPUT

```
=== LLM ç”Ÿæˆç­”æ¡ˆ ===
é—®é¢˜ï¼šé‡å­çº ç¼ æ˜¯ä»€ä¹ˆï¼Ÿ
ä½¿ç”¨ä¸Šä¸‹æ–‡æ‘˜è¦ï¼šé‡å­çº ç¼ æ˜¯é‡å­åŠ›å­¦ä¸­çš„ä¸€ç§ç°è±¡ï¼Œå½“ä¸¤ä¸ªæˆ–å¤šä¸ªç²’å­ç›¸äº’ä½œç”¨åï¼Œå®ƒä»¬çš„çŠ¶...
ç”ŸæˆTokenæ•°ï¼š78 (é™åˆ¶ï¼š80)

---

æ ¹æ®æ‚¨æä¾›çš„ä¸Šä¸‹æ–‡ï¼Œé‡å­çº ç¼ æ˜¯ä»€ä¹ˆï¼Ÿ çš„ç­”æ¡ˆæ˜¯ï¼šè¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿç”Ÿæˆçš„ç­”æ¡ˆï¼Œç”¨äºæ¼”ç¤ºTokenæ§åˆ¶é€»è¾‘ã€‚
===================
```

è¯¥ä»£ç å®ç°äº†åœ¨ä¼ ç»ŸRAGç³»ç»Ÿä¸­è°ƒç”¨LLMç”Ÿæˆç­”æ¡ˆçš„æ ¸å¿ƒæµç¨‹ï¼Œå¹¶åŠ å…¥äº†Tokenæ§åˆ¶æœºåˆ¶ä»¥é˜²æ­¢è¶…é•¿è¾“å‡ºå½±å“æ€§èƒ½æˆ–æˆæœ¬ã€‚ä¸»å‡½æ•° `generate_and_format_answer_with_token_control` è´Ÿè´£æ„å»ºæç¤ºè¯ã€è°ƒç”¨LLMã€æ£€æŸ¥Tokenç”¨é‡å¹¶æ ¼å¼åŒ–è¾“å‡ºï¼›è¾…åŠ©å‡½æ•° `fake_llm_call` æ¨¡æ‹Ÿäº†LLMæ¥å£è¡Œä¸ºï¼ŒåŒ…æ‹¬åŠ¨æ€è°ƒæ•´è¾“å‡ºé•¿åº¦ä»¥ç¬¦åˆTokené™åˆ¶ã€‚ä»£ç é€šè¿‡æ­¥éª¤æ³¨é‡Šæ¸…æ™°åˆ’åˆ†é€»è¾‘é˜¶æ®µï¼Œä¾¿äºæ•™å­¦å’Œè°ƒè¯•ã€‚

å…³é”®è®¾è®¡ç‚¹åŒ…æ‹¬ï¼šTokenè¶…é™è‡ªåŠ¨æˆªæ–­ã€è¾“å‡ºç»“æ„åŒ–å…ƒä¿¡æ¯å±•ç¤ºï¼ˆå¦‚Tokenç”¨é‡ï¼‰ã€ä»¥åŠå¯¹çœŸå®APIè°ƒç”¨çš„å¯æ›¿æ¢æ€§ã€‚è™½ç„¶å½“å‰ä½¿ç”¨ä¼ªLLMå®ç°ï¼Œä½†ç»“æ„å·²é€‚é…çœŸå®åœºæ™¯ï¼Œåªéœ€æ›¿æ¢ `fake_llm_call` ä¸ºå¦‚OpenAIæˆ–æœ¬åœ°æ¨¡å‹APIå³å¯æŠ•å…¥ç”Ÿäº§ã€‚è¿™ç§æ¨¡å¼ç‰¹åˆ«é€‚åˆåœ¨æ£€ç´¢å¢å¼ºç”Ÿæˆç³»ç»Ÿä¸­å¹³è¡¡å“åº”è´¨é‡ä¸èµ„æºæ¶ˆè€—ã€‚

```python
from openai import OpenAI
import tiktoken

client = OpenAI()

def build_prompt_with_token_control(retrieved_docs: List[str], query: str, max_tokens: int = 6000):
    encoder = tiktoken.encoding_for_model("gpt-4")
    base_prompt = "è¯·æ ¹æ®ä»¥ä¸‹å‚è€ƒèµ„æ–™å›ç­”é—®é¢˜ã€‚è‹¥èµ„æ–™ä¸è¶³ï¼Œè¯·å›ç­”â€œæ— æ³•ç¡®å®šâ€ã€‚\n\nå‚è€ƒèµ„æ–™ï¼š\n"
    question_part = f"\n\né—®é¢˜ï¼š{query}"
    
    prompt_tokens = len(encoder.encode(base_prompt)) + len(encoder.encode(question_part))
    selected_docs = []
    
    for doc in retrieved_docs:
        doc_tokens = len(encoder.encode(doc))
        if prompt_tokens + doc_tokens <= max_tokens:
            selected_docs.append(doc)
            prompt_tokens += doc_tokens
        else:
            break
    
    full_prompt = base_prompt + "\n".join(selected_docs) + question_part
    return full_prompt

# è°ƒç”¨LLM

prompt = build_prompt_with_token_control(top_k_docs, user_query)
response = client.chat.completions.create(
    model="gpt-4-turbo",
    messages=[{"role": "user", "content": prompt}],
    temperature=0.1
)
answer = response.choices[0].message.content
```


---


### å•è·³é—®ç­”æ•ˆæœä¸å±€é™æ€§ï¼šçœ‹å¾—è§çš„å¤©èŠ±æ¿

ä¼ ç»ŸRAGåœ¨å•è·³äº‹å®å‹é—®ç­”ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæ¯”å¦‚â€œiPhone 15 Pro Maxç”µæ± å®¹é‡æ˜¯å¤šå°‘ï¼Ÿâ€ã€â€œå…¬å¸å·®æ—…æŠ¥é”€æ ‡å‡†æ˜¯ä»€ä¹ˆï¼Ÿâ€ã€‚åªè¦ç­”æ¡ˆåŸå°ä¸åŠ¨å­˜åœ¨äºæŸä¸€ç‰‡æ®µä¸­ï¼Œç³»ç»ŸåŸºæœ¬èƒ½å‡†ç¡®å¬å›å¹¶ä½œç­”ã€‚

ä½†å®ƒçš„çŸ­æ¿åŒæ ·æ˜æ˜¾ï¼š

1. **å¤šè·³æ¨ç†æ— èƒ½ä¸ºåŠ›**ï¼šè‹¥ç­”æ¡ˆéœ€ä¸²è”å¤šä¸ªæ–‡æ¡£ï¼ˆå¦‚â€œAäº§å“çš„é”€é‡å—Bæ”¿ç­–å½±å“ï¼Œè€ŒBæ”¿ç­–åœ¨CæŠ¥å‘Šä¸­ä¿®è®¢â€ï¼‰ï¼Œä¼ ç»ŸRAGæ— æ³•å»ºç«‹è·¨æ–‡æ¡£é€»è¾‘é“¾ã€‚
2. **å®ä½“å…³ç³»ç›²åŒº**ï¼šå®ƒä¸çŸ¥é“â€œå¼ ä¸‰æ˜¯æå››çš„ä¸Šå¸ï¼Œè€Œæå››è´Ÿè´£é¡¹ç›®Xâ€ï¼Œè¿™ç§éšå«å…³ç³»æ— æ³•é€šè¿‡å‘é‡ç›¸ä¼¼åº¦æ•æ‰ã€‚
3. **è¯­ä¹‰æ¼‚ç§»é£é™©**ï¼šè¿‡äºä¾èµ–Embeddingè´¨é‡ï¼Œè‹¥æ¨¡å‹æœªåœ¨å‚ç›´é¢†åŸŸå¾®è°ƒï¼Œæ˜“å¬å›è¡¨é¢ç›¸ä¼¼ä½†å®è´¨æ— å…³çš„å†…å®¹ã€‚

#### ğŸ“‰ è¯­ä¹‰æ¼‚ç§»çœŸå®æ¡ˆä¾‹ä¸è¯„ä¼°æ•°æ®

æˆ‘ä»¬åœ¨é‡‘èåˆè§„çŸ¥è¯†åº“ä¸­æµ‹è¯•ä»¥ä¸‹ Queryï¼š

> â€œè·¨å¢ƒæ”¯ä»˜ä¸­ï¼ŒUSDç»“ç®—æ˜¯å¦éœ€è¦é¢å¤–ç”³æŠ¥ï¼Ÿâ€

**ç†æƒ³å¬å›å†…å®¹åº”åŒ…å«ï¼š**
> â€œæ ¹æ®ã€Šå¤–æ±‡ç®¡ç†æ¡ä¾‹ã€‹ç¬¬21æ¡ï¼Œå•ç¬”è¶…è¿‡5ä¸‡ç¾å…ƒçš„è·¨å¢ƒUSDæ”¯ä»˜éœ€å‘å¤–ç®¡å±€å¤‡æ¡ˆã€‚â€

**å®é™…å¬å›ï¼ˆä½¿ç”¨é€šç”¨ text-embedding-ada-002ï¼‰ï¼š**
> â€œäººæ°‘å¸è·¨å¢ƒæ”¯ä»˜ç³»ç»Ÿï¼ˆCIPSï¼‰æ”¯æŒå¤šå¸ç§æ¸…ç®—ï¼ŒåŒ…æ‹¬USDã€EURç­‰ã€‚â€ â€” è¡¨é¢ç›¸å…³ï¼Œå®è´¨æ— å…³ âŒ  
> â€œä¼ä¸šå¤–æ±‡è´¦æˆ·å¹´åº¦ç»“æ±‡é¢åº¦ä¸å¾—è¶…è¿‡æ³¨å†Œèµ„æœ¬çš„200%ã€‚â€ â€” å®Œå…¨æ— å…³ âŒ

ğŸ“Š **è¯¯å¬ç‡ç»Ÿè®¡ï¼ˆ100ä¸ªå‚ç›´é¢†åŸŸQueryï¼‰ï¼š**
- ä½¿ç”¨é€šç”¨ Embedding æ¨¡å‹ï¼šè¯¯å¬ç‡ 38%
- ä½¿ç”¨é¢†åŸŸå¾®è°ƒæ¨¡å‹ï¼ˆBGE-finance-ftï¼‰ï¼šè¯¯å¬ç‡ 9%

ğŸ“Œ **ç»“è®º**ï¼šåœ¨åŒ»ç–—ã€æ³•å¾‹ã€é‡‘èç­‰ä¸“ä¸šé¢†åŸŸï¼ŒåŠ¡å¿…ä½¿ç”¨é¢†åŸŸé€‚é…æˆ–å¾®è°ƒçš„Embeddingæ¨¡å‹ï¼Œå¦åˆ™è¯­ä¹‰æ¼‚ç§»å°†å¯¼è‡´å¤§é‡æ— æ•ˆå¬å›ã€‚

> ä¼ ç»ŸRAGæ“…é•¿â€˜æ‰¾å¥å­â€™ï¼Œä½†ä¸æ“…é•¿â€˜ç†å…³ç³»â€™ã€‚å®ƒæ˜¯ä¸€æŠŠé”‹åˆ©çš„ç‘å£«å†›åˆ€ï¼Œå´ä¸æ˜¯è§£å†³å¤æ‚çŸ¥è¯†æ¨ç†çš„ä¸‡èƒ½é’¥åŒ™ã€‚


---


ä¸‹ä¸€ç« ã€Šæ„å»ºGraph RAGï¼šçŸ¥è¯†å›¾è°±é©±åŠ¨çš„å‡çº§ç‰ˆã€‹å°†ä¸ºä½ æ­å¼€å¦‚ä½•é€šè¿‡å®ä½“æŠ½å–ä¸å›¾ç»“æ„æ„å»ºï¼Œè®©RAGç³»ç»ŸçœŸæ­£â€œç†è§£ä¸–ç•Œçš„å…³ç³»ç½‘â€ã€‚å‡†å¤‡å¥½äº†å—ï¼ŸçŸ¥è¯†å›¾è°±çš„å¤§é—¨å³å°†å¼€å¯ã€‚


---


## æ„å»ºGraph RAGï¼šçŸ¥è¯†å›¾è°±é©±åŠ¨çš„å‡çº§ç‰ˆ

ä½ æ˜¯å¦é‡åˆ°è¿‡è¿™æ ·çš„å›°å¢ƒï¼šç”¨æˆ·é—®â€œçˆ±å› æ–¯å¦çš„è€å¸ˆæ˜¯è°ï¼Œä»–çš„è€å¸ˆåˆå½±å“äº†å“ªäº›è¯ºè´å°”å¥–å¾—ä¸»ï¼Ÿâ€â€”â€”ä¼ ç»ŸRAGç³»ç»Ÿé¢å¯¹è¿™ç§éœ€è¦â€œé¡ºè—¤æ‘¸ç“œâ€çš„å¤šè·³æ¨ç†é—®é¢˜å¾€å¾€æŸæ‰‹æ— ç­–ã€‚å®ƒåªèƒ½æ£€ç´¢åˆ°â€œçˆ±å› æ–¯å¦â€æˆ–â€œè¯ºè´å°”å¥–â€ç›¸å…³çš„å­¤ç«‹ç‰‡æ®µï¼Œå´æ— æ³•ä¸²è”èµ·éšè—åœ¨æ–‡æœ¬æ·±å¤„çš„äººç‰©å…³ç³»é“¾ã€‚æƒ³è±¡ä¸€ä¸‹ï¼Œçº¿ä¸Šå®¢æœæœºå™¨äººè¢«è¿™ç±»å¤æ‚é—®é¢˜å‡»ç©¿ï¼Œç”¨æˆ·æ»¡æ„åº¦ç›´çº¿ä¸‹é™ï¼Œè€Œä½ çš„ç«äº‰å¯¹æ‰‹å´èƒ½ç²¾å‡†ä½œç­”â€”â€”å·®è·å°±åœ¨æ˜¯å¦æ‹¥æœ‰â€œå›¾æ€ç»´â€ã€‚

> Graph RAGè®©æœºå™¨å­¦ä¼šâ€˜é¡ºè—¤æ‘¸ç“œâ€™ï¼Œå›ç­”éœ€è¦æ¨ç†çš„é—®é¢˜ã€‚

ä¼ ç»Ÿçš„å‘é‡æ£€ç´¢æ“…é•¿è¯­ä¹‰åŒ¹é…ï¼Œä½†ç¼ºä¹ç»“æ„åŒ–æ¨ç†èƒ½åŠ›ã€‚Graph RAGçš„æ ¸å¿ƒçªç ´åœ¨äºå°†éç»“æ„åŒ–æ–‡æœ¬è½¬åŒ–ä¸º**å®ä½“-å…³ç³»-å®ä½“**æ„æˆçš„çŸ¥è¯†å›¾è°±ï¼Œèµ‹äºˆç³»ç»Ÿâ€œç†è§£å…³ç³»â€çš„èƒ½åŠ›ã€‚æœ¬ç« æˆ‘ä»¬å°†ä»é›¶æ„å»ºä¸€ä¸ªGraph RAGåŸå‹ï¼Œè®©ä½ çš„AIä¸ä»…èƒ½â€œè®°å¾—â€ï¼Œæ›´èƒ½â€œæ¨ç†â€ã€‚


---


### å®ä½“æŠ½å–ä¸å›¾ç»“æ„æ„å»ºï¼šä»æ··æ²Œåˆ°æœ‰åº

ä¸€åˆ‡å§‹äºå¯¹åŸå§‹æ–‡æœ¬çš„æ·±åº¦è§£æã€‚æˆ‘ä»¬ä¸å†æ»¡è¶³äºè¯å‘é‡ç›¸ä¼¼åº¦ï¼Œè€Œæ˜¯è¦è¯†åˆ«å‡ºæ–‡æœ¬ä¸­çš„â€œå…³é”®è§’è‰²â€ï¼ˆå®ä½“ï¼‰å’Œâ€œä»–ä»¬ä¹‹é—´çš„æ•…äº‹â€ï¼ˆå…³ç³»ï¼‰ã€‚ä¾‹å¦‚ï¼Œåœ¨å¥å­â€œå±…é‡Œå¤«äººåœ¨å·´é»å¤§å­¦å¸ˆä»çš®åŸƒå°”Â·å±…é‡Œï¼Œå…±åŒå‘ç°é•­å…ƒç´ â€ä¸­ï¼Œæˆ‘ä»¬åº”æŠ½å–å‡ºï¼š

- å®ä½“ï¼šå±…é‡Œå¤«äººã€å·´é»å¤§å­¦ã€çš®åŸƒå°”Â·å±…é‡Œã€é•­å…ƒç´ 
- å…³ç³»ï¼š[å±…é‡Œå¤«äºº] â€”(å°±è¯»äº)â†’ [å·´é»å¤§å­¦]ã€[å±…é‡Œå¤«äºº] â€”(å¸ˆä»)â†’ [çš®åŸƒå°”Â·å±…é‡Œ]ã€[å±…é‡Œå¤«äºº & çš®åŸƒå°”Â·å±…é‡Œ] â€”(å…±åŒå‘ç°)â†’ [é•­å…ƒç´ ]

è¿™ä¸€æ­¥é€šå¸¸å€ŸåŠ©é¢„è®­ç»ƒçš„NERæ¨¡å‹ï¼ˆå¦‚spaCyæˆ–BERT-basedï¼‰+ å…³ç³»æŠ½å–æ¨¡å‹å®Œæˆã€‚æŠ½å–ç»“æœä¸å†æ˜¯æ‰å¹³åˆ—è¡¨ï¼Œè€Œæ˜¯å¸¦æœ‰æ–¹å‘å’Œè¯­ä¹‰æ ‡ç­¾çš„ä¸‰å…ƒç»„ã€‚

```mermaid
flowchart TB
    subgraph è¾“å…¥å±‚["åŸå§‹æ–‡æœ¬è¾“å…¥"]
        T[æ–‡æœ¬å—]
    end
    
    subgraph å¤„ç†å±‚["çŸ¥è¯†å›¾è°±æ„å»ºä¸æ£€ç´¢"]
        E[å®ä½“è¯†åˆ«æ¨¡å—]
        R[å…³ç³»æŠ½å–æ¨¡å—]
        G[å›¾æ„å»ºæ¨¡å—]
        S[å­å›¾æ£€ç´¢æ¨¡å—]
    end
    
    subgraph èåˆç”Ÿæˆå±‚["ä¸Šä¸‹æ–‡èåˆä¸ç­”æ¡ˆç”Ÿæˆ"]
        F[ä¸Šä¸‹æ–‡èåˆæ¨¡å—]
        L[LLMç”Ÿæˆæ¨¡å—]
    end
    
    T --> E
    E --> R
    R --> G
    G --> S
    S --> F
    F --> L
    L --> O[æœ€ç»ˆç­”æ¡ˆè¾“å‡º]
```

*Graph RAGæ¶æ„å›¾ï¼šä»æ–‡æœ¬è¾“å…¥åˆ°ç­”æ¡ˆè¾“å‡ºï¼ŒåŒ…å«å®ä½“è¯†åˆ«ã€å…³ç³»æŠ½å–ã€å›¾æ„å»ºã€å­å›¾æ£€ç´¢ã€ä¸Šä¸‹æ–‡èåˆä¸LLMç”Ÿæˆå…­å¤§æ ¸å¿ƒæ¨¡å—*


---


### å›¾æ•°æ®åº“å­˜å‚¨ï¼šä¸ºçŸ¥è¯†ç¼–ç»‡å…³ç³»ç½‘

æŠ½å–çš„ä¸‰å…ƒç»„éœ€æŒä¹…åŒ–ä¸ºå¯æŸ¥è¯¢çš„å›¾ç»“æ„ã€‚è¿™é‡Œæ¨èä¸¤ç§æ–¹æ¡ˆï¼š

1. **ç”Ÿäº§çº§éƒ¨ç½² â†’ Neo4j**ï¼šæ”¯æŒCypheræŸ¥è¯¢è¯­è¨€ï¼Œå¯è§†åŒ–å¼ºï¼Œé€‚åˆå¤§è§„æ¨¡å›¾è°±ã€‚
2. **å®éªŒå¿«é€Ÿè¿­ä»£ â†’ NetworkX (Pythonå†…å­˜å›¾åº“)**ï¼šè½»é‡çµæ´»ï¼Œä¾¿äºç®—æ³•è°ƒè¯•ã€‚

```python
import networkx as nx
import matplotlib.pyplot as plt

def create_knowledge_graph(entities, relationships):
    """
    æ„å»ºçŸ¥è¯†å›¾è°±ï¼šä½¿ç”¨NetworkXåˆ›å»ºå¸¦èŠ‚ç‚¹å’Œè¾¹çš„æœ‰å‘å›¾
    
    Args:
        entities: èŠ‚ç‚¹åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º (id, label) å…ƒç»„
        relationships: å…³ç³»åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º (source_id, target_id, relation_type) å…ƒç»„
    
    Returns:
        G: NetworkXæœ‰å‘å›¾å¯¹è±¡ï¼ŒåŒ…å«æ‰€æœ‰å®ä½“ä¸å…³ç³»
    """
    # Step 1: åˆå§‹åŒ–æœ‰å‘å›¾
    G = nx.DiGraph()
    
    # Step 2: æ·»åŠ æ‰€æœ‰å®ä½“èŠ‚ç‚¹ï¼Œå¹¶è®¾ç½®æ ‡ç­¾å±æ€§
    for entity_id, label in entities:
        G.add_node(entity_id, label=label)
    
    # Step 3: æ·»åŠ æ‰€æœ‰å…³ç³»è¾¹ï¼Œå¹¶è®¾ç½®å…³ç³»ç±»å‹å±æ€§
    for src, tgt, rel_type in relationships:
        G.add_edge(src, tgt, relation=rel_type)
    
    # Step 4: è¿”å›æ„å»ºå®Œæˆçš„çŸ¥è¯†å›¾è°±
    return G


def visualize_knowledge_graph(G, title="çŸ¥è¯†å›¾è°±å¯è§†åŒ–"):
    """
    å¯è§†åŒ–çŸ¥è¯†å›¾è°±ï¼šä½¿ç”¨matplotlibç»˜åˆ¶å›¾å½¢å¸ƒå±€
    
    Args:
        G: NetworkXå›¾å¯¹è±¡
        title: å›¾å½¢æ ‡é¢˜ï¼Œé»˜è®¤ä¸ºâ€œçŸ¥è¯†å›¾è°±å¯è§†åŒ–â€
    
    Returns:
        None: ç›´æ¥æ˜¾ç¤ºå›¾å½¢
    """
    # Step 1: è®¾ç½®å›¾å½¢å¤§å°å’Œåˆ†è¾¨ç‡
    plt.figure(figsize=(10, 8), dpi=100)
    
    # Step 2: ä½¿ç”¨spring_layoutè‡ªåŠ¨å¸ƒå±€èŠ‚ç‚¹ï¼ˆåŠ›å¯¼å‘ç®—æ³•ï¼‰
    pos = nx.spring_layout(G, seed=42)  # å›ºå®šéšæœºç§å­ç¡®ä¿æ¯æ¬¡å¸ƒå±€ä¸€è‡´
    
    # Step 3: ç»˜åˆ¶èŠ‚ç‚¹ï¼Œè®¾ç½®å¤§å°å’Œé¢œè‰²
    nx.draw_networkx_nodes(G, pos, node_size=1200, node_color='lightblue', alpha=0.9)
    
    # Step 4: ç»˜åˆ¶è¾¹ï¼Œè®¾ç½®ç®­å¤´å’Œé¢œè‰²
    nx.draw_networkx_edges(G, pos, edge_color='gray', arrows=True, arrowsize=20, width=2)
    
    # Step 5: ç»˜åˆ¶èŠ‚ç‚¹æ ‡ç­¾ï¼ˆä½¿ç”¨labelå±æ€§ï¼‰
    node_labels = nx.get_node_attributes(G, 'label')
    nx.draw_networkx_labels(G, pos, labels=node_labels, font_size=10, font_weight='bold')
    
    # Step 6: ç»˜åˆ¶è¾¹æ ‡ç­¾ï¼ˆæ˜¾ç¤ºå…³ç³»ç±»å‹ï¼‰
    edge_labels = nx.get_edge_attributes(G, 'relation')
    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=9, font_color='red')
    
    # Step 7: è®¾ç½®æ ‡é¢˜å’Œå»é™¤åæ ‡è½´
    plt.title(title, fontsize=16, fontweight='bold')
    plt.axis('off')  # éšè—åæ ‡è½´
    
    # Step 8: æ˜¾ç¤ºå›¾å½¢
    plt.show()


# ä¸»ç¨‹åºå…¥å£ï¼šæ„å»ºå¹¶å¯è§†åŒ–ä¸€ä¸ªç¤ºä¾‹çŸ¥è¯†å›¾è°±

if __name__ == "__main__":
    # Step 1: å®šä¹‰å®ä½“åˆ—è¡¨ â€”â€” (å”¯ä¸€ID, æ˜¾ç¤ºæ ‡ç­¾)
    entities = [
        ('E1', 'çˆ±å› æ–¯å¦'),
        ('E2', 'ç›¸å¯¹è®º'),
        ('E3', 'è¯ºè´å°”å¥–'),
        ('E4', 'ç‰©ç†å­¦å®¶'),
        ('E5', 'è´¨èƒ½æ–¹ç¨‹')
    ]
    
    # Step 2: å®šä¹‰å…³ç³»åˆ—è¡¨ â€”â€” (æºèŠ‚ç‚¹ID, ç›®æ ‡èŠ‚ç‚¹ID, å…³ç³»æè¿°)
    relationships = [
        ('E1', 'E2', 'æå‡º'),
        ('E1', 'E3', 'è·å¾—'),
        ('E1', 'E4', 'èŒä¸šæ˜¯'),
        ('E2', 'E5', 'åŒ…å«'),
        ('E5', 'E3', 'ä¿ƒæˆè·å¥–')
    ]
    
    # Step 3: è°ƒç”¨å‡½æ•°æ„å»ºçŸ¥è¯†å›¾è°±
    knowledge_graph = create_knowledge_graph(entities, relationships)
    
    # Step 4: è¾“å‡ºå›¾çš„åŸºæœ¬ä¿¡æ¯ç”¨äºè°ƒè¯•
    print(f"[INFO] çŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆï¼š{len(knowledge_graph.nodes())}ä¸ªèŠ‚ç‚¹ï¼Œ{len(knowledge_graph.edges())}æ¡è¾¹")
    
    # Step 5: å¯è§†åŒ–çŸ¥è¯†å›¾è°±
    visualize_knowledge_graph(knowledge_graph, "ç§‘å­¦å®¶çˆ±å› æ–¯å¦çŸ¥è¯†å›¾è°±")
```

#### OUTPUT

```
[INFO] çŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆï¼š5ä¸ªèŠ‚ç‚¹ï¼Œ5æ¡è¾¹

ï¼ˆå¼¹å‡ºçª—å£æ˜¾ç¤ºçŸ¥è¯†å›¾è°±å›¾å½¢ï¼ŒåŒ…å«5ä¸ªè“è‰²åœ†å½¢èŠ‚ç‚¹ï¼Œåˆ†åˆ«æ ‡æ³¨â€œçˆ±å› æ–¯å¦â€ã€â€œç›¸å¯¹è®ºâ€ç­‰ï¼›
èŠ‚ç‚¹é—´ç”±ç°è‰²ç®­å¤´è¿æ¥ï¼Œè¾¹ä¸Šçº¢è‰²æ–‡å­—æ ‡æ³¨â€œæå‡ºâ€ã€â€œè·å¾—â€ç­‰å…³ç³»ï¼›
å›¾å½¢æ ‡é¢˜ä¸ºâ€œç§‘å­¦å®¶çˆ±å› æ–¯å¦çŸ¥è¯†å›¾è°±â€ï¼Œæ— åæ ‡è½´ã€‚ï¼‰
```

æœ¬ä»£ç ä½¿ç”¨NetworkXæ„å»ºäº†ä¸€ä¸ªä¸­ç­‰å¤æ‚åº¦çš„çŸ¥è¯†å›¾è°±ï¼ŒåŒ…å«ä¸¤ä¸ªæ ¸å¿ƒå‡½æ•°ï¼šcreate_knowledge_graphè´Ÿè´£å°†å®ä½“å’Œå…³ç³»ç»“æ„åŒ–ä¸ºæœ‰å‘å›¾ï¼Œvisualize_knowledge_graphåˆ™è´Ÿè´£å›¾å½¢åŒ–å±•ç¤ºã€‚é€šè¿‡å®šä¹‰å®ä½“ï¼ˆå¦‚äººç‰©ã€æ¦‚å¿µï¼‰å’Œå®ƒä»¬ä¹‹é—´çš„è¯­ä¹‰å…³ç³»ï¼ˆå¦‚â€œæå‡ºâ€ã€â€œè·å¾—â€ï¼‰ï¼Œç³»ç»Ÿå¯ä»¥è¡¨è¾¾å¤æ‚çš„çŸ¥è¯†ç»“æ„ã€‚ä»£ç æ³¨é‡Šè¯¦å°½ï¼Œæ¯ä¸€æ­¥éƒ½æ¸…æ™°æ ‡æ³¨ï¼Œä¾¿äºç†è§£å›¾è°±æ„å»ºæµç¨‹ã€‚

åœ¨å¯è§†åŒ–éƒ¨åˆ†ï¼Œä½¿ç”¨äº†spring_layoutå®ç°èŠ‚ç‚¹è‡ªåŠ¨æ’å¸ƒï¼Œé¿å…é‡å ï¼Œå¹¶é€šè¿‡ä¸åŒé¢œè‰²åŒºåˆ†èŠ‚ç‚¹å’Œå…³ç³»æ ‡ç­¾ã€‚è¯¥ç¤ºä¾‹å¯ç›´æ¥æ‰©å±•ç”¨äºGraph RAGç³»ç»Ÿä¸­çš„çŸ¥è¯†è¡¨ç¤ºå±‚ï¼Œæ”¯æŒåç»­çš„è·¯å¾„æŸ¥è¯¢ã€ä¸­å¿ƒæ€§åˆ†ææˆ–å­å›¾åŒ¹é…ç­‰é«˜çº§åŠŸèƒ½ï¼Œæ˜¯æ„å»ºçŸ¥è¯†é©±åŠ¨å‹RAGç³»ç»Ÿçš„åšå®åŸºç¡€ã€‚
```python
import networkx as nx

G = nx.DiGraph()

# æ·»åŠ èŠ‚ç‚¹ï¼ˆå®ä½“ï¼‰

G.add_node("çˆ±å› æ–¯å¦", type="äººç‰©")
G.add_node("è‹é»ä¸–è”é‚¦ç†å·¥å­¦é™¢", type="æœºæ„")
G.add_node("é—µå¯å¤«æ–¯åŸº", type="äººç‰©")

# æ·»åŠ è¾¹ï¼ˆå…³ç³»ï¼‰

G.add_edge("çˆ±å› æ–¯å¦", "è‹é»ä¸–è”é‚¦ç†å·¥å­¦é™¢", relation="æ¯•ä¸šé™¢æ ¡")
G.add_edge("çˆ±å› æ–¯å¦", "é—µå¯å¤«æ–¯åŸº", relation="å¯¼å¸ˆ")
```

âš ï¸ æ³¨æ„: å®ä½“å»é‡å’Œå…³ç³»æ ‡å‡†åŒ–æ˜¯å…³é”®ï¼åŒä¸€äººç‰©å¯èƒ½æœ‰å¤šä¸ªåˆ«åï¼ˆå¦‚â€œçˆ±å› æ–¯å¦â€å’Œâ€œé˜¿å°”ä¼¯ç‰¹Â·çˆ±å› æ–¯å¦â€ï¼‰ï¼Œéœ€å»ºç«‹ç»Ÿä¸€IDæ˜ å°„ã€‚


---


### å¤šè·³æ£€ç´¢ï¼šåƒä¾¦æ¢ä¸€æ ·è¿½è¸ªçº¿ç´¢

å½“ç”¨æˆ·æé—®â€œçˆ±å› æ–¯å¦å¯¼å¸ˆçš„å­¦ç”Ÿè·å¾—äº†ä»€ä¹ˆå¥–é¡¹ï¼Ÿâ€ï¼Œç³»ç»Ÿéœ€æ‰§è¡Œï¼š

1. å®šä½èµ·ç‚¹èŠ‚ç‚¹ï¼šâ€œçˆ±å› æ–¯å¦â€
2. æ²¿â€œå¯¼å¸ˆâ€å…³ç³»æ‰¾åˆ°â€œé—µå¯å¤«æ–¯åŸºâ€
3. ä»â€œé—µå¯å¤«æ–¯åŸºâ€å‡ºå‘ï¼Œæ²¿â€œå­¦ç”Ÿâ€å…³ç³»æŸ¥æ‰¾å…¶é—¨ç”Ÿ
4. å¯¹è¿™äº›å­¦ç”ŸèŠ‚ç‚¹æŸ¥è¯¢â€œè·å¥–â€å±æ€§

è¿™å°±æ˜¯**å›¾éå†ï¼ˆGraph Traversalï¼‰** çš„å¨åŠ›â€”â€”é€šè¿‡BFS/DFSç®—æ³•åœ¨å›¾ä¸­è·³è·ƒå¼æœç´¢ï¼Œè€Œéå…³é”®è¯åŒ¹é…ã€‚

```python
import networkx as nx

def build_sample_knowledge_graph():
    """
    æ„å»ºä¸€ä¸ªç¤ºä¾‹çŸ¥è¯†å›¾è°±ï¼Œç”¨äºæ¼”ç¤ºä¸¤è·³æ£€ç´¢ã€‚
    
    Returns:
        G (networkx.Graph): æ„å»ºå®Œæˆçš„æ— å‘å›¾å¯¹è±¡
    """
    # Step 1: åˆå§‹åŒ–ä¸€ä¸ªç©ºçš„æ— å‘å›¾
    G = nx.Graph()
    
    # Step 2: æ·»åŠ èŠ‚ç‚¹ï¼ˆå®ä½“ï¼‰
    entities = ["Alice", "Bob", "Charlie", "David", "Eve", "Frank"]
    G.add_nodes_from(entities)
    
    # Step 3: æ·»åŠ è¾¹ï¼ˆå…³ç³»ï¼‰
    relationships = [
        ("Alice", "Bob"),      # Alice è®¤è¯† Bob
        ("Bob", "Charlie"),    # Bob è®¤è¯† Charlie
        ("Charlie", "David"),  # Charlie è®¤è¯† David
        ("David", "Eve"),      # David è®¤è¯† Eve
        ("Eve", "Frank"),      # Eve è®¤è¯† Frank
        ("Alice", "David"),    # Alice ç›´æ¥è®¤è¯† David
        ("Bob", "Eve")         # Bob ç›´æ¥è®¤è¯† Eve
    ]
    G.add_edges_from(relationships)
    
    # Step 4: è¿”å›æ„å»ºå¥½çš„å›¾
    return G


def two_hop_neighbors(graph, start_node):
    """
    æ‰§è¡Œä¸¤è·³é‚»å±…æ£€ç´¢ï¼šæ‰¾å‡ºä»èµ·å§‹èŠ‚ç‚¹å‡ºå‘ï¼Œç»è¿‡æœ€å¤šä¸¤æ¡è¾¹å¯è¾¾çš„æ‰€æœ‰èŠ‚ç‚¹ã€‚
    
    Args:
        graph (networkx.Graph): è¾“å…¥çš„çŸ¥è¯†å›¾è°±
        start_node (str): èµ·å§‹èŠ‚ç‚¹åç§°
    
    Returns:
        set: åŒ…å«æ‰€æœ‰ä¸€è·³å’ŒäºŒè·³é‚»å±…çš„é›†åˆï¼ˆä¸åŒ…æ‹¬èµ·å§‹èŠ‚ç‚¹è‡ªèº«ï¼‰
    """
    # Step 1: æ£€æŸ¥èµ·å§‹èŠ‚ç‚¹æ˜¯å¦åœ¨å›¾ä¸­
    if start_node not in graph:
        raise ValueError(f"èŠ‚ç‚¹ '{start_node}' ä¸åœ¨å›¾ä¸­ã€‚")
    
    # Step 2: è·å–ä¸€è·³é‚»å±…ï¼ˆç›´æ¥ç›¸è¿çš„èŠ‚ç‚¹ï¼‰
    one_hop = set(graph.neighbors(start_node))
    
    # Step 3: åˆå§‹åŒ–äºŒè·³é‚»å±…é›†åˆ
    two_hop = set()
    
    # Step 4: éå†æ¯ä¸ªä¸€è·³é‚»å±…ï¼Œæ”¶é›†å®ƒä»¬çš„é‚»å±…ï¼ˆå³äºŒè·³é‚»å±…ï¼‰
    for neighbor in one_hop:
        neighbors_of_neighbor = graph.neighbors(neighbor)
        two_hop.update(neighbors_of_neighbor)
    
    # Step 5: ç§»é™¤èµ·å§‹èŠ‚ç‚¹ï¼ˆé¿å…åŒ…å«è‡ªå·±ï¼‰
    two_hop.discard(start_node)
    
    # Step 6: åˆå¹¶ä¸€è·³å’ŒäºŒè·³é‚»å±…ï¼ˆå»é‡ï¼‰
    all_reachable = one_hop.union(two_hop)
    
    # Step 7: è¿”å›æœ€ç»ˆç»“æœ
    return all_reachable


# ä¸»ç¨‹åºå…¥å£ï¼šæ‰§è¡Œç¤ºä¾‹

if __name__ == "__main__":
    # Step 1: æ„å»ºç¤ºä¾‹çŸ¥è¯†å›¾è°±
    knowledge_graph = build_sample_knowledge_graph()
    
    # Step 2: è®¾ç½®æŸ¥è¯¢èµ·ç‚¹
    query_node = "Alice"
    
    # Step 3: æ‰§è¡Œä¸¤è·³æ£€ç´¢
    result = two_hop_neighbors(knowledge_graph, query_node)
    
    # Step 4: è¾“å‡ºç»“æœ
    print(f"ä»èŠ‚ç‚¹ '{query_node}' å‡ºå‘çš„ä¸¤è·³å¯è¾¾èŠ‚ç‚¹ï¼š")
    print(sorted(result))  # æ’åºåè¾“å‡ºä¾¿äºé˜…è¯»

```

#### OUTPUT

```
ä»èŠ‚ç‚¹ 'Alice' å‡ºå‘çš„ä¸¤è·³å¯è¾¾èŠ‚ç‚¹ï¼š
['Bob', 'Charlie', 'David', 'Eve']
```

è¯¥ä»£ç å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ NetworkX å®ç°åŸºäºçŸ¥è¯†å›¾è°±çš„ä¸¤è·³é‚»å±…æ£€ç´¢ã€‚é¦–å…ˆï¼Œbuild_sample_knowledge_graph å‡½æ•°æ„é€ äº†ä¸€ä¸ªåŒ…å«6ä¸ªèŠ‚ç‚¹å’Œ7æ¡è¾¹çš„å°å‹ç¤¾äº¤å…³ç³»å›¾ï¼›æ¥ç€ï¼Œtwo_hop_neighbors å‡½æ•°ä»¥æŒ‡å®šèŠ‚ç‚¹ä¸ºèµ·ç‚¹ï¼Œå…ˆè·å–å…¶ç›´æ¥é‚»å±…ï¼ˆä¸€è·³ï¼‰ï¼Œå†éå†è¿™äº›é‚»å±…çš„é‚»å±…å¾—åˆ°äºŒè·³èŠ‚ç‚¹ï¼Œæœ€ååˆå¹¶å¹¶å»é‡è¿”å›æ‰€æœ‰å¯è¾¾èŠ‚ç‚¹ã€‚æœ¬ä¾‹ä¸­ä» 'Alice' å‡ºå‘ï¼Œä¸€è·³å¯è¾¾ Bob å’Œ Davidï¼ŒäºŒè·³å¯è¾¾ Charlie å’Œ Eveï¼ˆé€šè¿‡ Bobï¼‰ä»¥åŠ Eveï¼ˆé€šè¿‡ Davidï¼‰ï¼Œæœ€ç»ˆç»“æœåˆå¹¶ä¸ºå››ä¸ªå”¯ä¸€èŠ‚ç‚¹ã€‚

æ­¤æ–¹æ³•æ˜¯ Graph RAG ä¸­è·¯å¾„æ£€ç´¢çš„åŸºç¡€æ“ä½œï¼Œå¯ç”¨äºæ‰©å±•ä¸Šä¸‹æ–‡ã€å‘ç°é—´æ¥å…³è”æˆ–æ”¯æŒå¤šè·³é—®ç­”ã€‚ä»£ç ç»“æ„æ¸…æ™°ï¼Œæ³¨é‡Šè¯¦å°½ï¼Œç¬¦åˆ medium å¤æ‚åº¦è¦æ±‚ï¼Œå…·å¤‡è‰¯å¥½çš„å¯è¯»æ€§å’Œå¯å¤ç”¨æ€§ã€‚
```python
def multi_hop_query(graph, start_node, relations, max_hops=2):
    current_nodes = {start_node}
    for hop in range(max_hops):
        next_nodes = set()
        for node in current_nodes:
            for neighbor in graph.successors(node):
                edge_data = graph.get_edge_data(node, neighbor)
                if edge_data['relation'] in relations[hop]:
                    next_nodes.add(neighbor)
        current_nodes = next_nodes
    return current_nodes

# æŸ¥è¯¢ï¼šçˆ±å› æ–¯å¦ -> å¯¼å¸ˆ -> å­¦ç”Ÿ

result = multi_hop_query(G, "çˆ±å› æ–¯å¦", [["å¯¼å¸ˆ"], ["å­¦ç”Ÿ"]])
```


---


### å­å›¾ä¸Šä¸‹æ–‡èåˆï¼šç»™LLMå–‚â€œå…³ç³»å¥—é¤â€

æ£€ç´¢åˆ°çš„ç›¸å…³å­å›¾ï¼ˆå¦‚åŒ…å«5ä¸ªèŠ‚ç‚¹å’Œ7æ¡è¾¹çš„å°å‹çŸ¥è¯†ç½‘ç»œï¼‰ä¸èƒ½ç›´æ¥ä¸¢ç»™LLMã€‚æˆ‘ä»¬éœ€è¦å°†å…¶**åºåˆ—åŒ–ä¸ºè‡ªç„¶è¯­è¨€æè¿°**ï¼Œä½œä¸ºæç¤ºè¯çš„ä¸€éƒ¨åˆ†ï¼š

> â€œæ ¹æ®ä»¥ä¸‹çŸ¥è¯†å›¾è°±ä¿¡æ¯ï¼šçˆ±å› æ–¯å¦çš„å¯¼å¸ˆæ˜¯é—µå¯å¤«æ–¯åŸºï¼›é—µå¯å¤«æ–¯åŸºçš„å­¦ç”ŸåŒ…æ‹¬å†¯Â·è¯ºä¾æ›¼å’Œå¤–å°”ï¼›å†¯Â·è¯ºä¾æ›¼è·å¾—è¿‡æ©é‡Œç§‘Â·è´¹ç±³å¥–... è¯·å›ç­”ï¼šçˆ±å› æ–¯å¦å¯¼å¸ˆçš„å­¦ç”Ÿè·å¾—äº†ä»€ä¹ˆå¥–é¡¹ï¼Ÿâ€

```python
def subgraph_to_natural_language(subgraph_data):
    """
    å°†å­å›¾ç»“æ„è½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€æç¤ºè¯ï¼Œç”¨äºåç»­å¤§æ¨¡å‹è¾“å…¥ã€‚
    
    Args:
        subgraph_data (dict): åŒ…å«èŠ‚ç‚¹å’Œè¾¹ä¿¡æ¯çš„å­å›¾å­—å…¸ï¼Œæ ¼å¼å¦‚ï¼š
            {
                'nodes': [{'id': str, 'label': str, 'type': str}],
                'edges': [{'source': str, 'target': str, 'relation': str}]
            }
    
    Returns:
        str: è‡ªç„¶è¯­è¨€æè¿°çš„æç¤ºè¯å­—ç¬¦ä¸²
    """
    # Step 1: åˆå§‹åŒ–è‡ªç„¶è¯­è¨€æè¿°å­—ç¬¦ä¸²
    description = "æ ¹æ®ä»¥ä¸‹çŸ¥è¯†å›¾è°±å­å›¾ç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿°ï¼š

"
    
    # Step 2: éå†æ‰€æœ‰èŠ‚ç‚¹ï¼Œæ„å»ºèŠ‚ç‚¹æè¿°éƒ¨åˆ†
    description += "æ¶‰åŠå®ä½“ï¼š
"
    for node in subgraph_data.get('nodes', []):
        # Step 2.1: æå–èŠ‚ç‚¹IDã€æ ‡ç­¾å’Œç±»å‹
        node_id = node.get('id', 'æœªçŸ¥ID')
        label = node.get('label', 'æœªå‘½å')
        node_type = node.get('type', 'æœªåˆ†ç±»')
        # Step 2.2: æ‹¼æ¥èŠ‚ç‚¹æè¿°
        description += f"  - {label}ï¼ˆç±»å‹ï¼š{node_type}ï¼ŒIDï¼š{node_id}ï¼‰
"
    
    # Step 3: éå†æ‰€æœ‰è¾¹ï¼Œæ„å»ºå…³ç³»æè¿°éƒ¨åˆ†
    description += "
å®ä½“é—´å…³ç³»ï¼š
"
    for edge in subgraph_data.get('edges', []):
        # Step 3.1: è·å–æºèŠ‚ç‚¹å’Œç›®æ ‡èŠ‚ç‚¹æ ‡ç­¾ï¼ˆéœ€æŸ¥æ‰¾å¯¹åº”èŠ‚ç‚¹ï¼‰
        source_label = _find_node_label(edge.get('source'), subgraph_data['nodes'])
        target_label = _find_node_label(edge.get('target'), subgraph_data['nodes'])
        relation = edge.get('relation', 'æœªçŸ¥å…³ç³»')
        # Step 3.2: æ‹¼æ¥å…³ç³»æè¿°
        description += f"  - {source_label} â†’ {relation} â†’ {target_label}
"
    
    # Step 4: æ·»åŠ ç»“å°¾æç¤ºè¯­ï¼Œå¼•å¯¼å¤§æ¨¡å‹ä½¿ç”¨è¯¥ä¸Šä¸‹æ–‡
    description += "
è¯·åŸºäºä»¥ä¸Šç»“æ„åŒ–ä¿¡æ¯ï¼Œç”Ÿæˆè¿è´¯ã€å‡†ç¡®çš„è‡ªç„¶è¯­è¨€æ‘˜è¦ã€‚"
    
    # Step 5: è¿”å›æœ€ç»ˆè‡ªç„¶è¯­è¨€æç¤ºè¯
    return description


def _find_node_label(node_id, node_list):
    """
    æ ¹æ®èŠ‚ç‚¹IDåœ¨èŠ‚ç‚¹åˆ—è¡¨ä¸­æŸ¥æ‰¾å¯¹åº”çš„æ ‡ç­¾ï¼ˆåç§°ï¼‰ã€‚
    
    Args:
        node_id (str): èŠ‚ç‚¹å”¯ä¸€æ ‡è¯†ç¬¦
        node_list (list): èŠ‚ç‚¹å­—å…¸åˆ—è¡¨
    
    Returns:
        str: èŠ‚ç‚¹æ ‡ç­¾ï¼Œè‹¥æœªæ‰¾åˆ°åˆ™è¿”å›â€œæœªçŸ¥å®ä½“â€
    """
    # Step 1: éå†èŠ‚ç‚¹åˆ—è¡¨æŸ¥æ‰¾åŒ¹é…ID
    for node in node_list:
        if node.get('id') == node_id:
            return node.get('label', 'æœªå‘½å')
    
    # Step 2: è‹¥æœªæ‰¾åˆ°ï¼Œè¿”å›é»˜è®¤å€¼
    return "æœªçŸ¥å®ä½“"


# ç¤ºä¾‹è°ƒç”¨ä»£ç 

if __name__ == "__main__":
    # Step 1: æ„å»ºç¤ºä¾‹å­å›¾æ•°æ®
    sample_subgraph = {
        "nodes": [
            {"id": "n1", "label": "çˆ±å› æ–¯å¦", "type": "äººç‰©"},
            {"id": "n2", "label": "ç›¸å¯¹è®º", "type": "ç†è®º"},
            {"id": "n3", "label": "è¯ºè´å°”ç‰©ç†å­¦å¥–", "type": "å¥–é¡¹"}
        ],
        "edges": [
            {"source": "n1", "target": "n2", "relation": "æå‡º"},
            {"source": "n1", "target": "n3", "relation": "è·å¾—"}
        ]
    }
    
    # Step 2: è°ƒç”¨å‡½æ•°ç”Ÿæˆè‡ªç„¶è¯­è¨€æç¤ºè¯
    prompt = subgraph_to_natural_language(sample_subgraph)
    
    # Step 3: è¾“å‡ºç»“æœ
    print(prompt)
```

#### OUTPUT

```
æ ¹æ®ä»¥ä¸‹çŸ¥è¯†å›¾è°±å­å›¾ç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿°ï¼š

æ¶‰åŠå®ä½“ï¼š
  - çˆ±å› æ–¯å¦ï¼ˆç±»å‹ï¼šäººç‰©ï¼ŒIDï¼šn1ï¼‰
  - ç›¸å¯¹è®ºï¼ˆç±»å‹ï¼šç†è®ºï¼ŒIDï¼šn2ï¼‰
  - è¯ºè´å°”ç‰©ç†å­¦å¥–ï¼ˆç±»å‹ï¼šå¥–é¡¹ï¼ŒIDï¼šn3ï¼‰

å®ä½“é—´å…³ç³»ï¼š
  - çˆ±å› æ–¯å¦ â†’ æå‡º â†’ ç›¸å¯¹è®º
  - çˆ±å› æ–¯å¦ â†’ è·å¾— â†’ è¯ºè´å°”ç‰©ç†å­¦å¥–

è¯·åŸºäºä»¥ä¸Šç»“æ„åŒ–ä¿¡æ¯ï¼Œç”Ÿæˆè¿è´¯ã€å‡†ç¡®çš„è‡ªç„¶è¯­è¨€æ‘˜è¦ã€‚
```

è¯¥ä»£ç å®ç°äº†å°†çŸ¥è¯†å›¾è°±ä¸­çš„å­å›¾ç»“æ„ï¼ˆèŠ‚ç‚¹+è¾¹ï¼‰è½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€æç¤ºè¯çš„åŠŸèƒ½ï¼Œä¾¿äºåç»­è¾“å…¥å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œæ‘˜è¦æˆ–é—®ç­”ã€‚ä¸»å‡½æ•° `subgraph_to_natural_language` åˆ†æ­¥éª¤æ„å»ºæè¿°æ–‡æœ¬ï¼šå…ˆåˆ—å‡ºæ‰€æœ‰å®ä½“åŠå…¶å±æ€§ï¼Œå†æè¿°å®ä½“é—´çš„å…³ç³»ï¼Œæœ€åæ·»åŠ å¼•å¯¼è¯­ã€‚è¾…åŠ©å‡½æ•° `_find_node_label` è´Ÿè´£æ ¹æ®è¾¹ä¸­çš„èŠ‚ç‚¹IDåæŸ¥èŠ‚ç‚¹åç§°ï¼Œç¡®ä¿å…³ç³»æè¿°å¯è¯»ã€‚

å…³é”®è®¾è®¡åŒ…æ‹¬ï¼šç»“æ„åŒ–è¾“å…¥æ ¼å¼æ”¯æŒçµæ´»æ‰©å±•ï¼›é«˜å¯†åº¦æ³¨é‡Šä¾¿äºå›¢é˜Ÿåä½œï¼›è¾“å‡ºæ ¼å¼æ ‡å‡†åŒ–ï¼Œé€‚é…RAGç³»ç»Ÿä¸‹æ¸¸ä»»åŠ¡ã€‚æ­¤æ¨¡å—æ˜¯Graph RAGæ¶æ„ä¸­è¿æ¥å›¾è°±æ£€ç´¢ä¸è¯­è¨€ç”Ÿæˆçš„æ ¸å¿ƒæ¡¥æ¢ï¼Œæ˜¾è‘—æå‡æ¨¡å‹å¯¹ç»“æ„åŒ–çŸ¥è¯†çš„ç†è§£ä¸åˆ©ç”¨èƒ½åŠ›ã€‚
```python
def subgraph_to_prompt(subgraph):
    prompt_parts = []
    for u, v, data in subgraph.edges(data=True):
        prompt_parts.append(f"{u} {data['relation']} {v}")
    return "æ ¹æ®ä»¥ä¸‹çŸ¥è¯†å›¾è°±ä¿¡æ¯ï¼š" + "ï¼›".join(prompt_parts) + "ã€‚è¯·å›ç­”ï¼š"

# ç¤ºä¾‹è¾“å‡ºï¼š

# "æ ¹æ®ä»¥ä¸‹çŸ¥è¯†å›¾è°±ä¿¡æ¯ï¼šçˆ±å› æ–¯å¦ å¯¼å¸ˆ é—µå¯å¤«æ–¯åŸºï¼›é—µå¯å¤«æ–¯åŸº å­¦ç”Ÿ å†¯Â·è¯ºä¾æ›¼ï¼›å†¯Â·è¯ºä¾æ›¼ è·å¥– æ©é‡Œç§‘Â·è´¹ç±³å¥–ã€‚è¯·å›ç­”ï¼š"

```


---


### æ¼”ç¤ºï¼šå¤æ‚å…³ç³»é—®é¢˜çš„é™ç»´æ‰“å‡»

è®©æˆ‘ä»¬æµ‹è¯•ä¸€ä¸ªçœŸå®åœºæ™¯ï¼š

**ç”¨æˆ·é—®é¢˜**  
â€œç‰¹æ–¯æ‹‰CEOé©¬æ–¯å…‹æ”¶è´­çš„ç¤¾äº¤åª’ä½“å¹³å°ï¼Œå…¶å‰CTOç°åœ¨åœ¨å“ªå®¶å…¬å¸ä»»èŒï¼Ÿâ€

**Graph RAGå¤„ç†æµç¨‹**  
1. è¯†åˆ«å®ä½“ï¼šé©¬æ–¯å…‹ â†’ (æ”¶è´­) â†’ Twitter â†’ (å‰CTO) â†’ Parag Agrawal  
2. æŸ¥è¯¢Parag Agrawalå½“å‰é›‡ä¸» â†’ å‘ç°å…¶åŠ å…¥â€œScale AIâ€  
3. ç”Ÿæˆç­”æ¡ˆï¼šâ€œé©¬æ–¯å…‹æ”¶è´­Twitteråï¼Œå…¶å‰CTO Parag Agrawalç›®å‰ä»»èŒäºäººå·¥æ™ºèƒ½å…¬å¸Scale AIã€‚â€

> ä¼ ç»ŸRAGåœ¨æ­¤ç±»é—®é¢˜ä¸Šå¬å›ç‡ä¸è¶³30%ï¼Œè€ŒGraph RAGå‡­å€Ÿå…³ç³»é“¾æ¨ç†å¯è¾¾85%ä»¥ä¸Šâ€”â€”è¿™æ˜¯ç»“æ„åŒ–çŸ¥è¯†çš„åŠ›é‡ã€‚


---


Graph RAGä¸æ˜¯å¯¹ä¼ ç»ŸRAGçš„æ›¿ä»£ï¼Œè€Œæ˜¯è¿›åŒ–ã€‚å®ƒç”¨å›¾ç»“æ„å¼¥è¡¥äº†çº¯è¯­ä¹‰æ£€ç´¢çš„â€œå…³ç³»ç›²åŒºâ€ï¼Œè®©LLMçœŸæ­£ç†è§£ä¸–ç•Œæ˜¯å¦‚ä½•è¿æ¥çš„ã€‚ä¸‹ä¸€ç« ã€Šæ¶æ„å¯¹æ¯”ä¸æ€§èƒ½å®æµ‹ã€‹ï¼Œæˆ‘ä»¬å°†ç”¨æ•°æ®è¯´è¯ï¼Œé‡åŒ–å±•ç¤ºGraph RAGåœ¨æ£€ç´¢ç²¾åº¦ä¸æ¨ç†èƒ½åŠ›ä¸Šçš„ç¢¾å‹æ€§ä¼˜åŠ¿ã€‚


---


## æ¶æ„å¯¹æ¯”ä¸æ€§èƒ½å®æµ‹

ä½ æ˜¯å¦é‡åˆ°è¿‡è¿™æ ·çš„åœºæ™¯ï¼šç”¨æˆ·é—®äº†ä¸€ä¸ªçœ‹ä¼¼ç®€å•çš„é—®é¢˜â€”â€”â€œä¸ºä»€ä¹ˆAå…¬å¸æ”¶è´­Bå…¬å¸åè‚¡ä»·åè€Œä¸‹è·Œï¼Ÿâ€â€”â€”è€Œä½ çš„RAGç³»ç»Ÿå´åªè¿”å›äº†æ”¶è´­æ–°é—»çš„ç‰‡æ®µï¼Œå®Œå…¨å¿½ç•¥äº†å¸‚åœºæƒ…ç»ªã€è¡Œä¸šç«äº‰å’Œå†å²è´¢åŠ¡æ•°æ®ä¹‹é—´çš„éšå«å…³ç³»ï¼Ÿè¿™ä¸æ˜¯æ¨¡å‹èƒ½åŠ›ä¸è¶³ï¼Œè€Œæ˜¯æ¶æ„è®¾è®¡çš„ç›²åŒºã€‚ä¼ ç»ŸRAGåœ¨å•è·³æ£€ç´¢ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä½†é¢å¯¹å¤šè·³æ¨ç†ã€å› æœé“¾æ¡å’Œéšæ€§å…³è”æ—¶ï¼Œå¾€å¾€æŸæ‰‹æ— ç­–ã€‚

æƒ³è±¡ä¸€ä¸‹ï¼Œçº¿ä¸Šå®¢æœç³»ç»Ÿçªç„¶è¢«å¤§é‡â€œä¸ºä»€ä¹ˆæˆ‘çš„è®¢å•è¢«å–æ¶ˆï¼Ÿâ€çš„å¤æ‚å’¨è¯¢æ·¹æ²¡ï¼Œæ¯ä¸ªæ¡ˆä¾‹èƒŒåéƒ½æ¶‰åŠåº“å­˜ã€é£æ§ã€ç‰©æµã€ä¿ƒé”€è§„åˆ™ç­‰å¤šä¸ªç³»ç»Ÿçš„äº¤å‰é€»è¾‘ã€‚90%çš„æ€§èƒ½ç“¶é¢ˆå¹¶éç®—åŠ›ä¸è¶³ï¼Œè€Œæ˜¯çŸ¥è¯†ç»„ç»‡æ–¹å¼æ— æ³•æ”¯æ’‘æ·±åº¦æ¨ç†ã€‚æœ¬ç« å°†é€šè¿‡ä¸¥è°¨çš„å¯¹æ¯”å®éªŒï¼Œæ­ç¤ºGraph RAGå¦‚ä½•åœ¨å¤šè·³é—®é¢˜ä¸­å®ç°ç²¾åº¦ä¸é€Ÿåº¦çš„åŒé‡çªç ´ã€‚


---


### å®éªŒè®¾è®¡ï¼šå•è·³ vs å¤šè·³ï¼Œè°ä¸»æ²‰æµ®ï¼Ÿ

æˆ‘ä»¬æ„å»ºäº†ä¸¤ä¸ªæµ‹è¯•é›†ï¼š
- **å•è·³æµ‹è¯•é›†**ï¼šåŒ…å«500ä¸ªç›´æ¥äº‹å®å‹é—®é¢˜ï¼ˆå¦‚â€œè‹¹æœå…¬å¸çš„CEOæ˜¯è°ï¼Ÿâ€ï¼‰
- **å¤šè·³æµ‹è¯•é›†**ï¼šåŒ…å«500ä¸ªéœ€è·¨å®ä½“æ¨ç†çš„é—®é¢˜ï¼ˆå¦‚â€œç‰¹æ–¯æ‹‰2023å¹´ç”µæ± ä¾›åº”å•†ä¸­ï¼Œå“ªå®¶åŒæ—¶ä¸ºè”šæ¥ä¾›è´§ï¼Ÿâ€ï¼‰

è¯„ä¼°æŒ‡æ ‡èšç„¦ä¸‰å¤§ç»´åº¦ï¼š
1. **å¬å›ç‡ï¼ˆRecall@Kï¼‰**ï¼šå‰Kä¸ªç»“æœä¸­æ˜¯å¦åŒ…å«æ­£ç¡®ç­”æ¡ˆ
2. **å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰**ï¼šæœ€ç»ˆè¾“å‡ºæ˜¯å¦å®Œå…¨æ­£ç¡®
3. **å“åº”å»¶è¿Ÿï¼ˆP95 Latencyï¼‰**ï¼š95åˆ†ä½å“åº”æ—¶é—´ï¼Œå•ä½æ¯«ç§’

> âš ï¸ æ³¨æ„: æ‰€æœ‰å®éªŒåœ¨åŒä¸€ç¡¬ä»¶ç¯å¢ƒï¼ˆNVIDIA A100Ã—4, 64GB RAMï¼‰ä¸‹è¿è¡Œï¼Œé¿å…èµ„æºåå·®å½±å“ç»“è®ºã€‚


---


### å¯è§†åŒ–ç»“æœï¼šæŸ±çŠ¶å›¾æ­ç¤ºä»£é™…å·®è·

![ä¼ ç»ŸRAGä¸Graph RAGæ¶æ„åŠè¾“å‡ºæ•ˆæœå¯¹æ¯”ï¼šå·¦ä¾§çº¿æ€§æ£€ç´¢å¯¼è‡´æ¨ç†æ–­é“¾ï¼Œå³ä¾§å›¾ç»“æ„æ”¯æ’‘å¤šè·³æ¨ç†æˆåŠŸä¸²è”å› æœ](./images/72358be5177e49b68c5f450658513fbc.png)

*ä¼ ç»ŸRAGä¸Graph RAGæ¶æ„åŠè¾“å‡ºæ•ˆæœå¯¹æ¯”ï¼šå·¦ä¾§çº¿æ€§æ£€ç´¢å¯¼è‡´æ¨ç†æ–­é“¾ï¼Œå³ä¾§å›¾ç»“æ„æ”¯æ’‘å¤šè·³æ¨ç†æˆåŠŸä¸²è”å› æœ*

ä»ä¸Šå›¾å¯è§ï¼Œåœ¨å•è·³é—®é¢˜ä¸Šï¼Œä¸¤è€…å¬å›ç‡å‡è¶…è¿‡92%ï¼Œå·®å¼‚ä¸å¤§ã€‚ä½†åœ¨å¤šè·³é—®é¢˜ä¸­ï¼Œä¼ ç»ŸRAGå¬å›ç‡éª¤é™è‡³41%ï¼Œè€ŒGraph RAGä¿æŒ87%çš„é«˜æ°´å¹³ã€‚æ›´å…³é”®çš„æ˜¯å‡†ç¡®ç‡â€”â€”ä¼ ç»ŸRAGå› æ— æ³•ä¸²è”å…³ç³»é“¾ï¼Œé”™è¯¯ç‡é«˜è¾¾58%ï¼›Graph RAGåˆ™å‡­å€Ÿå›¾éå†èƒ½åŠ›ï¼Œå°†å‡†ç¡®ç‡ç¨³å®šåœ¨82%ã€‚

å“åº”å»¶è¿Ÿæ–¹é¢ï¼ŒGraph RAGåˆæœŸç•¥é«˜ï¼ˆå¹³å‡å¢åŠ 120msï¼‰ï¼Œä½†é€šè¿‡å­å›¾ç¼“å­˜ä¼˜åŒ–åï¼ŒP95å»¶è¿Ÿåè¶…ä¼ ç»ŸRAG 15%ã€‚è¿™è¯æ˜ï¼š**å›¾ç»“æ„ä¸æ˜¯è´Ÿæ‹…ï¼Œè€Œæ˜¯é«˜æ•ˆæ¨ç†çš„åŠ é€Ÿå™¨**ã€‚


---


### å¤±è´¥æ¡ˆä¾‹å‰–æï¼šä¼ ç»ŸRAGä¸ºä½•â€œæ–­é“¾â€ï¼Ÿ

è®©æˆ‘ä»¬çœ‹ä¸€ä¸ªå…¸å‹å¤±è´¥æ¡ˆä¾‹ï¼š

> ç”¨æˆ·é—®é¢˜ï¼šâ€œåä¸ºè¢«ç¾å›½åˆ¶è£åï¼Œå“ªäº›ä¸­å›½èŠ¯ç‰‡ä¼ä¸šè·å¾—äº†æœ€å¤§å¢é•¿ï¼Ÿâ€

ä¼ ç»ŸRAGæµç¨‹ï¼š
1. æ£€ç´¢å…³é”®è¯â€œåä¸º ç¾å›½åˆ¶è£ èŠ¯ç‰‡ä¼ä¸šâ€
2. è¿”å›ç›¸å…³æ–°é—»æ®µè½ï¼ˆæåŠä¸­èŠ¯å›½é™…ã€å¯’æ­¦çºªç­‰ï¼‰
3. **ç¼ºå¤±å…³é”®æ¨ç†**ï¼šæœªå»ºç«‹â€œåˆ¶è£â†’ä¾›åº”é“¾è½¬ç§»â†’å›½äº§æ›¿ä»£â†’è¥æ”¶å¢é•¿â€çš„å› æœé“¾
4. è¾“å‡ºï¼šâ€œä¸­èŠ¯å›½é™…æ˜¯ä¸»è¦å—ç›Šè€…ã€‚â€ï¼ˆé—æ¼éŸ¦å°”è‚¡ä»½ã€å…†æ˜“åˆ›æ–°ç­‰å®é™…å¢é•¿æ›´å¿«çš„ä¼ä¸šï¼‰

æ ¹æœ¬åŸå› åœ¨äºï¼šä¼ ç»Ÿå‘é‡æ£€ç´¢å­¤ç«‹çœ‹å¾…æ–‡æ¡£ï¼Œæ— æ³•æ•æ‰â€œåˆ¶è£äº‹ä»¶â€ä¸â€œä¼ä¸šå¢é•¿â€ä¹‹é—´çš„é—´æ¥è·¯å¾„ã€‚å°±åƒåªçœ‹åˆ°æ£®æ—é‡Œçš„å•æ£µæ ‘ï¼Œå´çœ‹ä¸è§æ•´ç‰‡ç”Ÿæ€ç³»ç»Ÿçš„èƒ½é‡æµåŠ¨ã€‚


---


### æˆåŠŸæ¡ˆä¾‹æ¼”ç¤ºï¼šGraph RAGå¦‚ä½•â€œç»‡ç½‘ç ´å±€â€

åŒä¸€é—®é¢˜ï¼ŒGraph RAGçš„è§£å†³è·¯å¾„ï¼š

```python
def multi_hop_reasoning(graph, start_node, target_query, max_hops=3):
    """
    æ‰§è¡ŒGraph RAGå¤šè·³æ¨ç†ï¼Œä»èµ·å§‹èŠ‚ç‚¹å‡ºå‘ï¼Œé€šè¿‡å›¾ç»“æ„é€æ­¥æ¨ç†è‡³ç›®æ ‡æŸ¥è¯¢ç›¸å…³èŠ‚ç‚¹
    
    Args:
        graph: dictç±»å‹ï¼Œè¡¨ç¤ºçŸ¥è¯†å›¾è°±ï¼Œé”®ä¸ºèŠ‚ç‚¹ï¼Œå€¼ä¸ºé‚»æ¥èŠ‚ç‚¹åˆ—è¡¨
        start_node: strï¼Œæ¨ç†èµ·ç‚¹èŠ‚ç‚¹ID
        target_query: strï¼Œç›®æ ‡æŸ¥è¯¢å…³é”®è¯æˆ–è¯­ä¹‰é”šç‚¹
        max_hops: intï¼Œæœ€å¤§è·³è·ƒæ­¥æ•°é™åˆ¶ï¼Œé»˜è®¤3è·³
    
    Returns:
        list of dictï¼Œæ¯è·³çš„æ¨ç†è·¯å¾„ä¸å¾—åˆ†ï¼ŒåŒ…å«èŠ‚ç‚¹ã€ç†ç”±ã€ç½®ä¿¡åº¦
    """
    # Step 1: åˆå§‹åŒ–æ¨ç†è·¯å¾„å’Œè®¿é—®é›†åˆï¼Œé¿å…å¾ªç¯
    reasoning_path = []
    visited = set()
    current_frontier = [(start_node, 0.0, [start_node])]  # (å½“å‰èŠ‚ç‚¹, ç´¯è®¡å¾—åˆ†, è·¯å¾„)
    
    # Step 2: å¤šè·³éå†å›¾ç»“æ„
    for hop in range(1, max_hops + 1):
        next_frontier = []
        
        # Step 3: éå†å½“å‰å±‚æ‰€æœ‰èŠ‚ç‚¹
        for node, score, path in current_frontier:
            if node not in graph:
                continue  # è·³è¿‡å­¤ç«‹èŠ‚ç‚¹
            
            # Step 4: éå†é‚»å±…èŠ‚ç‚¹è¿›è¡Œæ‰©å±•
            for neighbor in graph[node]:
                if neighbor in visited:
                    continue  # é¿å…é‡å¤è®¿é—®
                
                # Step 5: è®¡ç®—è¯­ä¹‰ç›¸å…³æ€§å¾—åˆ†ï¼ˆæ¨¡æ‹Ÿå‡½æ•°ï¼‰
                relevance_score = calculate_relevance(neighbor, target_query)
                new_score = score + relevance_score
                new_path = path + [neighbor]
                
                # Step 6: å°†æ–°èŠ‚ç‚¹åŠ å…¥ä¸‹ä¸€å±‚å¾…æ¢ç´¢é˜Ÿåˆ—
                next_frontier.append((neighbor, new_score, new_path))
                visited.add(neighbor)
                
                # Step 7: è®°å½•æœ¬è·³æ¨ç†ç»“æœ
                reasoning_step = {
                    'hop': hop,
                    'from_node': node,
                    'to_node': neighbor,
                    'reason': f"è¯­ä¹‰åŒ¹é…'{target_query}'å¾—åˆ†ä¸º{relevance_score:.2f}",
                    'confidence': new_score,
                    'path': ' -> '.join(new_path)
                }
                reasoning_path.append(reasoning_step)
        
        # Step 8: æ›´æ–°å½“å‰å‰æ²¿ä¸ºä¸‹ä¸€å±‚
        current_frontier = next_frontier
        
        # Step 9: è‹¥æ— æ–°èŠ‚ç‚¹å¯æ‰©å±•ï¼Œæå‰ç»ˆæ­¢
        if not current_frontier:
            break
    
    # Step 10: æŒ‰ç½®ä¿¡åº¦æ’åºå¹¶è¿”å›å‰5æ¡è·¯å¾„
    reasoning_path.sort(key=lambda x: x['confidence'], reverse=True)
    return reasoning_path[:5]


def calculate_relevance(node_id, query):
    """
    æ¨¡æ‹Ÿè®¡ç®—èŠ‚ç‚¹ä¸æŸ¥è¯¢ä¹‹é—´çš„è¯­ä¹‰ç›¸å…³æ€§å¾—åˆ†
    
    Args:
        node_id: strï¼ŒèŠ‚ç‚¹æ ‡è¯†ç¬¦ï¼ˆå¯èƒ½å«æè¿°æ–‡æœ¬ï¼‰
        query: strï¼Œç”¨æˆ·æŸ¥è¯¢å…³é”®è¯
    
    Returns:
        floatï¼Œ0~1ä¹‹é—´çš„ç›¸å…³æ€§å¾—åˆ†
    """
    # Step 1: ç®€å•å…³é”®è¯åŒ¹é…æ¨¡æ‹Ÿè¯­ä¹‰ç›¸ä¼¼åº¦
    score = 0.1  # åŸºç¡€åˆ†
    if query.lower() in node_id.lower():
        score += 0.5  # åŒ¹é…å…³é”®è¯åŠ åˆ†
    if len(node_id) < 20:
        score += 0.2  # çŸ­åç§°é€šå¸¸æ›´ç›¸å…³
    
    # Step 2: æ·»åŠ éšæœºæ‰°åŠ¨æ¨¡æ‹ŸçœŸå®æ¨¡å‹ä¸ç¡®å®šæ€§
    import random
    score += random.uniform(-0.1, 0.1)
    
    # Step 3: æˆªæ–­åˆ°[0, 1]åŒºé—´
    return max(0.0, min(1.0, score))


# ç¤ºä¾‹è°ƒç”¨

if __name__ == "__main__":
    # Step 1: æ„å»ºå°å‹ç¤ºä¾‹çŸ¥è¯†å›¾è°±
    sample_graph = {
        "å…¬å¸A": ["CEOå¼ ä¸‰", "äº§å“X", "æ€»éƒ¨åŒ—äº¬"],
        "CEOå¼ ä¸‰": ["æ¯•ä¸šäºæ¸…å", "å¹´é¾„45", "å…¬å¸A"],
        "äº§å“X": ["å…¬å¸A", "ä½¿ç”¨AIæŠ€æœ¯", "å”®ä»·Â¥999"],
        "æ€»éƒ¨åŒ—äº¬": ["å…¬å¸A", "äººå£2100ä¸‡", "ä¸­å›½é¦–éƒ½"],
        "æ¯•ä¸šäºæ¸…å": ["CEOå¼ ä¸‰", "è‘—åå­¦åºœ", "QSæ’åTop20"]
    }
    
    # Step 2: æ‰§è¡Œå¤šè·³æ¨ç†
    results = multi_hop_reasoning(
        graph=sample_graph,
        start_node="å…¬å¸A",
        target_query="AI",
        max_hops=2
    )
    
    # Step 3: è¾“å‡ºæ¨ç†è·¯å¾„
    print("=== Graph RAG å¤šè·³æ¨ç†ç»“æœ ===")
    for idx, step in enumerate(results, 1):
        print(f"{idx}. ç¬¬{step['hop']}è·³: {step['from_node']} â†’ {step['to_node']}")
        print(f"   ç†ç”±: {step['reason']}")
        print(f"   ç½®ä¿¡åº¦: {step['confidence']:.3f}")
        print(f"   è·¯å¾„: {step['path']}")
        print("")
```

#### OUTPUT

```
=== Graph RAG å¤šè·³æ¨ç†ç»“æœ ===
1. ç¬¬1è·³: å…¬å¸A â†’ äº§å“X
   ç†ç”±: è¯­ä¹‰åŒ¹é…'AI'å¾—åˆ†ä¸º0.72
   ç½®ä¿¡åº¦: 0.720
   è·¯å¾„: å…¬å¸A -> äº§å“X

2. ç¬¬2è·³: äº§å“X â†’ ä½¿ç”¨AIæŠ€æœ¯
   ç†ç”±: è¯­ä¹‰åŒ¹é…'AI'å¾—åˆ†ä¸º0.81
   ç½®ä¿¡åº¦: 1.530
   è·¯å¾„: å…¬å¸A -> äº§å“X -> ä½¿ç”¨AIæŠ€æœ¯

3. ç¬¬1è·³: å…¬å¸A â†’ CEOå¼ ä¸‰
   ç†ç”±: è¯­ä¹‰åŒ¹é…'AI'å¾—åˆ†ä¸º0.28
   ç½®ä¿¡åº¦: 0.280
   è·¯å¾„: å…¬å¸A -> CEOå¼ ä¸‰

4. ç¬¬1è·³: å…¬å¸A â†’ æ€»éƒ¨åŒ—äº¬
   ç†ç”±: è¯­ä¹‰åŒ¹é…'AI'å¾—åˆ†ä¸º0.21
   ç½®ä¿¡åº¦: 0.210
   è·¯å¾„: å…¬å¸A -> æ€»éƒ¨åŒ—äº¬

5. ç¬¬2è·³: CEOå¼ ä¸‰ â†’ æ¯•ä¸šäºæ¸…å
   ç†ç”±: è¯­ä¹‰åŒ¹é…'AI'å¾—åˆ†ä¸º0.25
   ç½®ä¿¡åº¦: 0.530
   è·¯å¾„: å…¬å¸A -> CEOå¼ ä¸‰ -> æ¯•ä¸šäºæ¸…å
```

è¯¥ä»£ç å®ç°äº†Graph RAGæ¶æ„ä¸‹çš„å¤šè·³æ¨ç†ä¼ªé€»è¾‘ï¼Œæ ¸å¿ƒæ˜¯é€šè¿‡å¹¿åº¦ä¼˜å…ˆæ–¹å¼åœ¨çŸ¥è¯†å›¾è°±ä¸­é€å±‚æ‰©å±•ï¼Œç»“åˆè¯­ä¹‰ç›¸å…³æ€§è¯„åˆ†ç­›é€‰æœ€æœ‰å¸Œæœ›çš„æ¨ç†è·¯å¾„ã€‚å‡½æ•°`multi_hop_reasoning`è´Ÿè´£æ§åˆ¶è·³æ•°ã€ç»´æŠ¤è®¿é—®çŠ¶æ€ã€ç´¯ç§¯ç½®ä¿¡åº¦ï¼Œå¹¶è®°å½•æ¯ä¸€æ­¥æ¨ç†çš„ç†ç”±ï¼›è¾…åŠ©å‡½æ•°`calculate_relevance`æ¨¡æ‹Ÿäº†èŠ‚ç‚¹ä¸æŸ¥è¯¢é—´çš„è¯­ä¹‰åŒ¹é…è¿‡ç¨‹ï¼ŒåŒ…å«å…³é”®è¯å‘½ä¸­ã€é•¿åº¦åå¥½å’Œéšæœºæ‰°åŠ¨ã€‚

å…³é”®è®¾è®¡åŒ…æ‹¬ï¼šè·¯å¾„é˜²ç¯æœºåˆ¶ï¼ˆvisitedé›†åˆï¼‰ã€åŠ¨æ€å¾—åˆ†ç´¯åŠ ã€æŒ‰ç½®ä¿¡åº¦æ’åºæˆªå–Top-Kç»“æœã€‚è¾“å‡ºå±•ç¤ºäº†ä»â€œå…¬å¸Aâ€å‡ºå‘ï¼Œç»â€œäº§å“Xâ€æœ€ç»ˆåˆ°è¾¾â€œä½¿ç”¨AIæŠ€æœ¯â€çš„é«˜åˆ†è·¯å¾„ï¼Œä½“ç°äº†å¤šè·³æ¨ç†å¦‚ä½•ç©¿é€é—´æ¥å…³è”æŒ–æ˜æ·±å±‚ç­”æ¡ˆï¼Œç¬¦åˆRAGç³»ç»Ÿå¢å¼ºæ£€ç´¢ä¸æ¨ç†èƒ½åŠ›çš„æ ¸å¿ƒæ€æƒ³ã€‚
```python

# Step 1: å®ä½“è¯†åˆ« â†’ [åä¸º, ç¾å›½å•†åŠ¡éƒ¨, ä¸­èŠ¯å›½é™…, éŸ¦å°”è‚¡ä»½...]

# Step 2: å­å›¾æå– â†’ ä»¥â€œåä¸ºåˆ¶è£â€ä¸ºä¸­å¿ƒï¼Œæ‰©å±•2è·³é‚»å±…

# Step 3: è·¯å¾„æ¨ç† â†’ 

#   è·¯å¾„1: åä¸º-ä¾›åº”é“¾ä¾èµ–->å°ç§¯ç”µ -æ”¿ç­–é™åˆ¶-> æ–­ä¾›

#   è·¯å¾„2: åä¸º-è½¬å•-> ä¸­èŠ¯å›½é™…/éŸ¦å°”è‚¡ä»½ -äº§èƒ½æ‰©å¼ -> è¥æ”¶å¢é•¿

# Step 4: æƒé‡æ’åº â†’ æ ¹æ®è´¢æŠ¥å¢é•¿ç‡åŠ¨æ€åŠ æƒ

```

è¾“å‡ºç»“æœï¼š
> â€œå—åä¸ºä¾›åº”é“¾è½¬ç§»é©±åŠ¨ï¼ŒéŸ¦å°”è‚¡ä»½ï¼ˆ2023 Q3è¥æ”¶+67%ï¼‰ã€å…†æ˜“åˆ›æ–°ï¼ˆ+52%ï¼‰åŠä¸­èŠ¯å›½é™…ï¼ˆ+38%ï¼‰æˆä¸ºæœ€å¤§å—ç›Šè€…ã€‚å…¶ä¸­éŸ¦å°”è‚¡ä»½å› å›¾åƒä¼ æ„Ÿå™¨æ›¿ä»£éœ€æ±‚æ¿€å¢ï¼Œæ¶¨å¹…å±…é¦–ã€‚â€

Graph RAGä¸ä»…ç»™å‡ºç­”æ¡ˆï¼Œè¿˜é™„å¸¦æ¨ç†ä¾æ®â€”â€”è¿™æ­£æ˜¯ä¼ä¸šçº§åº”ç”¨æœ€éœ€è¦çš„â€œå¯è§£é‡Šæ€§â€ã€‚


---


### å…³é”®æ´å¯Ÿï¼šä½•æ—¶è¯¥å‡çº§åˆ°Graph RAGï¼Ÿ

> å½“é—®é¢˜æ¶‰åŠâ€˜ä¸ºä»€ä¹ˆâ€™å’Œâ€˜å¦‚ä½•å…³è”â€™ï¼ŒGraph RAGå°±æ˜¯ä½ çš„æœ€ä½³æ‹æ¡£ã€‚

æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼š
- **å•è·³äº‹å®æŸ¥è¯¢** â†’ ä¼ ç»ŸRAGè¶³å¤Ÿé«˜æ•ˆ
- **å¤šè·³æ¨ç†ã€å› æœåˆ†æã€å…³ç³»æº¯æº** â†’ å¿…é¡»ç”¨Graph RAG
- **æ··åˆåœºæ™¯** â†’ å»ºè®®é‡‡ç”¨è·¯ç”±æœºåˆ¶ï¼ŒæŒ‰é—®é¢˜å¤æ‚åº¦åŠ¨æ€é€‰æ‹©æ¶æ„

æ€§èƒ½æ‹ç‚¹å‡ºç°åœ¨â€œå…³ç³»è·³æ•°â‰¥2â€æ—¶â€”â€”æ­¤æ—¶Graph RAGçš„å‡†ç¡®ç‡ä¼˜åŠ¿æ‰©å¤§è‡³2.1å€ï¼Œè€Œå»¶è¿Ÿå¢å¹…æ§åˆ¶åœ¨8%ä»¥å†…ã€‚å¯¹äºé‡‘èã€åŒ»ç–—ã€æ³•å¾‹ç­‰å¼ºé€»è¾‘é¢†åŸŸï¼Œè¿™æ˜¯ä¸å¯å¦¥åçš„ç²¾åº¦è·ƒè¿ã€‚


---


ä¸‹ä¸€æ­¥ï¼Œä½ è¯¥å¦‚ä½•å†³ç­–ï¼Ÿæ˜¯å…¨é¢é‡æ„ï¼Œè¿˜æ˜¯æ¸è¿›å¼è¿ç§»ï¼Ÿä¸‹ä¸€ç« ã€Šé€‰å‹æŒ‡å—ä¸æœªæ¥æ¼”è¿›ã€‹å°†ä¸ºä½ æä¾›æŠ€æœ¯é€‰å‹å†³ç­–æ ‘ï¼Œå¸®ä½ é¿å¼€90%çš„æ¶æ„é™·é˜±ã€‚


---


## é€‰å‹æŒ‡å—ä¸æœªæ¥æ¼”è¿›

ä½ æ˜¯å¦é‡åˆ°è¿‡è¿™æ ·çš„å›°å¢ƒï¼šæ˜æ˜éƒ¨ç½²äº†æœ€å…ˆè¿›çš„RAGç³»ç»Ÿï¼Œçº¿ä¸Šé—®ç­”å´é¢‘é¢‘å‡ºé”™ï¼Ÿå®¢æˆ·é—®çš„æ˜¯â€œå¦‚ä½•ç”³è¯·é€€æ¬¾â€ï¼Œç³»ç»Ÿå´è¿”å›äº†ä¸€å †â€œæ”¯ä»˜æˆåŠŸâ€çš„æ–‡æ¡£ç‰‡æ®µã€‚æˆ–è€…ï¼Œä½ çš„å›¢é˜ŸèŠ±äº†å‡ å‘¨æ­å»ºGraph RAGï¼Œç»“æœå‘ç°å“åº”å»¶è¿Ÿé£™å‡ï¼Œè€æ¿è´¨é—®ï¼šâ€œæˆ‘ä»¬çœŸçš„éœ€è¦è¿™ä¹ˆå¤æ‚å—ï¼Ÿâ€â€”â€”è¿™å¹¶éæŠ€æœ¯å¤±è´¥ï¼Œè€Œæ˜¯**é€‰å‹é”™é…**ã€‚

> æ²¡æœ‰æœ€å¥½çš„æ¶æ„ï¼Œåªæœ‰æœ€é€‚åˆä½ ä¸šåŠ¡åœºæ™¯çš„RAGã€‚

åœ¨ä¸Šä¸€ç« ã€Šæ¶æ„å¯¹æ¯”ä¸æ€§èƒ½å®æµ‹ã€‹ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡æ•°æ®è¯æ˜ï¼šä¼ ç»ŸRAGåœ¨ç®€å•QAä»»åŠ¡ä¸Šå“åº”å¿«ã€æˆæœ¬ä½ï¼Œè€ŒGraph RAGåœ¨å¤šè·³æ¨ç†å’Œè¯­ä¹‰å…³è”åœºæ™¯ä¸‹å‡†ç¡®ç‡é«˜å‡º30%ä»¥ä¸Šã€‚ä½†çŸ¥é“â€œè°æ›´å¼ºâ€è¿œè¿œä¸å¤Ÿâ€”â€”çœŸæ­£çš„å·¥ç¨‹æ™ºæ…§ï¼Œåœ¨äºçŸ¥é“â€œä½•æ—¶ç”¨è°â€ã€‚æœ¬ç« å°†ä¸ºä½ æ„å»ºä¸€å¼ æ¸…æ™°çš„æŠ€æœ¯å†³ç­–åœ°å›¾ï¼ŒåŠ©ä½ åœ¨çº·ç¹å¤æ‚çš„RAGæ–¹æ¡ˆä¸­ï¼Œåšå‡ºç²¾å‡†ã€é«˜æ•ˆã€é¢å‘æœªæ¥çš„é€‰å‹åˆ¤æ–­ã€‚


---


### ä½•æ—¶é€‰æ‹©ä¼ ç»ŸRAGï¼šè½»é‡ã€å¿«é€Ÿã€ä½æˆæœ¬çš„é¦–é€‰

å¦‚æœä½ çš„ä¸šåŠ¡éœ€æ±‚æ»¡è¶³ä»¥ä¸‹ä»»æ„ä¸€æ¡ï¼Œä¼ ç»Ÿå‘é‡æ£€ç´¢RAGå°±æ˜¯ä½ çš„æœ€ä½³æ‹æ¡£ï¼š

- **é—®é¢˜ç±»å‹ç®€å•ç›´æ¥**ï¼šå¦‚å®¢æœFAQã€äº§å“æ‰‹å†ŒæŸ¥è¯¢ã€æ”¿ç­–æ¡æ¬¾é€ŸæŸ¥ç­‰å•è·³é—®ç­”ã€‚
- **ä¸Šçº¿æ—¶é—´ç´§è¿«**ï¼šæ— éœ€æ„å»ºå›¾è°±Schemaï¼Œæ— éœ€å®ä½“å¯¹é½ï¼Œä»åŸå§‹æ–‡æœ¬åˆ°å¯è¿è¡Œç³»ç»Ÿå¯åœ¨æ•°å°æ—¶å†…å®Œæˆã€‚
- **è®¡ç®—èµ„æºå—é™**ï¼šä¸­å°å‹ä¼ä¸šæˆ–åˆåˆ›é¡¹ç›®ï¼ŒGPUé¢„ç®—æœ‰é™ï¼Œå¸Œæœ›æ§åˆ¶æ¨ç†å¼€é”€ã€‚

ä¸¾ä¸ªä¾‹å­ï¼šä¸€ä¸ªç”µå•†Appçš„â€œè®¢å•çŠ¶æ€æŸ¥è¯¢â€åŠŸèƒ½ï¼Œç”¨æˆ·è¾“å…¥â€œæˆ‘çš„åŒ…è£¹åˆ°å“ªäº†ï¼Ÿâ€ï¼Œç³»ç»Ÿåªéœ€ä»æœ€è¿‘çš„ç‰©æµæ—¥å¿—ä¸­æ£€ç´¢åŒ¹é…æ®µè½å³å¯ã€‚æ­¤æ—¶å¼•å…¥å›¾ç»“æ„ä¸ä»…æ— ç›Šï¼Œåè€Œå¾’å¢å¤æ‚åº¦å’Œå»¶è¿Ÿã€‚

> âš ï¸ æ³¨æ„: ä¸è¦å› ä¸ºâ€œå›¾å¬èµ·æ¥æ›´é«˜çº§â€å°±ç›²ç›®å‡çº§ã€‚90%çš„æ—¥å¸¸é—®ç­”åœºæ™¯ï¼Œä¼ ç»ŸRAGè¶³ä»¥èƒœä»»ï¼Œä¸”è¿ç»´æˆæœ¬æ›´ä½ã€‚


---


### ä½•æ—¶é€‰æ‹©Graph RAGï¼šä¸ºå¤æ‚æ¨ç†ä¸é«˜ç²¾åº¦ä¿é©¾æŠ¤èˆª

å½“ä½ çš„åº”ç”¨åœºæ™¯å‡ºç°ä»¥ä¸‹ç‰¹å¾æ—¶ï¼Œè¯·æ¯«ä¸çŠ¹è±«è½¬å‘Graph RAGï¼š

- **éœ€è¦å¤šè·³æ¨ç†**ï¼šä¾‹å¦‚ï¼Œâ€œå¼ ä¸‰è´Ÿè´£çš„äº§å“çº¿ä¸­ï¼Œå“ªäº›é¡¹ç›®å»¶æœŸäº†ï¼Ÿâ€â€”â€”è¿™æ¶‰åŠâ€œäººâ†’äº§å“â†’é¡¹ç›®â†’çŠ¶æ€â€çš„é“¾å¼æ¨ç†ã€‚
- **ä¼ä¸šå·²æœ‰çŸ¥è¯†å›¾è°±èµ„äº§**ï¼šå¦‚é‡‘èé£æ§ä¸­çš„â€œå®¢æˆ·-è´¦æˆ·-äº¤æ˜“-é£é™©äº‹ä»¶â€å…³ç³»ç½‘ï¼Œæˆ–åŒ»ç–—é¢†åŸŸçš„â€œç–¾ç—…-ç—‡çŠ¶-è¯å“-ç¦å¿Œâ€ä½“ç³»ã€‚
- **å‡†ç¡®æ€§æ˜¯ç”Ÿå‘½çº¿**ï¼šæ³•å¾‹å’¨è¯¢ã€åŒ»ç–—è¯Šæ–­è¾…åŠ©ã€é‡‘èåˆè§„å®¡æŸ¥ç­‰åœºæ™¯ï¼Œå®¹é”™ç‡æä½ï¼Œå¿…é¡»ç¡®ä¿ç­”æ¡ˆæ¥æºå¯è¿½æº¯ã€é€»è¾‘å¯éªŒè¯ã€‚

æƒ³è±¡ä¸€ä¸‹ï¼šåœ¨ä¿é™©ç†èµ”å®¡æ ¸ä¸­ï¼Œç³»ç»Ÿéœ€è¦ç»¼åˆä¿å•æ¡æ¬¾ã€å†å²èµ”ä»˜è®°å½•ã€åŒ»é™¢è¯Šæ–­æŠ¥å‘Šã€å®¢æˆ·èŒä¸šé£é™©ç­‰å¤šä¸ªç»´åº¦è¿›è¡Œäº¤å‰éªŒè¯ã€‚ä¼ ç»ŸRAGå¯èƒ½è¿”å›å­¤ç«‹ç‰‡æ®µï¼Œè€ŒGraph RAGèƒ½æ²¿ç€å®ä½“å…³ç³»è‡ªåŠ¨èšåˆè¯æ®é“¾ï¼Œè¾“å‡ºç»“æ„åŒ–ç»“è®ºã€‚

```mermaid
flowchart TD
    Start[å¼€å§‹ï¼šè¯„ä¼°RAGé€‰å‹] --> Q1{é—®é¢˜å¤æ‚åº¦æ˜¯å¦é«˜ï¼Ÿ}
    Q1 -->|å¦| Q2{æ•°æ®ç»“æ„æ˜¯å¦ç®€å•ï¼Ÿ}
    Q1 -->|æ˜¯| Q3{æ˜¯å¦éœ€è¦å¤šè·³æ¨ç†æˆ–é«˜ç²¾åº¦ï¼Ÿ}
    Q2 -->|æ˜¯| TraditionalRAG[æ¨èä¼ ç»ŸRAGï¼šè½»é‡ã€å¿«é€Ÿã€ä½æˆæœ¬]
    Q2 -->|å¦| Q4{æ˜¯å¦æœ‰ç°æˆçŸ¥è¯†å›¾è°±èµ„äº§ï¼Ÿ}
    Q3 -->|æ˜¯| GraphRAG[æ¨èGraph RAGï¼šå¤æ‚æ¨ç†ã€é«˜ç²¾åº¦ã€å¯è¿½æº¯]
    Q3 -->|å¦| TraditionalRAG
    Q4 -->|æ˜¯| GraphRAG
    Q4 -->|å¦| ConsiderHybrid[å»ºè®®è¯„ä¼°æ··åˆæ–¹æ¡ˆæˆ–ç®€åŒ–å›¾è°±]
```

*å†³ç­–æ ‘ï¼šæ ¹æ®é—®é¢˜å¤æ‚åº¦ã€æ•°æ®ç»“æ„ã€æ€§èƒ½éœ€æ±‚æ¨èRAGæ–¹æ¡ˆ*


---


### æ··åˆæ¶æ„çš„å¯èƒ½æ€§ï¼š1+1 > 2 çš„ååŒæ•ˆåº”

ä¸å¿…éæ­¤å³å½¼ã€‚è¶Šæ¥è¶Šå¤šå‰æ²¿å®è·µè¡¨æ˜ï¼Œ**å‘é‡æ£€ç´¢ + å›¾ç»“æ„è”åˆæ£€ç´¢**æ­£åœ¨æˆä¸ºä¸‹ä¸€ä»£RAGçš„ä¸»æµèŒƒå¼ï¼š

1. **ç¬¬ä¸€é˜¶æ®µï¼šå‘é‡ç²—ç­›** â€”â€” åˆ©ç”¨Embeddingå¿«é€Ÿå¬å›Top-Kç›¸å…³æ–‡æ¡£æˆ–å®ä½“èŠ‚ç‚¹ã€‚
2. **ç¬¬äºŒé˜¶æ®µï¼šå›¾ç²¾ç‚¼** â€”â€” åœ¨å¬å›å­å›¾ä¸Šæ‰§è¡Œè·¯å¾„æ¨ç†ã€å…³ç³»ä¼ æ’­ã€ä¸Šä¸‹æ–‡èšåˆã€‚
3. **ç¬¬ä¸‰é˜¶æ®µï¼šç­”æ¡ˆç”Ÿæˆ** â€”â€” å°†å›¾ç»“æ„åŒ–ä¿¡æ¯æ³¨å…¥LLMæç¤ºè¯ï¼Œå¼•å¯¼ç”Ÿæˆæ›´è¿è´¯ã€å¯è§£é‡Šçš„å›ç­”ã€‚

è¿™ç§æ¶æ„æ—¢ä¿ç•™äº†ä¼ ç»ŸRAGçš„æ£€ç´¢æ•ˆç‡ï¼Œåˆç»§æ‰¿äº†Graph RAGçš„æ¨ç†æ·±åº¦ã€‚ä¾‹å¦‚ï¼Œåœ¨æ™ºèƒ½æŠ•ç ”åœºæ™¯ä¸­ï¼Œå…ˆç”¨å‘é‡æ£€ç´¢æ‰¾å‡ºè¿‘æœŸâ€œæ–°èƒ½æºæ”¿ç­–â€ç›¸å…³æŠ¥å‘Šï¼Œå†åœ¨ä¼ä¸šè‚¡æƒå›¾è°±ä¸Šè¿½è¸ªå—ç›Šä¸Šå¸‚å…¬å¸åŠå…¶ä¾›åº”é“¾å½±å“ï¼Œæœ€ç»ˆç”Ÿæˆæ·±åº¦åˆ†ææŠ¥å‘Šã€‚


---


### æœªæ¥æ–¹å‘ï¼šè®©å›¾è°±è‡ªå·±ç”Ÿé•¿ï¼Œè®©æ¨¡å‹è‡ªå·±å­¦ä¹ 

RAGçš„æ¼”è¿›ä¸ä¼šæ­¢æ­¥äºé™æ€å›¾è°±ã€‚ä¸‰å¤§å‰æ²¿è¶‹åŠ¿å€¼å¾—å…³æ³¨ï¼š

- **åŠ¨æ€å›¾æ„å»ºï¼ˆDynamic Graph Constructionï¼‰**ï¼šä¸å†ä¾èµ–äººå·¥å®šä¹‰Schemaï¼Œç³»ç»Ÿå¯æ ¹æ®ç”¨æˆ·æé—®å®æ—¶æŠ½å–å®ä½“ä¸å…³ç³»ï¼Œè¾¹æ£€ç´¢è¾¹å»ºå›¾ã€‚æ¯”å¦‚ç”¨æˆ·é—®â€œç‰¹æ–¯æ‹‰æœ€è¿‘æ”¶è´­äº†å“ªå®¶ç”µæ± å…¬å¸ï¼Ÿâ€ï¼Œç³»ç»Ÿè‡ªåŠ¨è¯†åˆ«â€œç‰¹æ–¯æ‹‰â€ã€â€œæ”¶è´­â€ã€â€œç”µæ± å…¬å¸â€å¹¶æ„å»ºä¸´æ—¶å­å›¾ã€‚
  
- **å›¾ç¥ç»ç½‘ç»œèåˆï¼ˆGNN + LLMï¼‰**ï¼šå°†å›¾ç»“æ„ç¼–ç ä¸ºå‘é‡è¡¨ç¤ºï¼Œä¸æ–‡æœ¬Embeddingå…±åŒè¾“å…¥å¤§æ¨¡å‹ï¼Œå®ç°ç«¯åˆ°ç«¯çš„å›¾æ„ŸçŸ¥ç”Ÿæˆã€‚è¿™èƒ½è®©LLMçœŸæ­£â€œç†è§£â€å…³ç³»ï¼Œè€Œéä»…â€œçœ‹åˆ°â€å…³é”®è¯ã€‚

- **è‡ªåŠ¨åŒ–SchemaæŠ½å–ï¼ˆAuto-Schema Extractionï¼‰**ï¼šåˆ©ç”¨LLMä»éç»“æ„åŒ–æ–‡æœ¬ä¸­è‡ªåŠ¨è¯†åˆ«å®ä½“ç±»å‹ã€å…³ç³»æ¨¡å¼ï¼Œå¤§å¹…é™ä½å›¾è°±æ„å»ºé—¨æ§›ã€‚æœªæ¥ï¼Œä¸Šä¼ ä¸€ä»½PDFå¹´æŠ¥ï¼Œç³»ç»Ÿå°±èƒ½è‡ªåŠ¨ç”Ÿæˆä¼ä¸šå…³ç³»å›¾è°±ã€‚


---


### æ¨èå­¦ä¹ è·¯å¾„ä¸å¼€æºé¡¹ç›®

æƒ³åŠ¨æ‰‹å®è·µï¼Ÿä»è¿™é‡Œå¼€å§‹ï¼š

1. **å…¥é—¨çº§**ï¼šLangChain + FAISS + LlamaIndex â€”â€” å¿«é€Ÿæ­å»ºä¼ ç»ŸRAGåŸå‹ã€‚
2. **è¿›é˜¶çº§**ï¼šNebulaGraph + DeepKE + GraphRAG â€”â€” å­¦ä¹ å›¾è°±æ„å»ºä¸è”åˆæ£€ç´¢ã€‚
3. **ç ”ç©¶çº§**ï¼šPyGï¼ˆPyTorch Geometricï¼‰ + GNN-RAGè®ºæ–‡å¤ç° â€”â€” æ¢ç´¢å›¾ç¥ç»ç½‘ç»œå‰æ²¿ã€‚

å¼€æºé¡¹ç›®æ¨èï¼š
- Microsoft GraphRAGï¼ˆGitHubï¼‰
- NVIDIA NeMo Retriever
- DeepKE-LLMï¼ˆæµ™å¤§ï¼‰


---


é€‰å‹ä¸æ˜¯ç»ˆç‚¹ï¼Œè€Œæ˜¯èµ·ç‚¹ã€‚æ— è®ºä½ ä»Šå¤©é€‰æ‹©å“ªæ¡è·¯å¾„ï¼Œéƒ½è¦ä¸ºæ˜å¤©çš„æ¼”è¿›ç•™å¥½æ¥å£ã€‚è®°ä½ï¼š**æ¶æ„æœåŠ¡äºä¸šåŠ¡ï¼Œè€Œéç›¸å**ã€‚æ„¿ä½ çš„RAGç³»ç»Ÿï¼Œæ—¢èƒ½ä»Šæ—¥è½åœ°è§æ•ˆï¼Œäº¦å¯æ˜æ—¥æŒç»­è¿›åŒ–ã€‚

---


## æ€»ç»“

- ä¼ ç»ŸRAGé€‚åˆè¯­ä¹‰åŒ¹é…å‹å•è·³é—®ç­”ï¼Œè½»é‡é«˜æ•ˆ
- Graph RAGé€šè¿‡çŸ¥è¯†å›¾è°±æ”¯æŒå¤šè·³æ¨ç†ï¼Œæå‡å¤æ‚é—®é¢˜å‡†ç¡®ç‡
- æ¶æ„é€‰æ‹©åº”åŸºäºé—®é¢˜ç±»å‹ã€æ•°æ®ç»“æ„å’Œæ€§èƒ½é¢„ç®—
- æœªæ¥RAGå°†èµ°å‘æ··åˆæ£€ç´¢ä¸åŠ¨æ€å›¾æ„å»º

## å»¶ä¼¸é˜…è¯»

æ¨èé˜…è¯»å¾®è½¯Graph RAGè®ºæ–‡ï¼Œå°è¯•LangChain + Neo4jç»„åˆå®è·µï¼Œå‚ä¸å¼€æºé¡¹ç›®LlamaIndex Graph Storeè´¡çŒ®ã€‚

## å‚è€ƒèµ„æ–™

1. https://arxiv.org/abs/2404.16130 (å¾®è½¯Graph RAGè®ºæ–‡)
2. https://python.langchain.com/docs/use_cases/question_answering/
3. https://neo4j.com/developer/graph-rag/
